{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## CV-Module 21 (Innovative Skill)","metadata":{}},{"cell_type":"markdown","source":"**100019**","metadata":{}},{"cell_type":"code","source":"!pip install einops\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport tqdm, time, copy\nimport heapq\nimport datetime\nimport glob\nimport random,time\n\nimport math, random\n\nfrom functools import partial\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import *  # * means all the things included in tf & keras all be imported at a time\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import *\nfrom tensorflow.keras.regularizers import *\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport einops\nfrom einops import*\nimport pathlib\nimport itertools\nfrom keras.layers import Lambda\nimport warnings as wr\nwr.filterwarnings('ignore')\n\n\n\nimport random\nfrom tensorflow import (abs,cast,clip_by_value,concat,convert_to_tensor,\n    expand_dims, gather,gather_nd,linspace, map_fn,matmul,norm,pad,\n    print,range,repeat,reshape,shape,sign,split,squeeze,stack,tensor_scatter_nd_update,tile,transpose,unstack,zeros,\n)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:04:35.843804Z","iopub.execute_input":"2025-01-25T13:04:35.844249Z","iopub.status.idle":"2025-01-25T13:04:52.969070Z","shell.execute_reply.started":"2025-01-25T13:04:35.844185Z","shell.execute_reply":"2025-01-25T13:04:52.967967Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#Number of parameters = (N x M x D + 1) x K  # this si the formula of counting params of cnn model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:04:52.970018Z","iopub.execute_input":"2025-01-25T13:04:52.970610Z","iopub.status.idle":"2025-01-25T13:04:52.974728Z","shell.execute_reply.started":"2025-01-25T13:04:52.970578Z","shell.execute_reply":"2025-01-25T13:04:52.973680Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Basic layers","metadata":{}},{"cell_type":"code","source":"#Number of parameters = (N x M x D + 1) x K\nkr = 2  # Kernel Size\n\nimage_size = 32        # input image dimensions are 32x32 pixels with 3 channels (RGB)\n\nx_input = layers.Input(shape=(image_size,image_size,3))  # (32, 32, 3) (32x32 RGB images), and assigns it to d1. 3 channels (RGB)\nd1 = x_input\n\n\n# x_input as the input and d1 as the output. In this case, the model simply takes the input and outputs it without any modifications (an identity model).\nclass_model = Model(inputs = x_input, outputs=d1)   # the model import from tf.keras\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:04:52.975837Z","iopub.execute_input":"2025-01-25T13:04:52.976207Z","iopub.status.idle":"2025-01-25T13:04:53.018554Z","shell.execute_reply.started":"2025-01-25T13:04:52.976169Z","shell.execute_reply":"2025-01-25T13:04:53.017591Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"### Explain","metadata":{}},{"cell_type":"markdown","source":"**Parameters**\n\n- 𝑁 is the number of input features.\n- 𝑀 is the number of hidden units.\n- 𝐷 is the depth (number of layers).\n- 𝐾 is the number of output features.\n\n\n**Assumption**\n- This is basic layer desion, no params defined, out trainable & non-trainable parames will be 0\n- What the input define, output wil be same as input","metadata":{}},{"cell_type":"code","source":"# Visualization\nfrom tensorflow.keras.utils import plot_model\nplot_model(class_model, to_file='model.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:04:53.020376Z","iopub.execute_input":"2025-01-25T13:04:53.020710Z","iopub.status.idle":"2025-01-25T13:04:53.279411Z","shell.execute_reply.started":"2025-01-25T13:04:53.020682Z","shell.execute_reply":"2025-01-25T13:04:53.278448Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAnwAAAEACAYAAAAp5atxAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3dd3QU1fs/8GfTOymEUEIvRgi9F+kYupTQpCMICCIoCKJ8RHoTUEB6V7qAUgICUkPoVUBIACUggYQkpJBNfX5/8Mt+d3Zmd2eT3Wwyeb/OmXMys3fu3JuZnX1m7p07KmZmAgAAAADFsrF2AQAAAADAshDwAQAAACgcAj4AAAAAhUPABwAAAKBwCPgAAAAAFA4BHwAAAIDCIeADAAAAUDgEfAAAAAAKh4APAAAAQOEQ8AEAAAAonJ2cRKdOnaIBAwZYuiwAAAAAYIKFCxdSv379jKaTFfCp1Wp69uxZrgsFAAAAAOaTnJwsKx2adAEAAAAUDgEfAAAAgMIh4AMAAABQOAR8AAAAAAqHgA8AAABA4RDwAQAAACgcAj4AAAAAhUPABwAAAKBwCPgAAAAAFA4BHwAAAIDCIeADAAAAUDgEfAAAAAAKh4APAAAAQOEQ8AEAAAAoHAI+AAAAAIVDwAcAAACgcAj4AAAAABQOAR8AAACAwiHgAwAAAFA4BHwAAAAACoeADwAAAEDhEPABAAAAKBwCPgAAAACFQ8AHAAAAoHAI+AAAAAAUDgEfAAAAgMIh4AMAAABQOAR8AAAAAAqHgA8AAABA4RDwAQAAACgcAj4AAAAAhUPABwAAAKBwCPgAAAAAFA4BHwAAAIDCIeADAAAAUDgEfAAAAAAKh4APAAAAQOEQ8AEAAAAoHAI+E8TExBAziyZ/f39rFw2sCMdF4WJvb08nT57U7OcnT56Qn5+ftYsFoCjBwcGUlZWl+Z6NHTvW2kUq8BDwAQCYYNWqVdSyZUsiInrz5g1169aNXrx4Yd1CASjMnj17aMaMGZr5pUuXUvv27a1YooIPAR8AgEzjxo2jYcOGaeZHjRpF165dE6WLj48X3O0NDAzMy2KCluHDhwv2xZEjR6xdJJDpu+++o0OHDhERka2tLe3cuZMqVKhg5VIVXAj4oMCYPXu24MQ9ceJEaxcJCpHAwEBasGCBZn7v3r20detWK5ao8Jo6darmPNCoUSNrFwcshJlp+PDh9OrVKyIi8vDwoJ9//plsbW2tXLKCCQEfFAg2NjY0cOBAaxcDCil7e3v65ZdfyNHRkYje9tscOXKklUtVeDVp0sTaRYA8EhUVJei/17hxY5oyZYoVS1RwIeAzQdGiRUmlUommp0+fWrtoite2bVsqXbq0tYsBhdSYMWOoRo0amvnp06dTTEyMFUtUeKlUKtzVK2R27NhBoaGhmvmvv/4avwc5gIAPCoShQ4dauwhQSPn4+ND//vc/zfz9+/dp9erVVixR4RYQEEA+Pj7WLgbksS+++ELzt7OzM82fP9+KpSmYEPBBvufp6UndunWzdjGgkJowYQJ5eXlp5mfPnk0ZGRlWLFHhhubcwunixYuCB2769etHVatWtWKJCh4EfCYwdbw1T09PyfQHDx4UpPPx8aGvvvqKQkNDKTY2ltLS0igqKoouXLhAU6dOpWLFihktm75t3b17V5CuSpUqNGPGDLpw4QJFRkaSWq2mZ8+e0dmzZ2ncuHGCHzZ92rZtK7mtc+fOGV23WbNmkuveuHFDkG7KlCmaz+Li4sjJyUmU18KFCwV5REREGN1+fmNjY0OtWrWiJUuW0OnTp+nZs2eUmJhI6enpFB0dTbdu3aK1a9dSt27djHZUnjx5suT/9tGjR7LL07hxY8k8UlNTydvb2+C6jo6O1K9fP1qzZg3dvHmTXrx4QWlpaRQTE0N//fUX7dq1i/r27Uuurq6yyqLvmD5w4IAmTalSpWjt2rX09OlTSktLo+fPn1Pv3r1l19cYZ2dnGjVqlGb+xYsXtHPnTrPlT/S2I7p2/dasWSP4vF27drR161YKDw+n5ORkSktLo5cvX9K5c+fou+++oxIlShjdRoUKFQTb2LJli+YzZ2dnGjlyJIWEhNDTp08pNTWVkpOTKSIigg4cOEADBgyQ/P7pqlSpkmAbp06dkv0/mDhxomBd3THXgoODNZ+tW7dO8FlYWJhg3VmzZsneriWoVCpq0aIF/fjjjxQaGkrPnz/X7Lfs7/SGDRuoR48eZGdnZzCvAwcOCOr2ySefmFyePn36CPI4duyY0XW8vLxozJgxtHv3boqIiKD4+HhSq9UUGRlJV65coeXLl1OrVq1kPzzh5eUlKMOqVas0nwUFBdHx48cpLi6O1Go1Xbx4UW8+y5YtE8yPHz9e1vbh/2MZQkJCmIgK/RQTEyP5//H395dMb2dnJ5k+NDRUkyY4OJjj4+MN/v9jY2O5V69eBstma2srue6rV6+YiNjR0ZHXrVtndF9HRUVxUFCQwW21bdtWct1z584Z/R82a9ZMct0bN24I0k2ZMsVoWXVFREQUiOMie+rYsSM/ePBAdv0eP37MrVq10ptf8eLFOT09XXLdmjVryqrLjBkzJNffu3ev3nVUKhWPHz+eX7x4Iasez58/5969exsti729veT62cdZmTJl+NmzZ6LPJ06caLZ9O3z4cEHeM2bMkLWe7nc6MDBQb1rd88S2bduYiNjHx4dDQkKM/j9TUlK4b9++Bsvj5+cnWOf3339nIuJatWrxw4cPjW7j3r17XKdOHYPbqFSpkmCdU6dOyf4/T5w4UbDu2LFjBZ8HBwcbLWO2WbNmGdyHR44csdi5oE6dOnz16lXZZX306BE3b95cb37dunUTpL9w4YLJZdq9e7cgjwEDBhj8zs2ePZsTExNllf/atWtGjwsiYmdnZ8F6W7ZsYSLiESNGcFZWluCzmJgYvfmoVCrB8ZqSksKenp4W258FZVq7dq2s/YU7fBaUkZFB6enpouXZd9H69OlDu3btoiJFihjMx8vLi7Zv305dunTRmyYzM5PS0tJEy93d3cnGxob2799PH330kdEy+/n50eHDh6ljx45G00LOTZs2jQ4dOkSVK1eWvU65cuXo+PHjNGjQIMnPo6Ki6PDhw5KfffDBB7K2oW+/a98R0ubm5kaHDh2iJUuWyLoTTURUvHhx2rlzp2CIEynp6emSTafZ35e1a9dSyZIlZW0zp/r06SOY37Vrl9m3kZGRQVlZWZp5V1dXcnV1pRMnTsgaaNbJyYl++eUXatq0qd40qampgnl3d3eqWLEi/fnnn7LGNQsICKCTJ09iPEEDWrduTefOnaM6derIXqd8+fJ04sQJCgoKkvz84MGDgkG9GzZsSFWqVJGdv4uLC3Xo0EEzn5iYSHv37pVM6+XlRX/++SdNnTqV3NzcZOVfu3ZtunTpEnXv3t1gOrVaLZh3dXWlMmXK0I8//kgqlUrWtoiImJn27NmjmXdycpJ9bgM06Vqc7oFO9PZkW6FCBVq/fr3sg93W1pZWr15N7u7uetPontSJ3g4nMWnSJJNGKLexsaEdO3bg1WAW0r9/f8EI8qawsbGhdevWUe3atSU/37Bhg+RyOX0gixUrJvljFRMToxn8VLcs27ZtE/ygmGLSpElGx1KUOqbd3d2pcePG9P777+dou3J5e3tr3qhBRBQREUF//fWXRbalfWHo5ORE8+bNo5o1a1JSUhLNmjWLatasSa6uruTi4kLvvPMOTZo0iRITEzXr2NjY0OLFi2Xln72NDRs2kJeXF0VFRdHEiRMpMDCQ3NzcyM3NjapXr07z5s0TrOfh4UF79+412gxpCXv27NGMivDLL78IPmvcuLFg1IRvvvkmz8vn4+ND27dvJ2dnZ82yO3fu0IABA6hy5cpUpEgRcnBwIH9/f+rbt6+gC4udnR1t376dPD09RflmZGSILrb0XfBJ6dixo6ALxe7du+nNmzeidNnf5WbNmmmWZWZm0po1a6hFixbk6elJjo6OVLZsWRowYABduXJFk87W1pa2b99OjRs31lsOZhZcvDk7O9OECRNkdRXQpRuwBgcHm5xHoSXnNiCadN9OOWm6i42NFaWPiYkR3WaXa9SoUXq3FRcXJ7lOcnIyMzNfv36dO3fuzO7u7lykSBFu164dh4WF6d3W2rVrJbeTF0262tOsWbMk1zFn011eHRdOTk56mz6vXLnCbdq0YU9PT/b29ub3339fb5Ovvu+knZ0dP3/+XHKdMmXKGKzH4MGDJddbtmyZZHrdZrhsiYmJ/Pnnn3O5cuXY3t6eixcvzsOHD+eoqChR2pSUFC5fvrxJx/TLly95y5YtkttmNt9x0bNnT0G+y5cvl72uKU26RMRv3rzRpI2OjuasrCx++PAhV6hQQe86LVq0EDWHValSRTKtbpNadtP/nTt3uHjx4nq30bJlS1E3gaFDh0qmtWSTrvb0888/C9I2atTIYN550aT77bffCrZx/fp1dnV11Zve0dGRQ0NDBetMnTpVMm1AQIAg3T///MMqlUpWuXbs2CFYV1/z8bhx4wTpXr9+zU2bNtWbr42NDS9btkywzrVr1wyWKyUlRZP2zJkzHB0dzczMhw8f5qZNm7Kbmxs7Ojpy6dKlDdZJpVIJflffvHnDdnZ2Zt+nBWmS26SLgM+EKScBn9Q6WVlZmhP1tWvXuGPHjuzh4cEeHh7csWNHvnv3rt59cezYMZPLx/w2GHN2dhatY29vz6dPn5ZcJy0tjb28vETrIODL+XHRt29fybRqtVryh7dq1aqiH3Xmt8eQr6+vZHnmz58vuY1PP/3UYD10fxyy1a9fX5TW3d1dst5paWl6f4DLly/Pr169Eq3z888/m/S/VavVmouYo0ePcrNmzdjV1ZXd3d35nXfeMRhAmjItXLhQsF1DfZ90J1MDvqSkJNH/UU6/yxMnTsgqo5OTk+j/mJGRwbVr1zb5/3D27FnJdIU54NM9Z3fs2NHoOi1bthSsY+j8qRsctmjRwmj+Tk5Ogr54jx49kgzIHBwc+OnTp4L8O3fubDR/GxsbPnfunGC9nj17yjrGsy8iNm/eLDt41Z6OHDki2K6cfoRKntCHLx/Lbno4efIkNW7cmA4fPkwJCQmUkJBAhw8fpvfee0/vYM6m9A/JlpGRQR999BGlpKSIPktPT6dRo0YRM4s+s7e3p06dOpm8PdDP09OTzp49S9evX6eIiAiKioqipKQkOnPmDEVFRYnS3717ly5duiRarlKpqHnz5pLbyEmzrq2trWQT6b179+jy5cui5cOHD5ccC23r1q104cIFyW08fvyY5s6dK1revXt32U/uEr19GtjFxYV2795N7du3p3PnzlFycjIlJibS/fv36fHjx7LzMqRBgwaCeX31soQdO3bQzZs3jab7888/BfOm9O86dOgQXb9+3Wg63ScjGzVqZLTfcWFib29Pf/31F4WGhtLDhw8pMTGRTp48aXS90NBQQb9rQ0OMrF+/XjAvp1m3Q4cOgr54mzdvljzPd+vWjUqVKqWZP378uGgkCSlZWVmirilyn5C3s7OjV69e0SeffCJZJmN0v4sNGzY0OY/CCAGflbx584YGDRok2Ufp1atXNG/ePMn1vL29ZQ2dou3o0aN0//59vZ/fu3ePwsLCJD9r06aNSdsCw1atWkXNmzenOnXqUOXKlalEiRLk7u5usD/arVu3JJfre2Dh/v37glHpszVv3lzvsdOoUSPJz/Q9rNGjRw/J5fo6hGeTeujBxcXF5IeEEhMTafTo0Tn6sZDrnXfe0fydnp5u0vA2ubVt2zZZ6XSDW1MCse3bt8tK9+TJEwoPD9fM29nZ5ejCU6nS09Opd+/e1KxZM6pUqRJ5eHhIXlxLraf9thZPT0+9w5zs2rWLkpKSNPPBwcGC/oJStPu2sc5QPNpat24tmNftI2lI9nAq2Tp06CB7qJbNmzdTcnKy7G1pe/DggWDelAudwgwBn5Xs2rXL4CvZDF1hmXp1rT1umT76rkirVatm0rbA/F6/fi253FDgr3tHgOjtD7W+O7ZSAVdWVhb9/PPPkvnUq1dPMh9DFxZEb4MHqfrUr1/f4Hq69u7dq3mhuiU4OTkJnjp++vSp4ElaSzM0Fpk27SCA6G3wLJeccTOz6Y6TWalSJdnrgn7aD8WoVCqyt7eXTJeUlCQY/9HDw8PgHXtHR0fq3LmzZv7s2bN673zrthSYclxkZWXR+fPnNfPu7u6yj40//vhD9nZ06dalbNmyOc6rMEHAZyXaI4ZLiYyM1PsDk/0Cd7l0T9ZSdK+YsuHKKe/Z2dmRs7MzeXh4kLe3t979bWOj/+u7a9cuwVOc2fT9SEg9afvnn39KXpSULVtW79N14eHhkoMla09SFyzVq1fXWxcpuk2Z5laqVCnBE/SRkZEW3Z62tLQ0wV0TY2m1yX3qPyUlxaR3gOvWHz+w+nl5eVGvXr3ohx9+oJCQELp16xb9+++/9PLlS4qLi6PExERSq9WUkZFh0v9Rt6uGoWbdoKAg8vDw0Mxv2rRJb9ry5ctr/mZmk4913d+Od999V9Z6t2/fNmk72v7991/BPN6rK0/eP18PRPS2GdWQrKwsiomJkRzbzJRxi4hI1olde6wnbR4eHmRjY5OndzcKi0qVKlHPnj2padOmVLVqVSpatCh5eHiYvH+lJCcn086dO2n48OGC5UFBQeTk5CQYLqh48eJUq1YtUR76moCKFy+e6/Lp0v7RkcPYncTc0v6xJCJKSEiw6Pa0SQXq5hYdHW1Set0AVO44bYWJl5cXzZgxg4YPH56j4UaMOX/+PN27d08TULVr146KFy8u2fdXuzn3zZs3grHrtDk7OwvKqlKpJIcSM4WcN79kZGTQ8+fPc7wN3e+IoeHK4P/gDp+V6Gum02auE7+cfPT1pVCpVCZ1qAfjfH196ZdffqEHDx7QvHnzqEuXLlSxYkUqUqSIWYK9bFIPb7i5uYn6ZXbo0EG03aSkJL398Yz1HcoJU0/Ycu+A5ZRu06jU2GUFman10e2ThnOCUOXKleny5cs0duxYiwR72bS/07a2tvThhx+K0jg4OFDXrl0183v37tX7GyA19l9uyfkuJycn56r/re7vlSldGQozBHxWkpmZmWfbkvPFMtTR1px39+R26FUqf39/CgsLow8//NCswZ2UsLAw0buUicTNulLNub/++qveiwCpN7rklu4dNWMsHYDpNqNLPVxVmOh2H8jL81d+5+LiQvv27aOKFSsKll+4cIEmTpxIQUFBVK9ePSpfvjwVK1aMPD09ydXVlezt7UVNk8Zs2bJF0O9Pqlm3Xbt2gm4ThppzLbEf5dz9lXqDjimysrIEeZjazamwQpNuIeDu7m70Lp++K6SsrCzZP65yrvotcUVZkGzZskX0w6BPZmYmZWRkkI2Njd7O3MZs2LCBFi1aJFjWpUsXTTO9nZ0dtWvXTrKc+hi6u+bv70/Pnj3LUVnzE90AT2k/KKbeodO9a5XTpyuVaOTIkYKH29LT02nw4MGyn4I2xcuXL+nQoUOai7aaNWtS9erVBf3htJtzIyMjDQ4Ro9vSlJKSUiDultnY2Aje+FLYL8jkwh2+QkBOnyt9r1GLi4uTfevd19fXaJrC/NRvo0aNqFWrVpKfPXr0iMaNG0eBgYHk7e2tOaE5OTkZfGWWMbp3BIjevi+5UaNGRPT2tVS6QXhkZCSdOnVKb56xsbF6P/Pz88txWfMT3YucgvAjaApTL7yKFi0qmJfTJcUUpt7hzU9077JNmzZNdrCXk/EMdZ/A137fs4ODg+AO/tatWw220KSmpgqOdWdnZ3JwcDC5THlN94JFaV0uLAUBXyFQs2ZNo2kCAgIkl0s9XKLvaqpYsWJG+6+Y8k5fpenSpYvk8vj4eGratCktW7aM7ty5Iwqyc9MhOTo6WnKIn+wfBanhWIz9SDx79kzvkCiWeKDDGpTeKdzd3V1W5/psuk9BSo1JqHthaMpdaVPKkp+oVCrBRWxmZiatXr1a1rqlSpXKUYtHSEgI/ffff5r5Xr16af5u3769IM/Nmzcbze/OnTuCee3xJ/Mr3e9jXjzopAQI+AoBOW/L0B18M5vUo/P6ru7t7e0pKChI7zbq1asneDl3bhkaliQ/0jd0wJEjRySftMuWfTcup6TG5Pvggw+ISLr/nqHm3Gz6Bupu0qSJiaXLn54+fSoIYMqUKWPF0lhG3bp1ZaetXbu2YF57IOZsug92mBIk5/YYtxZfX19BYPvixQuKj4+Xta5206spMjMzBYFclSpVNBf1/fr10ywPCwvTO9yWNt036TRt2jRH5cpLusPZ5OWwSQVZwfrFhBzp0qWLwfGe6tWrJzksB9Hbt3ToevTokd5m3hkzZkg+xenp6UmbNm0y64MKUkPW5Gf6+k0ZegiiZcuWet9qIPdpwCNHjoj61VWpUoXatGkjuvt76dIlWUOeHDp0SHL5oEGDDDYJtW/fnhISEig8PJzOnTtHe/bsoRUrVlDbtm1l1CTvqNVqevnypWbe39+/wF1gGKPvbSm6KlWqROXKldPMJycnS76STfdCUHsdQwIDAykwMFBW2vxOt/uEPm5ubvTFF1+Ilss9P+o+gR8cHEyurq6CVgQ5d/eIxGPCDhw4UNZ61qR7bJn68EthpawzGEhycHCg9evXS/4QOzk50U8//SS5XlJSkmTAl5SUJHmFT0RUo0YNOnHiBL333nvk4uJCXl5eFBwcTFeuXKFq1arl6IlffeNCtWjRwuS8rEnf2GcNGzaUfHq5QoUKBu+2yW0+1b0jkE33HalE8n8ktm7dKvnwRunSpWn+/PmS6zg7O9OMGTM0o/E3bdqUevbsSaNHjxYEV/mF9t0Re3t7qlChghVLY34ffvihrPEPx40bJ5g/deqU5EVKcnKyYGw1d3d3vW9k0TZ79mwZpf0/uheb1uxzFhsbK/hf+Pv7G22mtbGxobVr10re8ZfbxBsREUFnzpzRzHfv3p26dOmiuahUq9WCN3MYcvjwYcFYrU2aNJF9MWBnZ0fnz5+n48eP01dffZVnr9zTbXaWcycTEPAVCunp6dSmTRs6ffo0tWvXjtzc3MjDw4Pat29PoaGhel9r9cMPP+gNtgy9M7Vx48Z05swZSk5OptjYWNq9e7fmydRVq1aZXH59g0LXq1eP5s6dSyVLliQnJyeqWrVqvn6a8tKlS5LL33nnHdq0aRNVqlSJHB0dqWLFijR58mS6evUqlS5dmmJjYyUD7Hbt2sn+gdiwYYPoh1J3RPy0tDTasWOHrPySk5NpwYIFkp+NHz+edu/eTQ0bNiRXV1fy8fGh9u3b08mTJyWPtU2bNul9X7A16e4vJb2gPS0tjRwdHWnXrl0Gj6GgoCAaM2aMYNmKFSv0ptd9Jdy0adMM3rWaM2cOde3a1aSBoHWfEK5atarsdc0tIyND0CRqa2tLEydO1Jve09OTduzYQX379qVLly6JLqhr1Kghe9vaXTWqVatGU6ZM0cz/9ttvspuWMzMzae7cuYJlmzZtMtr9xtXVlbZu3UqNGzemNm3a0Jw5c+jjjz+WXf7c0P0uyn0VYaHHMoSEhDARFfopJiZG8v/j7+9v1nWyp4iICMl1AwICTNrWggUL5OxmgcjISPbw8NBbtjJlyvCbN29MyvPFixdctGhRzsjIEH128+ZNvduqXr267G3I+b9a67jw9vbm169fm/Q/Y2bu2bMnr1y5UvKzJ0+e8P79+3nx4sVGy3nq1CmD29m7d69J9baxseETJ06YXB9t4eHhBo+z3Hx/cjsFBwcLtrls2TLZ68bHxwvWDQwMNJg+KSlJkzYmJkb2dtq3by/Yzrp16yTTOTk5CdJdvHiRL168yMzMz5494/Hjx3NAQAC7uLiwq6sr16hRgxcsWMDp6emC9UJDQw2Wp2fPnqJ9dfDgQW7VqhV7eXmxnZ0d+/n5cY8ePfjcuXPMzBwXF8dDhgwRrDN27Fi925g4caIg7T///MPNmzdnZ2dn9vT05Fq1agnSDx8+XJD+yJEjZj1OPv74Y0H+WVlZ/OOPP/K7777L9vb27OXlxXXq1OHp06fzixcvmJlZrVZz1apVedmyZYJ1L1++zFWqVGF7e3t2dXU1uF0XFxe955MOHTqYVAeVSsXHjh0T5JGRkcFr1qzhli1bctGiRdne3p5LlCjB9erV4+nTp/M///wjSP/ixQv29fU1+zEuVdZXr15p8nrz5g3b2dlZ9FyQ36e1a9dKHge6EPCZMBXUgK9YsWIcGhoqZ1czM3NCQgLXrFnTaPnGjh0rO8/U1FRu06YNExEnJCSIPr9//77Bbcktf34O+IiIP/nkE9n/M2bmmTNnMhFxq1atDKY7deqU0XIOHDjQYB7dunUzue6enp6iHwq57t27Z3R/WTPg8/b2FgQ8Dx48kL1ufg/4rly5wu+++67kd1GfqKgoo/93GxsbTSAnR1paGnfv3p2bNWsmWD5+/Hi92wgICDBaTu30ugFfbukGFw4ODnzlyhXZ62dlZfHAgQOZiLhbt256002ZMsXo/l+1apVovf/++49tbW1NPt6LFCnCJ0+ezMm/hGNiYrh+/foWOcZ1pwYNGgi2feDAAYufC/L7JDfgQ5NuIREUFCSrT8fNmzepSZMmdPPmTaNply9fTp999pnRdy9GRUVRhw4d6MSJE0Qk/Qi9sYFgBw8erIgBfX/66SeaPHmy0ZHmU1JSaOjQoTRt2jQiIjp58iRt3bo1V9ves2eP3iesY2Ji9D6IYUh8fDx16NCBvv76a9mvO1Or1bRkyRKqW7eurPc8W0tsbKxgPMLKlSsrZhxJOzs7unfvHrVu3ZoePnxoNP2VK1eoWbNmRvdXVlYW9ezZky5cuGA0z/j4eOrUqRPt27ePkpKSBJ8ZeiDp77//lux/ai1paWnUtWtXunr1qtG0z58/py5dumi+ywcOHJC1nj5ST+D//PPPOXqDxuvXrykoKIhmzJgh2h+G7Nu3j+rWrSt62tdSdPsX6ntPMEiQExXiDt/bqaDe4StZsqQmTZMmTXjdunV8+/Ztjo2N5Tdv3nBERATv37+fe/Xqxfb29ib/XypUqMBz587l69evc0xMDKenp3NMTAyfPHmSP/vsM3Zzc3r0klAAACAASURBVBOkv3XrlqiMCQkJRrfj6+vL8+fP57t373JKSgqr1Wp+8eIF37t3j3fu3MmfffYZOzk5FYjjolKlSrx48WK+du0ax8fHc0ZGBsfFxfGFCxf4u+++E+yz7EmlUvGgQYN43759fO3aNb5x4wafOHGCV6xYwR07dpRV1tWrV0uW1ZTmSn2Th4cHDxkyhLdu3cp3797l6OhoTk9P5/j4eH706BH/9ttvPH78eIPNPub8/phj0r079N1338laL7/f4bt9+7bmMwcHB+7evTvv2rWL7927x69fv+akpCQODw/nffv2cc+ePU0+L9jY2HCfPn14z549/PjxY05KSuL09HSOjo7m06dP85dffsne3t6a9JUrVxaUL/vOtr5JpVLxmDFj+Pr16/zmzRvOyMjg2NhYvnz5Mi9YsMDgPswtfc2HdnZ2PHDgQP7999/52bNnrFarWa1Wc2RkJB86dIhHjBjBLi4uovWKFi3Ka9eu5efPn2u+L9euXeOuXbvK+l/fvn1bUL5q1arl+rj39fXlkSNH8p49e/jBgwccGxvLGRkZ/Pr1a378+DEfPHiQp06dyhUrVpSdpznu8KlUKg4PD9fkk5KSwp6enrmub0Gf0KRbCCdr/zhiyv/T/v37JY8RY80xhXVycXERfK/++++/HF0UWXvSDfj++usvq5cJU+4nOzs7/u+//zT79fz581YvkyUn3QucNWvWWL1M+WFCky4ACPj7+0sOwn316tU8a44paN68eSN4srxEiRLUu3dvK5YI4P/07t1b8JYSQ09QK8Gnn34qmF+6dKmVSlIwIeADKCSmTp0qeOF4tty8q7cwWLJkiWCIi2+++Uby/wiQl+zs7Oibb77RzEdGRtKuXbusWCLLql+/vuDNQDt37qS7d+9asUQFDwI+gEKgXbt2NHLkSNHyBw8eKPpHwhxevXpFM2bM0MwHBATQiBEjrFgigLcXcNpjaS5cuFD2mz4KokWLFmnGdFSr1fTll19auUQFkJx2X/ThKxgT+vARjx8/XlZfhtyIiIiwej0NTSVKlGAvLy92cnLiypUr86RJkzg5OVmyLj169LB6eQvCZG9vL+gc//LlS/bx8bF6ueRO6MOnrGngwIGcmZmp2Z/3798vkH1L5U69e/cWHL/Tpk2zepny04SHNgrhhIAPAR8R8ZEjR2TVY9++fVYva0GaatSowWq1WvP/2717t9XLJHdCwFdwJ3d3d3Z0dGQHBweuW7cub968WbAvMzIyuGXLllYvp6UmPz8/jo6O1tQ3LCwsR+MMKnnCQxsAoNf9+/fpo48+snYxCpRbt27R5MmTNfPBwcE0YMAAK5YICoOZM2eSWq2m1NRUunLlCg0aNEjw+aRJkwTjRSqJSqWi9evXU9GiRYno7RiuAwYMyNE4g4A+fKAwS5cuJZVKZdGpUqVK1q5mrpw+fZpatmxJsbGx1i5KgfPDDz/Qxo0bNfOrV6+m2rVrW7FEUFip1Wr65JNPaMmSJdYuisX873//04wskJmZSX369JE1UDhIQ8AHoDD379+nJ0+eUFJSEmVmZpJaraYnT57Qrl276IMPPqBWrVpRVFSUtYtZYI0cOVJzR8XFxYV+++038vPzs26hQLGePn1KsbGxlJWVRSkpKfTgwQP68ccfKTAwkFauXGnt4llMz5496dtvv9XMjx8/nkJCQqxYooJPxcxsLNGRI0cEj0MDAAAAgPWtXbuWhg8fbjQd7vABAAAAKBwCPgAAAACFQ8AHAAAAoHAI+AAAAAAUDgEfAAAAgMIh4AMAAABQOAR8AAAAAAqHgA8AAABA4RDwAQAAACgcAj4AAAAAhUPABwAAAKBwCPgAAAAAFA4BHwAAAIDCIeADAAAAUDgEfAAAAAAKh4APAAAAQOEQ8AEAAAAoHAI+AAAAAIVDwAcAAACgcAj4AAAAABQOAR8AAACAwiHgAwAAAFA4BHwAAAAACoeADwAAAEDhEPABAAAAKBwCPgAAAACFQ8AHAAAAoHAI+AAAAAAUDgEfAAAAgMIh4AMAAABQOAR8AAAAAAqHgA8AAABA4RDwAQAAACgcAj4AAAAAhUPABwAAAKBwCPgAAAAAFA4BHwAAAIDCIeADAAAAUDgEfAAAAAAKh4APAAAAQOEQ8AEAAAAoHAI+AAAAAIVDwAcAAACgcAj4AAAAABTOzpyZvf/++9S4cWNzZgkAAABQKCQkJNCSJUsskrdZA76goCD6/PPPzZklAAAAQKEQGRlpsYAPTboAAAAACoeADwAAAEDhEPABAAAAKBwCPgAAAACFQ8AHAAAAoHAI+AAAAAAUDgEfAAAAgMIh4AMAAABQOAR8AAAAAAqHgA8AAABA4RDwAQAAACgcAj4AAAAAhUPABwAAAKBwCPgAAAAAFA4BHwAAAIDCIeADAAAAUDgEfAAAAAAKh4APAAAAQOEQ8AEAAAAoHAI+AAAAAIVDwAcAAACgcAj4AAAAABQOAR8AAACAwiHgAwAAAFA4BHwAAAAACoeADwAAAEDhEPABAAAAKBwCPgAAAACFQ8AHQEQHDx4klUqlmf755x9rFwlM0K5dO8H+U6lUNHToUGsXCwDykf79+4vOEx07drR2sfJMoQn4YmNjaffu3TRq1Chq0KABVahQgTw8PMjJyYlKlSpFtWrVouDgYFq5ciVFRERYu7gAINO6devo+PHjgmXFixenxYsXaz7XPclnT7/99pvs7SxatEi0/pQpU8xaFzDNmTNn6NNPP6X69euTr68v2dvbk4eHB5UtW5Y6dOhAs2bNMvni7dSpUzRu3DiqU6cO+fn5kYODA7m7u1OZMmWoY8eONGfOHIqMjLRMhWQqrPUmyl3df/jhB/L19RUsCwkJoc2bN+dByfMBliEkJISJyOj0/fffy8kuTz19+pTHjBnDjo6OsuqQPQUFBXFYWJi1i8/p6ens7OzMRMQrV660dnFyLb/W58CBA4L9//jxY2sXCWR49eoVe3l5ib6/27Zt06RZu3at3u955cqVOS0tTda2Fi5cKFp/8uTJlqoaGHDt2jWuV6+erHO5jY0NDx06lOPj4w3mGR4ezk2aNJGd56hRozgxMTGPavxWYa03s/nqvmnTJlF6Hx8fjouLy/M6SXny5IlJsQoR8dq1a2Xlreg7fFu2bKFKlSrRihUrKDU11aR1jx49So0bN6ZRo0ZRenq6hUpo3J07dyglJcVq2zc3pdUHrGv69OkUFxcnWNagQQPq27evrPXDw8Np+fLlligaWEhISAg1bdqUrly5Iit9VlYWbdy4kZo0aUIxMTGSaa5du0b16tWj8+fPy85z1apV1KZNG0pKSpJd9tworPUmMm/dBw4cSLVq1RIse/XqFc2cOdNs5c2vFBvwTZkyhQYPHkxqtVqzzMfHh0aPHk2///47RURE0OvXr0mtVtOTJ0/o7NmzNG3aNHrnnXcE+axevZratm1LCQkJeV0FIiLZB3hBobT6gPU8efKEVq1aJVo+f/58UqlUsvOZOXMmxcbGmrNoYCERERHUq1evHF003r17l0aMGCFanpCQQF26dKHXr1+bnOelS5do/PjxJq9nqsJabyLz193GxobmzJkjSrt8+XL677//clzOgkCRAd/atWtp/vz5mnmVSkUTJ06khw8f0k8//URdunShihUrkoeHBzk6OlLp0qWpWbNmNGPGDLpz5w6tW7eOPDw8NOufOXOGhg0bZo2qKC5AUlp9wHoWL14suvveoEEDatmypUn5xMXF0fTp081XMLCYcePGUXJysmj52LFjKTw8nNRqNYWHh9PcuXPJxcVFlG7//v109+5dwbKFCxdK/tC3aNGCzp8/TwkJCRQZGUnr16+nokWLitJt3LiRHj9+nItaGVdY601kmbp36NCBatasKViWlpZGS5cuNW/h8xs57b4FqQ/fnTt3BP317OzseOvWrSbnc+PGDS5evLigfsuXL7dAiQ2rX7++Zvv5qc9bTuXX+qAPX8GSmJjIbm5uonPQjh07RGkN9eHTPk/8/fffBreJPnzWFR4eziqVSrQPRo8eLZl+3bp1kvt68eLFmjSZmZlcokQJUZrAwEBOT08X5Xn06FHJPJcuXYp6W4Al6p5t8+bNonRFihThN2/eWLROxqAPnwlmzpwp6K/3v//9jwYMGGByPjVr1qQdO3aQjc3//YtmzpwpaCLWNm/ePM2Te3Z2drK2sXTpUsl1Vq1apVl++fJlzfLRo0cLnhDMvlu2cOFCzbIKFSpo0sfExND//vc/atCgAZUsWZIcHR2pZMmS1KxZM1qyZInBW/nWrE9OpKWl0a5du6h///5UvXp18vb2Jnt7e3J2dqYSJUpQs2bNaPLkyXT9+nVZ+WU3CWZkZND69espKCiIKlSoQE5OTuTl5UWBgYH02Wef0cOHD2Xll5mZSYcOHaKPPvqIatWqRT4+PuTg4ECurq7k7+9P7du3pwULFtDLly8N5mOJfa3rv//+o9mzZ1O7du3I39+fnJ2dycPDgypVqkSdOnWi1atXi/rNSdE+HlQqFR05ckR2GYz59ddfRX2IPD09qVu3brLWb9KkiWA+IyODJk6caLbyaQsNDaWpU6dS48aNqWzZsuTi4kJubm5Urlw5aty4MU2dOpXOnTtnNJ/169eLnhIOCgrSfM7MtHPnTurUqRP5+fmRvb09+fr6UqNGjWjevHmUmJgou8wJCQm0cuVK6tWrl6Y1xMnJicqVK0etWrWiH3/80eixam7Hjh0jZhYss7W1lWyeIyIaMmQIOTo6ipZrP2l648YNev78uSjN119/LXnee//996l06dKi5X/99ZfR8udUYa03kWXqni04OJjc3NwEy16/fk2///57Lkqcz8mJCgvKHb5Hjx6xra2tpjxVq1bljIyMXOU5evRoQR313ZWaO3euJo2tra2svJcsWSK5zsqVK2X9vy9fvszMzD/99JNmmY+PDzMzh4WFcbFixQyuX7p0aQ4NDc139THVhQsXuFKlSrKvhoKDg0VPb+ne4YuMjOTnz58bfSrMwcFB8ESolNu3b3OtWrVklc3V1dXg1Zol9nW29PR0/vLLL9nBwcFoOX18fHjjxo0G89M+HoiIQ0JCDKY3RVBQkKhMI0aMkEwrdYfvhx9+4DJlyoiWHz9+XO82Tb3Dd/HiRX7vvfdkH5dNmzY1ODLA9u3bRes0bNiQmd8+rdyyZUuD+ZcqVYpv3rxp8P+alZXFixYtYnd3d6Pl9fDwkH1nwRw2b97MXbt25aZNm3JAQAD7+vpyvXr1DK5TsWJFUbknTZqk+fzkyZPcqlUrrlOnDleqVIl9fX3Z0dGRo6Ki9OYptU979OhhtnrqKqz1ZrZM3bUNHDhQlPaDDz6wRFVks+QdPkUFfIsWLRKUZ9WqVbnO8/79+4Jbyi1btpRMZ80Aac2aNZpljo6OHBkZKTlUhdTk5eXF9+/fz1f1McX9+/clm/aMTS1btuSsrCxNProB39OnT7lmzZqy8rKzs+M7d+5Ilu/Bgwey94X2pC+YssS+Zn4b7EkFUcamuXPn6t03lgr4UlJS2MnJSVSWffv2SaaXCvhmzZrFW7duFS2vUaMGZ2ZmSuZjSsC3ZcsWWYGz7mRvb8+bN2+WzHPv3r2i9O+++y6np6dz48aNZeVfrFgxjomJkcw/MzOTg4ODTS7z9OnTZey1vJeSksKurq6i8v7888+5yjcgIECU5/Dhw81U6twrrPVmNr3uUhdRbm5usodqsgQ06cp06tQpzd8qlYr69OmT6zyrVKlC9erV08xfuHDB5CFeTDVq1ChiZtFTSStXriR+G6QTM2vKZWtrq0mTmppKX375JcXFxVGTJk1o//79FBUVRWlpaRQVFUXbt2+nSpUqadLHxcXRZ599lq/qY4qvv/5a07Tn4OBAX331FV2+fJni4uIoIyODEhMTKSIigrZt2yZoxjt16hTt3r1bb74LFy6kmzdv0jvvvEObN2+m//77j9LS0ig6Opr27t1L1apV06TNyMigRYsWSeYzZswYQfNnp06d6MCBA/Ts2TNKTU2l5ORkunbtGn322WeC7gOff/65ZDOspfb1V199RUePHtXMV65cmdasWUN3796l5ORkSkpKolu3btHcuXPJx8dHsN6JEyf0/h8tITQ0VNS1wtbWllq1aiU7j7i4OOrfv7/omLt16xatX78+V+U7fPgwDR48mNLS0kxeNz09nYYMGULHjh0Tfebg4CBalpCQQAsXLqSwsDBZ+b98+ZJmzJgh+dmkSZNoz549phWY3g6Ns2/fPpPXs7TFixeLOvt7eXlR165dc5zn9evX6e+//xYtr1y5co7zNLfCWm8i0+vetm1b0RP9SUlJdOHCBYuV0arkRIUF5Q6fj4+PpixVq1Y1W74TJkwQ1FOqacycd8SypaSkCLarrzl548aNon3RrVs3yc63zMzx8fFcpUoVQfpbt27lm/rIlZWVxS4uLpr8Fi1aZHSdAQMGsJ+fH9erV0/QkVf3Dp+joyO3bduWk5OTJfN59eoVFy1aVJO+VKlSojQPHz4U7RND5s2bJ0gv1VRsiX396NEjtrOz03zeoUMHgx2Xnz59yuXKldOkDwwMNFgvc9M+NrOnatWq6U0vdYdvzJgxzMx8+vRp0Wd+fn6ckJAgykfOHb7Y2FjBcaE99e/fn8PCwjgxMZGTkpL4/Pnzeu+olShRQnTsHT58WJTOxcWFixQpwjY2NjxhwgSOiIhgtVrNN27c4C5dukjm7ePjIzpe/vrrL7axsRGlrV27Nh8+fJifP3/O8fHxHBoayh06dBClq1ChAqempuZ0l5pFZmYmv3z5ko8fP859+/YVldHGxob37NmT4/zT0tK4QYMGkv/TiIgIM9bENIW13szmqbtUE/CSJUvyqAZiaNKVIT09XVCWnj17mi3v9evXC/KWOoDyU8Dn5uamt9km2/79+wXrzJkzJ9/UR67Y2FhBfseOHctxXroBn5eXF0dHRxtcZ+zYsYJ1dEefP3PmDL/33ntcpUoV9vDwMNg/jJk5OTmZ7e3tNfl98cUXojSW2Neffvqp5jNfX19ZI84fOXJEkGdO+1/mhNSJ/cMPP9SbXirgGzlypObzDz74QPT5V199JcpHTsA3Z84cyXPjd999p7d8useRvpO4ofPwsmXLRPlmZGTofYPC7du3BWn79esnSlOuXDl+/fq1ZJk7deokSi/1hHReCAsLM/rbVLJkST548GCOt5GZmcn9+/eXzLt79+5mrI18hbXezOate/fu3UXrDhkyJA9qIQ1NujK8evVKMO/t7W22vHXz0t1WftOrVy9Bs5uUTp06CZ5QCg0NtXSxzM7Dw0PQxHno0CGz5T1s2DDJsae0Va9eXTCvO3jve++9R2fOnKH79+/T69evqU2bNgbzc3FxETwJp290fG3m2NchISGav/v370+enp5GtxsUFCQo64EDB4yuYy5S77rWHTDdFAsWLCB7e3vBsiVLltC///5rcl5r164VLQsICKBvvvlG7zrz58+XPF9t3bpV1jbr1atHY8eOFS23tbXV++RxeHi45u/MzEzBMZBt/PjxgvFIdcusKyfNwZZka2tL3bp1o40bN1JERAR16tQpR/mkp6fToEGD6JdffhF95ubmprc7h7UU1noT5azuUucOuaMvFDSKCfh0h2iQGoAxp3Qf3c7LV8rkhJy+THZ2dlS7dm3NvPYPQEFha2srGGR36dKl9Omnn9KzZ89ynXfbtm2NptENCM3xyjhnZ2fN3xkZGUbT53ZfP3/+XBBAaaczplGjRpq/b926JXu93JIaLLZEiRI5zq9KlSo0atQowTK1Wk1TpkwxKZ8nT55IDkT74YcfCvpn6nJxcaHOnTuLll++fFnWMTBkyBC9n+kOP5MtPj5e8/f169cF89kaNGigN9+qVauSl5eXYNnJkyeNlDRvZWZm0tGjR2n9+vW0YcMGvUNqGRIXF0cdO3aUDHpUKhVt3LhRMDxSflBY602Us7qXKlVKtOzp06eWKJ7VKSbg070rkZPXxeijm5fuiS6/0b3zpE/ZsmU1f0uNU1QQLFy4UBAkLV++nMqUKUNNmzaladOm0YkTJ3J0witTpozRNLqd6FlnvChtL168oA0bNtCwYcOoWbNmVLlyZfLz8yMvLy9yc3MjJycnsrOzozt37phUztzu6ydPngjSDR48WDTWm75J+6GXBw8emFTu3IiOjhYtK168eK7y/Pbbb6lIkSKCZTt27DCp8/bVq1cll8t5GEkq0E5JSZG8m6lLO/DWVbRoUclgU/vBM31vS2jSpInefW9jYyMai/HVq1f04sULo+XNSykpKXTu3DkaO3Ysvfvuu3Tt2jXZ60ZERFCjRo3o+PHjkp//8MMPFBwcbK6imlVhrTeR6XWXuljMb8exuSgm4PPy8hI8bSOnOUwu3aY6Y01o1ia3OVv7By4lJYWysrIsVSSLqV27Nh07dozKly+vWZaVlUXnz5+nWbNmUdu2bcnLy4vat29P69atk30hYK47xKmpqTRhwgQqW7YsffTRR7Rx40YKDQ2liIgIevnyJcXHx1NycjKlpqZSZmamyfnndl+b6x2yUneILCE9PV30OjWi3O8vHx8f+vrrr0XLJ0yYoPnb2Pt5pQJRIqKSJUsa3b6+gFXO/jEU7Nra2ooC2ZxsQy45Aaq5NWrUiJiZsrKy6NWrV3T9+nWaNWuW6ML8n3/+odatW8tqrgsNDaXGjRtLXsjY2dnR6tWr6dNPPzVbHXKisNabyLx1lzp3mKO1Jj9STMBnY2Mj6FMk940Kcty8eVMwr323JD9ydXWVlU73DlVOhpHID5o2bUrh4eH0888/U8OGDUU/zGq1mo4ePUojRoygcuXK0dy5c/MkuE1NTaXWrVvT0qVLLTaUT273tdQ7KnMir7o56Ps/Ojk55TrvcePGUbly5QTLLly4QNu3byciMvrGGX1vstC+A62PvjRy3o4h9WYBbYaak4nMu+8SEhLMlpepVCoVeXt7U61atejrr7+mK1eukK+vryDN69evadKkSQbz2bVrF7Vp00bypoGXlxcdPHiQPv74Y7OWPTcKa72JzFN3qe8eM1t8+DVrUEzAR/T2hz/bs2fP6J9//jFLvtrNOt7e3rKb0axF7oGq3dSpUqmM/nDkZ7a2ttS/f3+6cOECPX/+nDZu3Eh9+/YVffnj4+Np6tSp1KNHjxzdUTPFtGnT6Pz585p5e3t7Gjx4MO3YsYOuXLlCjx49otjYWEpMTKSUlBTKyMgQjO8nR273tbu7uyDd0aNHBWMjyp3M2YUiJww1p8vl6OhIc+fOFS2fMmUKqdVqo0Glvgcc5ATV+tIYuztnDrrHQG6Y8vo2S6tQoYLkD/2BAwf0BqZbtmyhfv36SX6vAgMD6fLly4LX2eVHhbXeRDmruznOHQWFogK+5s2bC+Y3btyY6zzv378v6JvTokULo1fMclnqaljuj692M5y7u7vRJitjrHl1r83Pz4+GDBlC27dvpxcvXtDVq1dpypQpgn6ev/32G61cudJiZVCr1YInNr28vOjixYu0adMm6tOnD9WtW5fKly8v6MNna2trchCa232t2/c1vz+Bru9OWE76aUrp27cvNWzYULDsyZMntHjxYqNPL+teXGST0wFc34NG+vI0J319kq9du2Zy4N+7d2+Ll9cU9evXFy3LyMiQ7Cu7a9cuGjp0qOTd/27dulFYWBhVrFjRIuU0t8JabyLT6k4kfe4o6DdA9FFUwNerVy9Be/yqVatyHYQsW7ZMMD948GDJdNrBUmZmpqwfbnPdgdQlNSK6se3rNlPnp/rkhkqlojp16tDcuXPpzp07gpHhFyxYYLHt3r59WxBkTZ061egTsGlpaSY/PJPbff3OO+8I9rWlX4aeW7a2tqIhVIiI3rx5Y7ZtfP/996Jl8+bNM/odqFOnjuTyS5cuGd2mVBovL688eRLy3XfflVyenx7kUqvVNGbMGOrVqxe1aNGC3n33XfLx8ZEcHkabvotz3e4r586do0GDBkkGPZ988gn9+uuvotEa8kJhrTeR5eueTercYc5RPvITRQV8Pj4+giEKXr58SePHj89xfhcuXBDcBapWrZreV7To3nkwdqckKyuL/vzzzxyXzZCzZ88aTZOWlkY3btzQzOuORZSf6mMuJUuWFHTMj4yMtFgT1PPnzwXzhp6kzPb777+b3Kcut/va09NTEAQfPHjQpO1bQ7FixUTLXr58abb8mzZtSj179hQsS0xMpBUrVhhcr0yZMqI+gERE27ZtMzi8SmxsLB0+fFi0vHnz5rm+6y5HtWrVJO9eyjm28oqTkxPt3buX9uzZQ2fOnKG///6bYmNjjY69qdv/Opufn5/m71evXlGfPn0kmzNnzpxJK1asMFurjqkKa72JLFt3bbrnaqLcP/WfXykq4CN6+25P7ScXN27cqPfdkYbcvXuXevbsqbnyUalUNH/+fL0nYN2nJbV/YKX8+uuvJg/sKre5b9u2bUY7Yu/bt0/wJJL2eHZE+as++qxYsYKCg4OpXLlytG3bNlnr6D6Cb6kTmm6+xgLL+Ph40bhvcpopzbGvtS9ibt26JTkIr67U1FSqVasW9erVizZt2pRnT+kSST/1KjU2X27Mnz9f9KCLdn9MfaQ6tT969IhmzpwpmT4rK4s++eQTybsMI0eOlFna3FGpVNStWzfR8lWrVul96vbw4cPk5uZGFSpUoEaNGlHXrl0FTzQTER05ckRySJdz587lqJxSg+iePXtW7wDVycnJtHz5ctFyb29vwUXOmDFjJI+fkSNHGhwwW5/CWm+iglN3bVL/A6mx+RRBzus4CsKr1bTpvkqKiLhfv3789OlTo+tmZWXxpk2bBO/lJSL+8ssvDa539epV2a+duXPnDvv6+rKTk5MmvdSryNLS0gy+ximb7uu2VCoVDxkyhLOysiTTR0dHc9myZQXbhcL0xAAACt5JREFU/ueff/JNfeQaMGCA4DVQDx8+NLrO8OHDNev4+/trluu+Wu3x48dG89Jd5969e5rP/vrrL8Fnw4YN05vPs2fPuGHDhuzl5SV4Z2XdunVFaS2xr8PDwwXvUS1evDj//fffesubmpoqeN2Svb29KE9L+vDDD0Xf79y8Wk0f3XdoS026x3BcXJzed+l+9NFHfOPGDVar1RwXF8d//PEHt27dWjJtvXr1RPtU33nY2CsAdc9lROLXGt66dYtVKpUonZ+fH69fv56joqI4LS2Nnzx5wsuWLWN3d3ej/wt95T179qzR/72UK1euSJbR1taWv/jiC46IiOC0tDSOjIzkX3/9lQMCAiS3P2LECE2eFy9elExTvHhxTkpKylE5C2u9C0rddfXo0UOU3tD52tLwLt0cWLp0qehl4K6urjxo0CDes2cPh4eH8+vXr1mtVnNkZCSfP3+ev/vuO65evbqoXv379+eMjAyD20tPT+fixYsL1hs0aBBfvXqVk5OTOTU1lf/++2+eOXMmu7u7s62tLc+aNUtwAEtxc3MTfBnPnz/ParWaX758yf/++y8zi4OA3r17MxFx8+bN+bfffuMXL15wWloaP3/+nLdu3SoIAIiIBwwYkK/qI9fly5cFJwNvb2+eNWsWX758mePj4zkjI4OTkpI4MjKSDx06JHpn6tSpUzV5mTvgy8rKYn9/f8HnY8aM4Tt37nBKSgrHxsZyWFgYf/nll5r/ycqVK3n06NGa9CqVirdt28YpKSmckJBgsX3NzDx58mTRd+Xbb7/lW7ducVJSEickJPDff//NK1eu5MDAQEHa0aNHS+ap/W5lIuKQkBAT9q5+8+fPF31Hq1Wrpjd9TgO+2NhY9vLyMnjOk7poCQkJkfyRkju5u7vzgwcPJPOVSm+OgI+Z+fPPP89xmStUqKA5Ro2VN6c//szMI0eOzHEZs4/ryMhITX7Dhg3LVX5S54zCWu+CUnddFStWFK2zdOnSHJc3txDw5dC+ffu4SJEiOT5QbG1tefbs2bK3t2jRItl5T506lY8fP66ZV6lUknm2bdtWbx5ffPEFM4uDgAcPHsiut7+/P0dFReWr+pjiq6++ytG+rVGjBicnJ2vyMXfAx8y8cuVK2eXp3bs3Z2Zm8ubNmyU//+CDD5jZcvs6NTWVO3ToYPL/sW7dunrvCFgq4Dtx4oTkdzU+Pl4yfU4DPmbmxYsXG6y/vrvUmzdvZgcHB5P/n76+vnzu3DnJPC0d8KWlpXHnzp1NLrOfnx/fvn1bdnlz8+OflpbGXbp0ydF33sHBgY8ePSrIT/tOdW4nSwZ8BaHeBaXu2mJiYiQvzvR9B/OCJQM+xfXh09atWzd69OgRffHFFyYNzGpjY0P9+vWju3fv0tSpU2WvN2HCBBo4cKDRdBMnTqTZs2cLngRiZsmniKZOnWpyP7MSJUpQSEiI0Y6nAQEBdOTIEb2dWfNLfQyZPXu26PVqxvTt25dOnz5t8SexRo0aRWPGjDGabujQobRt2zaysbGhnj17mtR/xFz72sHBgX7//XeaNGmSrOEIVCoVDRs2jE6ePCl78Gdzadq0qWh/Z2ZmWuRdrmPGjMnRkBSDBg2is2fP6n2XrS6VSkW9e/emy5cvC8YTzUv29vb022+/0fTp02Xv044dO9Lly5cpMDBQ9nZy8/3PLuOiRYtMesVl/fr16fLly/T+++/neNu5VVjrTZR/637s2DHROHzu7u6ioZkUQ05UWFDv8GmLjY3ljRs38qBBg7h27drs4+PD9vb27OjoyKVKleJatWpxv379eOPGjfzs2bNcbevQoUMcHBzMZcqUYScnJ3ZwcOAyZcrwoEGD+MaNG5p0t27dEvz/YmNjJfM7evQoN2vWjF1cXNjBwYH9/Py4ZcuWvH//fmYW3/XJvtPx+vVrXrFiBTdv3pxLlSrFDg4OXKJECW7evDn/9NNPgjtc+ak+OREdHc1Llizhzp07c8WKFdnNzY1tbGzY2dmZS5Ysya1bt+ZvvvmG79y5I7m+Je7wZfvjjz84ODiY/f392cHBgZ2cnLhixYo8aNAgPnPmjCj93bt3+f3332dXV1d2dHTkcuXK8Zw5c5jZ8vua+e0V5pw5c7h169bs7+/Pzs7O7OjoyH5+fty8eXP+5ptvJJscdVnqDh8zc/v27UXnH339dHJzh4+Zec+ePXrPeXL6oZ46dYonTpzI9evX55IlS7KjoyO7ublxuXLluHXr1jx79my9x6U2S9/h0xYdHc2LFy/mzp07c7ly5djNzY0dHBzY19eX69evzxMmTOCrV6/mqLw3b940Wlc5EhMTed26ddy/f38OCAjgokWLsp2dHbu4uHDJkiX5vffe488//9zg3Zq8vMOn9HoXlLprGzhwoKis3bp1M0tZcwpNumCQbhAQFxdn7SKBhWBfvyXV9O3p6clqtdraRQMJZcqU0ewnU/vqFmSFtd7M+b/uycnJgj7l2dPOnTutWi406QIAaOnZs6doQNj4+Hjav3+/lUoE+iQnJ2veNuLi4iI5rI4SFdZ6ExWMuu/Zs0c0pFWRIkX0jrWrBAj4AKDAcXV1peHDh4uWL1682AqlAUMOHDigGc+0bt26ZGdnZ+US5Y3CWm+iglF3qXPFxx9/bFJ//4IGAR8AFEiff/656DVrly5dolOnTlmnQCDpp59+0vwtNcCzUhXWehPl/7qHhISI3sjh4OCQqzdzFQQI+ACgQCpdujSNGjVKtHzy5MmiJ+/AOg4cOKB5RZuLi4usp/6VoLDWmyj/1z0rK0ty9I2xY8fmy6Znc0LABwAF1vTp00VDNVy6dIm2b99upRJBtpcvXwpeNffNN9+Qr6+vFUuUNwprvYkKRt23bNkielWoj48PTZs2zUolyjv5r2EdAEAmb29vWrBgAY0YMUKw/IsvvqAOHTqYNG4XmFexYsUkX0yvdIW13kT5v+4xMTH05ZdfipZ///335OnpaYUS5S3c4QOAAm348OHUtm1bwbKoqCiaMGGClUoEAPnRZ599RtHR0YJl7du3p8GDB1upRHkLAZ8CDBkyhPjtmIrEzIXiSqWwwr6Wlj1ivva0adMmaxcLAPKRX375RXSeCAkJsXax8gwCPgAAAACFQ8AHAAAAoHAI+AAAAAAUDgEfAAAAgMIh4AMAAABQOAR8AAAAAAqHgA8AAABA4RDwAQAAACgcAj4AAAAAhUPABwAAAKBwCPgAAAAAFA4BHwAAAIDCIeADAAAAUDgEfAAAAAAKh4APAAAAQOEQ8AEAAAAoHAI+AAAAAIVDwAcAAACgcAj4AAAAABQOAR8AAACAwiHgAwAAAFA4BHwAAAAACoeADwAAAEDhEPABAAAAKBwCPgAAAACFQ8AHAAAAoHAI+AAAAAAUDgEfAAAAgMIh4AMAAABQOAR8AAAAAAqHgA8AAABA4RDwAQAAACgcAj4AAAAAhbMzZ2ZHjx6lhIQEc2YJAAAAUChYMoYya8D3xx9/0B9//GHOLAEAAAAgl9CkCwAAAKBwCPgAAAAAFA4BHwAAAIDCIeADAAAAUDgEfAAAAAAKJ+sp3YCAAPr+++8tXRYAAAAAMEGjRo1kpVMxM1u4LAAAAABgRWjSBQAAAFA4BHwAAAAACoeADwAAAEDhEPABAAAAKBwCPgAAAACFQ8AHAAAAoHAI+AAAAAAUDgEfAAAAgMIh4AMAAABQODsimm/tQgAAAACA5fw/2dAh8MMWasEAAAAASUVORK5CYII=\n","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Pytorch","metadata":{}},{"cell_type":"markdown","source":"#### Test 2: PyTorch","metadata":{}},{"cell_type":"code","source":"# Necessary Library\n!pip install torchinfo     # For Pytorch - summarizing and visualizing PyTorch models\n!pip install torchsummary  # For Pytorch - summarizing and visualizing PyTorch models\n\nimport torch.nn as nn\nfrom torchinfo import summary\n\n# Define Model\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super(SimpleModel, self).__init__()\n        # Additional layers can be added here if needed\n\n    def forward(self, x):\n        # Since we're just passing the input to output, we can return x directly, here x is dynamic can take any\n        return x\n\n# Initialize the Model\nmodel = SimpleModel()\n\n# Print the model Summary using TorchSummary\nsummary(model,(3, 32, 32))  # (Channel, hights, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:04:53.280775Z","iopub.execute_input":"2025-01-25T13:04:53.281051Z","iopub.status.idle":"2025-01-25T13:05:05.801139Z","shell.execute_reply.started":"2025-01-25T13:04:53.281027Z","shell.execute_reply":"2025-01-25T13:05:05.799838Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\nRequirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSimpleModel                              [3, 32, 32]               --\n==========================================================================================\nTotal params: 0\nTrainable params: 0\nNon-trainable params: 0\nTotal mult-adds (M): 0\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.01\n=========================================================================================="},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"#### Notes- Pytorch","metadata":{}},{"cell_type":"markdown","source":"**Notes**\n- Class File (OPP) is every essential for PyTorch\n- `__init__:` This is the constructor method where you can define layers or components of the model. Currently, it's empty, but you can add layers if needed.\n- `forward:` This method defines the forward pass of the model. Here, we're simply returning the input x as the output without any modifications. This is a placeholder, and you can add more complex operations if required.\n\n**Shape**\n- When we practice we try to use `Even` shape instead `Odd` number like 256x256, 512x512, 1024x2024, 512x768, 340x512 ect.\n- We use this Even Numbers, so that we can `downsampling` this and get anomther Even Numbers (Q. Why use Even Number), its  for Processing efficiency!\n\n**TensforFlow vs PyTorch**\n- TensorFlow is easy practice over PyTorch Applicatioin","metadata":{}},{"cell_type":"markdown","source":"#### Test 2.1 : Excercise","metadata":{}},{"cell_type":"markdown","source":"- Use 2x2 Kernel\n- Use Conv2D\n- Use Padding","metadata":{}},{"cell_type":"code","source":"#Number of parameters = (N x M x D + 1) x K\n\n# N = M = kernel size\n# D = input channel count\n# K = output filter / channel count\n\n\n\nimage_size = 32        # setting img_size 32x32 pixel\ninputs = layers.Input(shape=(image_size, image_size,3)) # image_size 32x32 pixel with 3 channel(RGB)\nd1 = (inputs)  # input passed in d1 var\n\nd1 = Conv2D(10, kernel_size=(2,2), padding='same')(d1)      # Simple Conv ops with 10 filters applied on d1 and saved in d1\n\nclass_model = Model(inputs = inputs, outputs= d1)  # finally d1 send to output layer\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:05.802385Z","iopub.execute_input":"2025-01-25T13:05:05.802805Z","iopub.status.idle":"2025-01-25T13:05:05.895897Z","shell.execute_reply.started":"2025-01-25T13:05:05.802763Z","shell.execute_reply":"2025-01-25T13:05:05.894909Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │             \u001b[38;5;34m130\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"### Explain","metadata":{}},{"cell_type":"markdown","source":"**Notes**\n- input : 32, 32, 3 which passed to next layer with 10 filters so 32,32,10\n- `Conv`: This line applies a 2D convolutional layer to d1. The Conv2D layer has 10 filters with a kernel size of (2, 2). The padding='same' ensures that the output has the same spatial dimensions as the input.\n\n\n**How to get 130 Parameters ?**\n\n- Kernel Size: (2, 2)\n- Input Channels: 3 (since the input image has 3 channels: RGB)\n- Number of Filters: 10\n- Bias: 1 (a bias term for each filter)\n\n**Calculation**:\n\n1. Kernel Parameters per Filter:\n   Kernel Parameters =`Kernel Height × Kernel Width × Input Channels = 2 x 2 x 3 = 12`\n   \n2. Add Bias:\n   Total Parameters per Filter = `Kernel Parameters + Bias  = 12 + 1 = 13`\n\n3. Total Parameters for All Filters\n   Total Parameters = `Total Parameters per Filter × Number of Filters  13 x 10 = 130`\n\n\nTherefore, the total number of parameters for the `Conv2D` layer is `130`.\nBreaking it down, `each filter has 12 weights` for the kernel and `1 bias term`, and since you have 10 filters, you multiply the total parameters per filter by the number of filters to get 130 parameters.\n\n\n**Calculation Example 2**\n\nNumber of Parameters = (𝑁×𝑀×𝐷+1)×𝐾\n\n- N: Kernel Height\n- M: Kernel Width\n- D: Number of Input Channels (Depth of the input)\n- K: Number of Filters (Output channels)\n- 1: Bias term for each filter\n  \n**Given your parameters:**\n\n- N = 2 (Kernel Height)\n- M = 2 (Kernel Width)\n- D = 3 (Number of Input Channels, as the input image has 3 channels: RGB)\n- K = 10 (Number of Filters)\n\n\n1. Calculate Kernel Parameters Per Filter:\n\n     𝑁×𝑀×𝐷=2×2×3=12\n\n2. Add the Bias Term:\n\n    Kernel Parameters +1=12+1=13\n\n\n3. Calculate Total Parameters:\n\n    Number of Parameters =13×𝐾=13×10=130\n\nSo, by using the formula:Number of Parameters=(2×2×3+1)×10=(12+1)×10=13×10=130\n\n","metadata":{}},{"cell_type":"markdown","source":"### Excercise - 3","metadata":{}},{"cell_type":"code","source":"# Define your model\nclass ConvModel(nn.Module):\n    def __init__(self):\n        super(ConvModel, self).__init__()\n        # Define a convolutional layer with 10 filters, 2x2 kernel size, and 'same' padding\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(2, 2), padding='same')\n\n    def forward(self, x):\n        # Apply the convolutional layer\n        x = self.conv1(x)\n        return x\n\n# Initialize the model \nmodel = ConvModel()\n\n# Print model summary using torchsummary\nsummary(model, input_size=(3, 32, 32))  # (channels, height, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:05.897201Z","iopub.execute_input":"2025-01-25T13:05:05.897627Z","iopub.status.idle":"2025-01-25T13:05:05.959787Z","shell.execute_reply.started":"2025-01-25T13:05:05.897583Z","shell.execute_reply":"2025-01-25T13:05:05.958506Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nConvModel                                [10, 32, 32]              --\n├─Conv2d: 1-1                            [10, 32, 32]              130\n==========================================================================================\nTotal params: 130\nTrainable params: 130\nNon-trainable params: 0\nTotal mult-adds (M): 0.04\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.08\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.09\n=========================================================================================="},"metadata":{}}],"execution_count":7},{"cell_type":"markdown","source":"## Text 3: PyTorch Application","metadata":{}},{"cell_type":"code","source":"# Test 1\n# Define your model\nclass ConvModel(nn.Module):\n    def __init__(self):\n        super(ConvModel, self).__init__()\n        # Define a convolutional layer with 10 filters, 2x2 kernel size, and 'same' padding           # 10 Filters/ 10 Different Features\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(2, 2), padding='same')\n\n    def forward(self, x):\n        # Apply the convolutional layer\n        x = self.conv1(x)\n        return x\n\n# Initialize the model\nmodel = ConvModel()\n\n# Print model summary using torchsummary\nsummary(model, input_size=(3, 32, 32))  # (channels, height, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:05.960946Z","iopub.execute_input":"2025-01-25T13:05:05.961400Z","iopub.status.idle":"2025-01-25T13:05:05.972266Z","shell.execute_reply.started":"2025-01-25T13:05:05.961316Z","shell.execute_reply":"2025-01-25T13:05:05.971171Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nConvModel                                [10, 32, 32]              --\n├─Conv2d: 1-1                            [10, 32, 32]              130\n==========================================================================================\nTotal params: 130\nTrainable params: 130\nNon-trainable params: 0\nTotal mult-adds (M): 0.04\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.08\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.09\n=========================================================================================="},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"#### Weights","metadata":{}},{"cell_type":"code","source":"# Instructor will discuss later on this(weights)\nwt = class_model.get_weights()  # retrieving the weights of all the layers in the model.get_weights() will return a list of NumPy arrays\nlen(wt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:05.973358Z","iopub.execute_input":"2025-01-25T13:05:05.973716Z","iopub.status.idle":"2025-01-25T13:05:05.998706Z","shell.execute_reply.started":"2025-01-25T13:05:05.973678Z","shell.execute_reply":"2025-01-25T13:05:05.997684Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Model A (using TensorFlow/Keras)\n\ninputs = layers.Input(shape=(image_size,image_size,3))     # Define input of the model with 3 channel\nd1 =  (inputs)\n\nd1 = Conv2D(5 ,kernel_size=(3,3), padding='same', activation='gelu')(d1)            # Added a 2D Conv layers with 5  filters each of size is (3,3)\nd1 = Activation('gelu')(d1)         # Defining this optiona here when pass above after padding\n\nclass_model = Model(inputs = inputs, outputs = d1)\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.000097Z","iopub.execute_input":"2025-01-25T13:05:06.000538Z","iopub.status.idle":"2025-01-25T13:05:06.038190Z","shell.execute_reply.started":"2025-01-25T13:05:06.000494Z","shell.execute_reply":"2025-01-25T13:05:06.036863Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │             \u001b[38;5;34m140\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m140\u001b[0m (560.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> (560.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m140\u001b[0m (560.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> (560.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":10},{"cell_type":"markdown","source":"#### Notes","metadata":{}},{"cell_type":"markdown","source":"- `The padding='same'` ensures that the output size is the same as the input size. The activation function used here is gelu (Gaussian Error Linear Unit)\n- `class_model = Model(inputs = inputs, outputs = d1)` : This creates the model by specifying the input and output layers. This prints a summary of the model, showing the layers and the number of parameters.\n- No Parameter in Activations Layer\n\n**Entire Network Consist of:**\n- An input layer for the images.\n- A convolutional layer to extract features from the images using a `gelu` activation function.\n- The model is built and summarized.\n\n**Parameters Calcuation**\n\n`Number of parameters=(Kernel width×Kernel height×Number of input channels+Bias term)×Number of filter`\n\n- Kernel size = 3x3\n- Channels = 3\n- Number of Filter = 5\n\n**Working**\n\n- So, Kernel Width: 3 and Height 3\n- Number of input Channels : 3\n- Bias Term 1 (Each Filter has one bias Term)\n- Number of Filter : 5\n\nSo, As per Formula, total parameter will be:\n\n`(3 x 3 x 3 + 1)\n= 27 + 1\n= 28`\n  \nSo, the filter has `28 parameters`.\nSince there are 5 filters so, the total number of parameters is:\n\n`28 (Parameters Per Filter) x 5 (Number of Filter)`\n`= 140`\n\nTherefore, the Conv2D layer has 140 parameters in total.\n\n","metadata":{}},{"cell_type":"code","source":"# Model B (using PyTorch)\nclass ConvGELUModel(nn.Module): \n    def __init__(self):\n        super(ConvGELUModel, self).__init__()\n        # Define a convolutional layer with 5 filters, 3x3 kernel size, and 'same' padding\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels=5, kernel_size=(3, 3), padding='same')\n        # Define the GELU activation function\n        self.gelu = nn.GELU()\n\n    def forward(self,x):\n        # Apply the convolutional layer followed by GELU activation\n        x = self.conv1(x)\n        x = self.gelu(x)\n        return x\n\n# Initialize the model\nmodel = ConvGELUModel()\n\n# Print model summary using torchsummary\nsummary(model, input_shape=(3, 32, 32))  # (channels, height, width)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.041258Z","iopub.execute_input":"2025-01-25T13:05:06.041659Z","iopub.status.idle":"2025-01-25T13:05:06.053864Z","shell.execute_reply.started":"2025-01-25T13:05:06.041601Z","shell.execute_reply":"2025-01-25T13:05:06.052814Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nConvGELUModel                            --\n├─Conv2d: 1-1                            140\n├─GELU: 1-2                              --\n=================================================================\nTotal params: 140\nTrainable params: 140\nNon-trainable params: 0\n================================================================="},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"### Explanation","metadata":{}},{"cell_type":"markdown","source":"**Initialization (__init__ method):**\n\n`super(ConvGELUModel, self).__init__():` Calls the initializer of the parent class `nn.Module`. This is necessary to properly initialize the model.\n\n`self.conv1 = nn.Conv2d(...):` Defines a 2D convolutional layer. It takes in 3 input channels (e.g., RGB color channels), and outputs 5 feature maps (filters). The kernel size is (3, 3), meaning the convolutional filter has dimensions of 3x3. The padding is set to 'same', which means the output size will be the same as the input size.\n\n**Forward Pass (forward method):**\n\n`x = self.conv1(x):` Applies the convolutional layer to the input tensor x.\n\n`x = self.gelu(x):` Applies the GELU (Gaussian Error Linear Unit) activation function to the output of the convolutional layer.\n\nThe GELU activation function is a smoother alternative to ReLU (Rectified Linear Unit) and can be beneficial for certain types of data and tasks.\n\n**Model Summary:**\n\n`model = ConvGELUModel():` Initializes an instance of the ConvGELUModel.\n\n`summary(model, input_shape=(3, 32, 32)):` Prints a summary of the model's architecture, using the torchsummary package. The input shape is specified as (3, 32, 32), which means the model expects an input with 3 channels and spatial dimensions 32x32 (like a 32x32 RGB image).","metadata":{}},{"cell_type":"markdown","source":"#### Models Comperasion (Model A Vs Model B) Tensorflow & PyTorch","metadata":{}},{"cell_type":"markdown","source":"**Model A: TensorFlow**\n\n**Framework**\nTensorFlow/Keras: This model uses the Keras API, which is a high-level neural networks API running on top of TensorFlow.\n\n**Layer Definitions:**\n\n- `inputs = layers.Input(shape=(image_size, image_size, 3)):` Defines the input layer with a shape of (image_size, image_size, 3) (3 channels for RGB images).\n\n- `d1 = Conv2D(5, kernel_size=(3, 3), padding='same', activation='gelu')(d1):` Adds a 2D convolutional layer with 5 filters, a kernel size of (3, 3), 'same' padding, and the GELU activation function directly.\n\n- `d1 = Activation('gelu')(d1):` Applies the GELU activation function. This is optional here as the activation has already been applied in the previous layer.\n\n**Model Definition:**\n\nclass_model = Model(inputs=inputs, outputs=d1): Defines the model by specifying the input and output layers.\n\n\n**Model B (using PyTorch):**\n\n**Framework:**\n\n- PyTorch: This model uses PyTorch, a flexible and efficient deep learning library.\n\n**Layer Definitions:**\n\n- self.conv1 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(3, 3), padding='same'): Defines a 2D convolutional layer with 3 input channels, 5 filters, a kernel size of (3, 3), and 'same' padding.\n\n- self.gelu = nn.GELU(): Defines the GELU activation function.\n\n**Forward Pass:**\n\n- x = self.conv1(x): Applies the convolutional layer to the input tensor x.\n- x = self.gelu(x): Applies the GELU activation function to the output of the convolutional layer.\n\n**Model Summary:**\n\n`model = ConvGELUModel()`: Initializes the model.\n\n`summary(model, input_shape=(3, 32, 32))`: Prints the model summary using the torchsummary package.\n\n\n**Key Differences:**\n\n**Framework:**\n\n- Model A uses TensorFlow/Keras, which is often praised for its high-level API and ease of use.\n\n- Model B uses PyTorch, which is known for its dynamic computation graph and flexibility.\n\n**Model Definition:**\n\n- Model A uses the Model class to define the model by specifying the inputs and outputs.\n\n- Model B defines the model by creating a class that inherits from nn.Module and implements the forward method.\n\n**Syntax and API:**\n\nTensorFlow/Keras and PyTorch have different syntax and API conventions. Model A's code is more declarative, while Model B's code is more imperative.","metadata":{}},{"cell_type":"markdown","source":"## Batch Normalization","metadata":{}},{"cell_type":"code","source":"wt = class_model.get_weights()\nlen(wt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.055866Z","iopub.execute_input":"2025-01-25T13:05:06.056314Z","iopub.status.idle":"2025-01-25T13:05:06.078278Z","shell.execute_reply.started":"2025-01-25T13:05:06.056269Z","shell.execute_reply":"2025-01-25T13:05:06.076638Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# simple Keras model with an input layer, a convolutional layer, and batch normalization\nimage_shape = 32\ninputs = layers.Input(shape=(image_size, image_size,3))\nd1 = (inputs)\n\nd1 = Conv2D(1, kernel_size=(3,3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)  \n\nclass_model = Model(inputs=inputs, outputs=d1)\nclass_model.summary()\n\n\n'''\nTask # 2: \nWhen Apply Batch Normalization, then Total Param 32, Trainable Param 32, Non-Trainable -2. \nFind who are these 2 Non-Trainable Params ?\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.079953Z","iopub.execute_input":"2025-01-25T13:05:06.080636Z","iopub.status.idle":"2025-01-25T13:05:06.142118Z","shell.execute_reply.started":"2025-01-25T13:05:06.080460Z","shell.execute_reply":"2025-01-25T13:05:06.140859Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m28\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m4\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n</pre>\n"},"metadata":{}},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'\\nTask # 2: \\nWhen Apply Batch Normalization, then Total Param 32, Trainable Param 32, Non-Trainable -2. \\nFind who are these 2 Non-Trainable Params ?\\n\\n'"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"#### Explanation","metadata":{}},{"cell_type":"markdown","source":"- `d1 = BatchNormalization()(d1):`This layer normalizes the output of the convolutional layer to improve the training process by stabilizing the learning process and speeding up convergence.\n- `class_model = Model(inputs=inputs, outputs=d1)`: Creates the Keras model by specifying the input and output layers.\n- Here for this model, the total Params are 32 (Conv + Batch) 28 + 4 =32\n- Since BatchNormaization Param are 4, so its has 2 trainable & 2 Non-trainable params inside this normalization layers","metadata":{}},{"cell_type":"code","source":"# Same model, its for testing (Better Readibilty)\n# Batch Normalization with Tensorflow \nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization\n\nimage_size = 32\ninputs = layers.Input(shape=(image_size, image_size, 3))\nd1 = (inputs)\n\nd1 = Conv2D(1, kernel_size=(3, 3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)\n\nclass_model = Model(inputs=inputs, outputs=d1)\nclass_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.143642Z","iopub.execute_input":"2025-01-25T13:05:06.143986Z","iopub.status.idle":"2025-01-25T13:05:06.190452Z","shell.execute_reply.started":"2025-01-25T13:05:06.143957Z","shell.execute_reply":"2025-01-25T13:05:06.189340Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │              \u001b[38;5;34m28\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m4\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"### Layers Explanation","metadata":{}},{"cell_type":"markdown","source":"**Input Layer:**\n\n- Type: `InputLayer`\n\n- Output Shape: `(None, 32, 32, 3)`\n\n- `Param #: 0` (No parameters because it's just the input definition)\n\n**Conv2D Layer:**\n\n- Type: `Conv2D`\n\n- Output Shape: `(None, 32, 32, 1)`\n\n- `Param #: 28` (Trainable parameters)\n\n**Parameter Calculation:**\n\n- Filters: 1\n\n- Kernel Size: (3, 3)\n\n- Input Channels: 3\n\n- Bias Term: 1\n\n- Total Params = (3 * 3 * 3 + 1) * 1 = 28\n\n**Batch Normalization Layer:**\n\n- Type: `BatchNormalization`\n\n- Output Shape: `(None, 32, 32, 1)`\n\n- `Param #: 4` (Total parameters, including both trainable and non-trainable)\n\n**Parameter Calculation:**\n\n**Trainable Parameters:**\n\n- Gamma (scaling factor): 1\n\n- Beta (shifting factor): 1\n\n- Total Trainable Params = 1 + 1 = 2\n\n**Non-Trainable Parameters:**\n\n- Mean: 1\n\n- Moving Variance: 1\n\n- Total Non-Trainable Params = 1 + 1 = 2\n\n**Identifying Non-Trainable Parameters:**\n\nIn the Batch Normalization layer, there are 2 non-trainable parameters: the moving mean and moving variance. These parameters are calculated during the training process and used during inference to normalize the data.\n\n**Summary:**\n\n- Input Layer: No parameters\n\n- Conv2D Layer: 28 trainable parameters\n\n- Batch Normalization Layer: 4 parameters (2 trainable, 2 non-trainable)\n\nSo, the non-trainable parameters in this model are the moving mean and moving variance of the Batch Normalization layer.","metadata":{}},{"cell_type":"markdown","source":"**Moving Mean and Moving Variance:**\n\n**Batch Normalization:**\n\nBatch Normalization is a technique used to improve the training of deep neural networks. It normalizes the inputs of a layer for each mini-batch, thereby reducing internal covariate shift.\n\n**How It Works:**\n\nDuring training, for each mini-batch, Batch Normalization calculates the mean and variance of the inputs.\n\nIt then normalizes the inputs by subtracting the batch mean and dividing by the batch standard deviation.\n\n**Moving Mean and Moving Variance:**\n\nMoving Mean: It's an exponential moving average of the batch means calculated during training.\n\nMoving Variance: It's an exponential moving average of the batch variances calculated during training.\n\nThese moving statistics are updated during each training step to capture the running statistics of the entire training data.\n\n**Why They Are Non-Trainable:**\n\nNon-Trainable Parameters: These parameters are not updated through backpropagation and gradient descent. Instead, they are updated using a moving average formula.\n\nPurpose: The moving mean and variance are used during inference (testing or deployment) to normalize the inputs based on the statistics learned during training. This ensures that the model's behavior is consistent between training and inference.\n\nConsistency: By using moving averages, the normalization can be applied even when a single data point (or a batch of size one) is fed into the network during inference, providing consistent performance.\n\nIn summary, the moving mean and moving variance are essential for maintaining the learned normalization during inference, ensuring the model's performance remains stable and accurate. These parameters are updated during training but are not trainable in the conventional sense—they're not adjusted through gradients but through running averages.","metadata":{}},{"cell_type":"markdown","source":"**Task**\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test : PyTorch\n# Batch Normalization with PyTorch\n\nfrom torchsummary import summary # Torch Summary used to print details Summary\nclass ConvGELUModel(nn.Module): \n    def __init__(self):\n        super(ConvGELUModel, self). __init__()\n        # Define a convolutional layer with 1 filter, 3x3 kernel size, and 'same' padding\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 1, kernel_size=(3,3), padding=1 )  # padding=1 for 'same'\n        # Define the GELU activation function\n        self.gelu = nn.GELU()\n\n        # Define Batch Normalization \n        self.batch_norm = nn.BatchNorm2d(1)  # Here inside 1 mean Channels (Applying on One channel and on EKJON both are correct, Out_channels 1 (ekjon)\n\n\n    def forward(self, x):\n        # Apply the convolutional layer, GELU activation, and Batch Normalization\n        x = self.conv1(x)\n        x = self.gelu(x)\n        x = self.batch_norm(x)\n        return x\n\n# Initialize the model\nmodel = ConvGELUModel()  \n\n# Print model summary using torchsummary\nsummary(model, input_size=(3, 32, 32))  # (channels, height, width)  Shows 1,32,32 instead of 32,32,3 due to out_channels=1 defined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.191613Z","iopub.execute_input":"2025-01-25T13:05:06.192058Z","iopub.status.idle":"2025-01-25T13:05:06.329089Z","shell.execute_reply.started":"2025-01-25T13:05:06.192015Z","shell.execute_reply":"2025-01-25T13:05:06.327707Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 1, 32, 32]              28\n              GELU-2            [-1, 1, 32, 32]               0\n       BatchNorm2d-3            [-1, 1, 32, 32]               2\n================================================================\nTotal params: 30\nTrainable params: 30\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.02\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.04\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"## Explanation","metadata":{}},{"cell_type":"markdown","source":"\n`[-1, 1, 32, 32]`\n- `-1`: The -1 is used as a placeholder indicating that this dimension will be dynamically determined based on the number of samples in your input data batch during runtime. Batch size (number of samples in the batch).\n- `1`: Number of channels (e.g., grayscale images have 1 channel, RGB images have 3 channels).\n- `32, 32`: Height and width of the feature map (spatial dimensions).\n- `Using -1` allows the network to process variable-sized batches of input data efficiently.\n\n**Code Part- Class**\n\n`class ConvGELUModel(nn.Module):\n\n    def __init__(self):\n    \n        super(ConvGELUModel, self). __init__()`\n\n**Explanation:**\n\nfrom torchsummary import summary: This line imports the summary function from the torchsummary library, which is often used to print a detailed summary of a PyTorch model, including the output shapes and the number of parameters for each layer.\n\nclass `ConvGELUModel(nn.Module)`:: This line defines a new class `ConvGELUModel` that inherits from nn.Module. In PyTorch, nn.Module is the base class for all neural network modules, and your custom model class should inherit from it.\n\n`def __init__(self)`:: This is the constructor method for the `ConvGELUModel` class. It's called when an object of the class is created. In this method, you typically define the layers and parameters of your model.\n\n`super(ConvGELUModel, self).__init__()`: This line calls the constructor of the parent class (nn.Module). The super() function is used to give your class access to methods and properties of the parent class. In this case, it initializes the nn.Module class, which is essential for PyTorch models to work correctly.\n","metadata":{}},{"cell_type":"markdown","source":"** self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 1, kernel_size=(3,3), padding=1 )  # padding=1 for 'same'\n\n\nThe line self.conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=(3,3), padding=1) defines a 2D convolutional layer in your neural network. Let's break down what each part of this line does:\n\nExplanation:\nself.conv1:\n\nThis creates an instance variable conv1 for your class. The self keyword is used to refer to the instance of the class itself.\n\nnn.Conv2d:\n\nThis is a built-in PyTorch class for creating a 2D convolutional layer. Convolutional layers are used in neural networks to process image data by applying convolution operations to the input.\n\nin_channels=3:\n\nSpecifies the number of input channels to the convolutional layer. If you are working with RGB images, the number of input channels is 3 (since an RGB image has three color channels: red, green, and blue).\n\nout_channels=1:\n\nSpecifies the number of output channels produced by the convolutional layer. In this case, it will produce a single output channel. This is useful if you want to reduce the number of channels, for example, to convert an RGB image to a grayscale image.\n\nkernel_size=(3,3):\n\nSpecifies the size of the convolutional kernel (also called a filter). A (3,3) kernel means that the filter is 3x3 pixels. This kernel will slide over the input image to compute the convolution.\n\npadding=1:\n\nSpecifies the amount of zero-padding added to the edges of the input image. Padding helps maintain the spatial dimensions (height and width) of the input image after convolution. In this case, a padding of 1 will keep the output image size the same as the input image size.\n\nWhy Use self.conv1:\nUsing self.conv1 (or any instance variable) to define layers in the __init__ method allows these layers to be part of the class instance. This ensures that the layers are properly managed by PyTorch’s framework, including weight initialization, gradient computation, and updating during the training process.\n\n**Batch Normalization2D**\n\n- `Input: (N,C,H,W)`                \n- `Outpur: (N,C,H,W) same as Input`\n-  `self.batch_norm = nn.BatchNorm2d(1):` 1 Means Applying on Channel (C)\n\n**Q.Why & How Channel Reduce from 32,32,3 to 32,32,1?**\n\n- Becasue Output channels is 1, so output shows as `32,32,1` instead of `32,32,3`\n- Whatever the operation it will apply on One","metadata":{}},{"cell_type":"markdown","source":"\n\n\n","metadata":{}},{"cell_type":"markdown","source":"### Batch Normalization (Test 2)","metadata":{}},{"cell_type":"code","source":"'''\nwt1 = list()\n\nfor i in range(len(wt)):\n   wt1.append(K.sigmoid(wt[i]))\n\nf1 = 0\nprint(wt[f1][0][0], wt1[f1][0][0])\nclass_model.set_weights(wt1)\n\nwt2 = class_model.get_weights()\n\nprint(wt2[f1][0][0], wt1[f1][0][0])\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.330369Z","iopub.execute_input":"2025-01-25T13:05:06.330713Z","iopub.status.idle":"2025-01-25T13:05:06.337328Z","shell.execute_reply.started":"2025-01-25T13:05:06.330682Z","shell.execute_reply":"2025-01-25T13:05:06.336087Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"'\\nwt1 = list()\\n\\nfor i in range(len(wt)):\\n   wt1.append(K.sigmoid(wt[i]))\\n\\nf1 = 0\\nprint(wt[f1][0][0], wt1[f1][0][0])\\nclass_model.set_weights(wt1)\\n\\nwt2 = class_model.get_weights()\\n\\nprint(wt2[f1][0][0], wt1[f1][0][0])\\n\\n'"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# Test 2.1 (TF Application)\n\nimage_size = 32\ninputs = layers.Input(shape=(image_size, image_size, 3))\nd1 = (inputs)\n\nd1 = Conv2D(5, kernel_size=(3,3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)      # Here Channel not mentioned, becuase TF/Keras by default make sure operation on LAST ON (Channel); whereas PyTorch alwasy keep channel at first (Allow Customization)\nd1 = MaxPool2D()(d1)             # Pooling reduce the dimenstion from 32 to 16\n\nclass_model = Model(inputs= inputs, outputs = d1)\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.338399Z","iopub.execute_input":"2025-01-25T13:05:06.338781Z","iopub.status.idle":"2025-01-25T13:05:06.403632Z","shell.execute_reply.started":"2025-01-25T13:05:06.338741Z","shell.execute_reply":"2025-01-25T13:05:06.402637Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │             \u001b[38;5;34m140\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │              \u001b[38;5;34m20\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m150\u001b[0m (600.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> (600.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"### Explanation","metadata":{}},{"cell_type":"markdown","source":"**Pooling**\n\n- Reduce the Dimenstion, in this layer there is no Trainable Parameters\n- See the Output Shape, its always recommended to take `Even` Numbers like 32,32, 16,16 (Half of 32,32)\n- In Batch Normalization, we would get 17,17 (This would Odd) if preceeding layer would have 34,34, So, its recommended take 2^ / 2 the power values","metadata":{}},{"cell_type":"code","source":"# Test 2.1 (PyTorch Application) Same This with PyTorch Application\n\nclass ConvGELUBNMaxPoolModel(nn.Module):\n    def __init__(self):\n        super(ConvGELUBNMaxPoolModel, self).__init__()\n        # Define the convolutional layer\n        self.conv1 = nn.Conv2d(in_channels =3, out_channels=5, kernel_size=(3,3), padding=1) # 'same' padding\n        # Define the GELU activation function\n        self.gelu = nn.GELU()\n        # Define Batch Normalization\n        self.batch_norm = nn.BatchNorm2d(5)\n        # Define Max Pooling\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n\n    def forward(self, x):\n        # Apply the convolutional layer, GELU activation, Batch Normalization, and Max Pooling\n        x = self.conv1(x)\n        x = self.gelu(x)\n        x = self.batch_norm(x)\n        x = self.max_pool(x)\n        return x\n\n# Initialization Model\nmodel = ConvGELUBNMaxPoolModel()\n\n# Print model summary using torchsummary\nsummary(model, input_size=(3, 32,32))  # (channels, height, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.404765Z","iopub.execute_input":"2025-01-25T13:05:06.405174Z","iopub.status.idle":"2025-01-25T13:05:06.431045Z","shell.execute_reply.started":"2025-01-25T13:05:06.405133Z","shell.execute_reply":"2025-01-25T13:05:06.429648Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 5, 32, 32]             140\n              GELU-2            [-1, 5, 32, 32]               0\n       BatchNorm2d-3            [-1, 5, 32, 32]              10\n         MaxPool2d-4            [-1, 5, 16, 16]               0\n================================================================\nTotal params: 150\nTrainable params: 150\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.13\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.14\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"### Explanation","metadata":{}},{"cell_type":"markdown","source":"-- 2.1 Both are same Code, but for one it has 160 and for another it has 150, why ?","metadata":{}},{"cell_type":"markdown","source":"**Mathmatical Equation Or Model**\n\nI = input, O = output,\nC = Conv,\nA = Activation,\nN = Normalization,\nP = Pooling \\/\n\n1. I -  O\n\n2. I - C -  O\n\n3. I - C - A -  O\n\n4. I - C - A - N -  O\n\n5. I - C - A - N - P -  O\n\n6. I - C - A - N - P - C - A - N - P - C - A - N - P -  O           # 3 CANP BETWEEN I & O\n\nInside Input & Output it has number of CANP","metadata":{}},{"cell_type":"markdown","source":"## <font color=RoyalBlue> CANP Operation by TensorFlow<font>","metadata":{}},{"cell_type":"code","source":"# TensorFlow Operaitons\n# Equation Number 6: I - C - A - N - P - C - A - N - P - C - A - N - P - O\n\n# Input\nimage_size = 32\ninputs = layers.Input(shape=(image_size,image_size,3))\nd1 =  (inputs)\n\n# CANP1\nd1 = Conv2D(5 ,kernel_size=(3,3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)\nd1 = MaxPool2D()(d1)\n\n\n# CANP2\nd1 = Conv2D(5 ,kernel_size=(3,3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)\nd1 = MaxPool2D()(d1)\n\n\n# CANP3\nd1 = Conv2D(5 ,kernel_size=(3,3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)\nd1 = MaxPool2D()(d1)\n\n\n# Output-d1\nclass_model = Model(inputs = inputs, outputs = d1)\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.432282Z","iopub.execute_input":"2025-01-25T13:05:06.432627Z","iopub.status.idle":"2025-01-25T13:05:06.532862Z","shell.execute_reply.started":"2025-01-25T13:05:06.432587Z","shell.execute_reply":"2025-01-25T13:05:06.531632Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_6\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │             \u001b[38;5;34m140\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │              \u001b[38;5;34m20\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │             \u001b[38;5;34m230\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           │              \u001b[38;5;34m20\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             │             \u001b[38;5;34m230\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             │              \u001b[38;5;34m20\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m5\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m660\u001b[0m (2.58 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> (2.58 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m630\u001b[0m (2.46 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">630</span> (2.46 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"## Explation","metadata":{}},{"cell_type":"markdown","source":"**Layers**\n\n- Layers 32 > 8 > 4 ( Continous DownSampling )\n","metadata":{}},{"cell_type":"markdown","source":"## <font color=RoyalBlue> CANP Operations by PyTorch <font>","metadata":{}},{"cell_type":"code","source":"# PyTorch Operaitons\n# Equation Number 6: I - C - A - N - P - C - A - N - P - C - A - N - P - O\n\n# Define your model\n\nclass ConvGELUBNMaxPoolModel(nn.Module): \n    def __init__(self):\n        super(ConvGELUBNMaxPoolModel, self).__init__()  # Confirmation all facilites of the class from nn.Module all for this ops\n        \n        # Define the First Convolution block\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(3, 3), padding=1), # 'same' padding\n            nn.GELU(),\n            nn.BatchNorm2d(5),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        # Sequence + Cov + Activation + Normalization + Pooling\n\n        # Define the Second convolutional block\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(in_channels=5, out_channels=5, kernel_size=(3,3), padding=1),   # Kernel  or Filter\n            nn.GELU(),\n            nn.BatchNorm2d(5),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        # Define the Third Convoluation Block\n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(in_channels=5, out_channels=5, kernel_size=(3,3), padding=1),\n            nn.GELU(),\n            nn.BatchNorm2d(5),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n    # Forward\n    def forward(self, x):\n        # Pass the input through the three convolutional blocks\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        return x\n\n# Initialize the model\nmodel = ConvGELUBNMaxPoolModel()      # This model took all input by the above forward pass\n\n# Print model summary using torchsummary        \nsummary(model, input_size=(3, 32, 32))   # (channels, height, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.534101Z","iopub.execute_input":"2025-01-25T13:05:06.534515Z","iopub.status.idle":"2025-01-25T13:05:06.560904Z","shell.execute_reply.started":"2025-01-25T13:05:06.534476Z","shell.execute_reply":"2025-01-25T13:05:06.559447Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 5, 32, 32]             140\n              GELU-2            [-1, 5, 32, 32]               0\n       BatchNorm2d-3            [-1, 5, 32, 32]              10\n         MaxPool2d-4            [-1, 5, 16, 16]               0\n            Conv2d-5            [-1, 5, 16, 16]             230\n              GELU-6            [-1, 5, 16, 16]               0\n       BatchNorm2d-7            [-1, 5, 16, 16]              10\n         MaxPool2d-8              [-1, 5, 8, 8]               0\n            Conv2d-9              [-1, 5, 8, 8]             230\n             GELU-10              [-1, 5, 8, 8]               0\n      BatchNorm2d-11              [-1, 5, 8, 8]              10\n        MaxPool2d-12              [-1, 5, 4, 4]               0\n================================================================\nTotal params: 630\nTrainable params: 630\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.17\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.18\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"**Question**\n\n- Q1.What are the params inside block? A. Input,output, kernel, padding\n- Q2. What are params in Pooling ? A: Kernel & Stride\n- Q3. Component of Block(s) Define : `Sequence + Cov + Activation + Normalization + Pooling`\n- Q4. Is Kernel and Filter is same ? Ans: Yes\n- Q5. What refer  by Padding 1 ? A: Its ensure that `output` will be same as `Input` size\n- Q6. What the Function of `GELU` ? Ans: It introduces non-linearity to the network, which helps in learning complex pattern\n- Q7. What is the contribution of BatchNorm ? Ans. Normalizes the output of the previous layer (5 feature maps) to improve the training stability and performance\n- Use of `Kernel_size` in maxpooling ? Its the size of `Pooling Window` is `2X2`\n- `Stide=2`: The window moves 2 steps at a time. This effectively downsamples the feature maps by a factor of 2, reducing their spatial dimensions\n\n**BatchNormalization**\n\n- Q8. Why `BatchNorm2d(5)`: Ans: BatchNorm2d must the `same number of output Channels` Since you defined the number of output channels as 5 in the convolutional layer, you also need the batch normalization to handle the same number of channels.\n- The purpose of this batch normalization is to standardize the outputs of the convolutional layer by adjusting and scaling the activations\n- This can help:\n  - Accelerate training by allowing the network to converge faster\n  - Improve generalization by reducing the risk of overfitting\n  - Ensure stable distributions of layer inputs, which can make the training process more robust\n  - The BatchNorm2d(5) line in your code indicates that batch normalization is being applied to five feature maps. This value of 5 matches the number of output channels defined in the convolutional layer `(nn.Conv2d(in_channels=5, out_channels=5, ...))`. Essentially, each output channel from the convolutional layer is normalized independently by the batch normalization layer\n  - Q9. What is the funnction of MaxPooling ? `Ans`: is helps for `Downsampling`\n\n\n**Model Architecture-Pytorch**\n\n- Class Define with nn Module\n- Constructor & Super Confirmation\n- Convolution Block(s) Design (Here we used 3 Block)\n- Forward Pass\n  - Pass Input(x) through all created block\n  - Return input(x)\n- Initializet the Model\n  - All forwarding will be initialized here\n- Print Summary of the Model","metadata":{}},{"cell_type":"markdown","source":"**Output Explanation**\n\n- `Conv2d-1:` The input shape is transformed to `[batch_size, 5, 32, 32].` This means the output of this layer will have 5 channels and the spatial dimensions (height and width) are both 32.\n- `GELU-2:` This is an activation layer, which does not change the shape of the input. So, the output shape remains `[batch_size, 5, 32, 32].`\n- `BatchNorm2d-3:` This layer also does not change the shape of the input. Thus, the output remains `[batch_size, 5, 32, 32].`\n- `MaxPool2d-4:` This layer performs downsampling, reducing the spatial dimensions by a factor of 2. The output shape is `[batch_size, 5, 16, 16]`\n- `Conv2d-5:` The output shape is `[batch_size, 5, 16, 16]`. The number of channels remains 5, and the spatial dimensions do not change.\n- `GELU-6:` This activation layer doesn't change the shape, so it remains `[batch_size, 5, 16, 16]`\n- `BatchNorm2d-7:` This also doesn't change the shape, so the output shape is `[batch_size, 5, 16, 16]`\n- `MaxPool2d-8:` Again, this layer downsamples by a factor of 2, resulting in an output shape of `[batch_size, 5, 8, 8]`\n- `Conv2d-9:` The output shape remains `[batch_size, 5, 8, 8]` as the number of channels remains 5 and the spatial dimensions do not change\n- `GELU-10:` This activation layer does not change the shape, so it remains `[batch_size, 5, 8, 8]`\n- `BatchNorm2d-11:` This layer does not change the shape, so the output remains `[batch_size, 5, 8, 8]`\n- `MaxPool2d-12:` Finally, this layer performs downsampling by a factor of 2, resulting in an output shape of `[batch_size, 5, 4, 4]`\n\n**Summary**\n\nSo, in summary, the shape transformation through the layers are as follows\n\n- Start with `[batch_size, 5, 32, 32]`\n- Downsampled to `[batch_size, 5, 16, 16]`\n- Downsampled again to `[batch_size, 5, 8, 8]`\n- Finally, downsampled to `[batch_size, 5, 4, 4]`\n\n**Question**\n\n- Q1. How you get total 230 param ? `A`: if you summ total params then you will get `230 Params`\n- Q2. As per output total oversavtion is 12,you see at every 4th rows, Pooling / downsampling Applied","metadata":{}},{"cell_type":"markdown","source":"## Exclusive Notes","metadata":{}},{"cell_type":"markdown","source":"- Need to Know details of each layers\n- 1.21 mins(1.43)","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Tasks","metadata":{}},{"cell_type":"markdown","source":"- `Task1`: Explain the Parameter Calcuation Formula\n- `Task2`: Find Who are those Two Non-trainable Param ?\n  - Difference between Batch Norm by pytorch & tf (PyTorch 30 whereas TF-32) ?\n","metadata":{}},{"cell_type":"code","source":"2+2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.562096Z","iopub.execute_input":"2025-01-25T13:05:06.562560Z","iopub.status.idle":"2025-01-25T13:05:06.569148Z","shell.execute_reply.started":"2025-01-25T13:05:06.562526Z","shell.execute_reply":"2025-01-25T13:05:06.568038Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"4"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"### Ref","metadata":{}},{"cell_type":"markdown","source":"1. https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Additional Test","metadata":{}},{"cell_type":"code","source":"# Excercise 1\n\nimport torch\nimport torch.nn as nn\nfrom torchsummary import summary\n\nclass ConvGELUModel(nn.Module):\n    def __init__(self):\n        super(ConvGELUModel, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n        self.gelu = nn.GELU()\n        self.bn1 = nn.BatchNorm2d(32)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n    def forward(self, x):\n        x = self.pool(self.bn1(self.gelu(self.conv1(x))))\n        return x\n\n# Creating an instance of the model\nmodel = ConvGELUModel()\n# Printing the model summary\nsummary(model, input_size=(1, 32, 32))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-25T13:05:06.570509Z","iopub.execute_input":"2025-01-25T13:05:06.570803Z","iopub.status.idle":"2025-01-25T13:05:06.598723Z","shell.execute_reply.started":"2025-01-25T13:05:06.570776Z","shell.execute_reply":"2025-01-25T13:05:06.597285Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 32, 32, 32]             320\n              GELU-2           [-1, 32, 32, 32]               0\n       BatchNorm2d-3           [-1, 32, 32, 32]              64\n         MaxPool2d-4           [-1, 32, 16, 16]               0\n================================================================\nTotal params: 384\nTrainable params: 384\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.81\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.82\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":22}]}