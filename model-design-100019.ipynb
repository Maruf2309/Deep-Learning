{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## CV-Module 21 (Model Design)","metadata":{}},{"cell_type":"markdown","source":"**100019**","metadata":{}},{"cell_type":"code","source":"!pip install einops\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport tqdm, time, copy\nimport heapq\nimport datetime\nimport glob\nimport random,time\n\nimport math, random\n\nfrom functools import partial\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import *  # * means all the things included in tf & keras all be imported at a time\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.utils import *\nfrom tensorflow.keras.regularizers import *\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport einops\nfrom einops import*\nimport pathlib\nimport itertools\nfrom keras.layers import Lambda\nimport warnings as wr\nwr.filterwarnings('ignore')\n\n\n\nimport random\nfrom tensorflow import (abs,cast,clip_by_value,concat,convert_to_tensor,\n    expand_dims, gather,gather_nd,linspace, map_fn,matmul,norm,pad,\n    print,range,repeat,reshape,shape,sign,split,squeeze,stack,tensor_scatter_nd_update,tile,transpose,unstack,zeros,\n)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:04.696616Z","iopub.execute_input":"2025-01-31T02:38:04.697087Z","iopub.status.idle":"2025-01-31T02:38:08.590188Z","shell.execute_reply.started":"2025-01-31T02:38:04.697048Z","shell.execute_reply":"2025-01-31T02:38:08.588609Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#Number of parameters = (N x M x D + 1) x K  # this si the formula of counting params of cnn model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:08.592081Z","iopub.execute_input":"2025-01-31T02:38:08.592406Z","iopub.status.idle":"2025-01-31T02:38:08.596993Z","shell.execute_reply.started":"2025-01-31T02:38:08.592377Z","shell.execute_reply":"2025-01-31T02:38:08.595903Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Basic layers","metadata":{}},{"cell_type":"code","source":"#Number of parameters = (N x M x D + 1) x K\nkr = 2  # Kernel Size\n\nimage_size = 32        # input image dimensions are 32x32 pixels with 3 channels (RGB)\n\nx_input = layers.Input(shape=(image_size,image_size,3))  # (32, 32, 3) (32x32 RGB images), and assigns it to d1. 3 channels (RGB)\nd1 = x_input\n\n\n# x_input as the input and d1 as the output. In this case, the model simply takes the input and outputs it without any modifications (an identity model).\nclass_model = Model(inputs = x_input, outputs=d1)   # the model import from tf.keras\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:08.599628Z","iopub.execute_input":"2025-01-31T02:38:08.599920Z","iopub.status.idle":"2025-01-31T02:38:08.635449Z","shell.execute_reply.started":"2025-01-31T02:38:08.599893Z","shell.execute_reply":"2025-01-31T02:38:08.634508Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_3\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"### Explain","metadata":{}},{"cell_type":"markdown","source":"**Parameters**\n\n- ùëÅ is the number of input features.\n- ùëÄ is the number of hidden units.\n- ùê∑ is the depth (number of layers).\n- ùêæ is the number of output features.\n\n\n**Assumption**\n- This is basic layer desion, no params defined, out trainable & non-trainable parames will be 0\n- What the input define, output wil be same as input","metadata":{}},{"cell_type":"code","source":"# Visualization\nfrom tensorflow.keras.utils import plot_model\nplot_model(class_model, to_file='model.png', show_shapes=True, show_layer_names=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:08.637263Z","iopub.execute_input":"2025-01-31T02:38:08.637691Z","iopub.status.idle":"2025-01-31T02:38:08.701652Z","shell.execute_reply.started":"2025-01-31T02:38:08.637649Z","shell.execute_reply":"2025-01-31T02:38:08.700625Z"}},"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"image/png":"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\n","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}],"execution_count":14},{"cell_type":"markdown","source":"# Pytorch","metadata":{}},{"cell_type":"markdown","source":"#### Test 2: PyTorch","metadata":{}},{"cell_type":"code","source":"# Necessary Library\n!pip install torchinfo     # For Pytorch - summarizing and visualizing PyTorch models\n!pip install torchsummary  # For Pytorch - summarizing and visualizing PyTorch models\n\nimport torch.nn as nn\nfrom torchinfo import summary\n\n# Define Model\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super(SimpleModel, self).__init__()\n        # Additional layers can be added here if needed\n\n    def forward(self, x):\n        # Since we're just passing the input to output, we can return x directly, here x is dynamic can take any\n        return x\n\n# Initialize the Model\nmodel = SimpleModel()\n\n# Print the model Summary using TorchSummary\nsummary(model,(3, 32, 32))  # (Channel, hights, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:08.702885Z","iopub.execute_input":"2025-01-31T02:38:08.703281Z","iopub.status.idle":"2025-01-31T02:38:16.621939Z","shell.execute_reply.started":"2025-01-31T02:38:08.703244Z","shell.execute_reply":"2025-01-31T02:38:16.620602Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\nRequirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nSimpleModel                              [3, 32, 32]               --\n==========================================================================================\nTotal params: 0\nTrainable params: 0\nNon-trainable params: 0\nTotal mult-adds (M): 0\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.01\n=========================================================================================="},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"#### Notes- Pytorch","metadata":{}},{"cell_type":"markdown","source":"**Notes**\n- Class File (OPP) is every essential for PyTorch\n- `__init__:` This is the constructor method where you can define layers or components of the model. Currently, it's empty, but you can add layers if needed.\n- `forward:` This method defines the forward pass of the model. Here, we're simply returning the input x as the output without any modifications. This is a placeholder, and you can add more complex operations if required.\n\n**Shape**\n- When we practice we try to use `Even` shape instead `Odd` number like 256x256, 512x512, 1024x2024, 512x768, 340x512 ect.\n- We use this Even Numbers, so that we can `downsampling` this and get anomther Even Numbers (Q. Why use Even Number), its  for Processing efficiency!\n\n**TensforFlow vs PyTorch**\n- TensorFlow is easy practice over PyTorch Applicatioin","metadata":{}},{"cell_type":"markdown","source":"#### Test 2.1 : Excercise","metadata":{}},{"cell_type":"markdown","source":"- Use 2x2 Kernel\n- Use Conv2D\n- Use Padding","metadata":{}},{"cell_type":"code","source":"#Number of parameters = (N x M x D + 1) x K\n\n# N = M = kernel size\n# D = input channel count\n# K = output filter / channel count\n\n\n\nimage_size = 32        # setting img_size 32x32 pixel\ninputs = layers.Input(shape=(image_size, image_size,3)) # image_size 32x32 pixel with 3 channel(RGB)\nd1 = (inputs)  # input passed in d1 var\n\nd1 = Conv2D(10, kernel_size=(2,2), padding='same')(d1)      # Simple Conv ops with 10 filters applied on d1 and saved in d1\n\nclass_model = Model(inputs = inputs, outputs= d1)  # finally d1 send to output layer\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.623335Z","iopub.execute_input":"2025-01-31T02:38:16.623704Z","iopub.status.idle":"2025-01-31T02:38:16.658264Z","shell.execute_reply.started":"2025-01-31T02:38:16.623678Z","shell.execute_reply":"2025-01-31T02:38:16.657284Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_4\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)          ‚îÇ             \u001b[38;5;34m130\u001b[0m ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m130\u001b[0m (520.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> (520.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":16},{"cell_type":"markdown","source":"### Explain","metadata":{}},{"cell_type":"markdown","source":"**Notes**\n- input : 32, 32, 3 which passed to next layer with 10 filters so 32,32,10\n- `Conv`: This line applies a 2D convolutional layer to d1. The Conv2D layer has 10 filters with a kernel size of (2, 2). The padding='same' ensures that the output has the same spatial dimensions as the input.\n\n\n**How to get 130 Parameters ?**\n\n- Kernel Size: (2, 2)\n- Input Channels: 3 (since the input image has 3 channels: RGB)\n- Number of Filters: 10\n- Bias: 1 (a bias term for each filter)\n\n**Calculation**:\n\n1. Kernel Parameters per Filter:\n   Kernel¬†Parameters =`Kernel¬†Height √ó Kernel¬†Width √ó Input¬†Channels = 2 x 2 x 3 = 12`\n   \n2. Add Bias:\n   Total¬†Parameters¬†per¬†Filter = `Kernel¬†Parameters + Bias  = 12 + 1 = 13`\n\n3. Total Parameters for All Filters\n   Total¬†Parameters = `Total¬†Parameters¬†per¬†Filter √ó Number¬†of¬†Filters  13 x 10 = 130`\n\n\nTherefore, the total number of parameters for the `Conv2D` layer is `130`.\nBreaking it down, `each filter has 12 weights` for the kernel and `1 bias term`, and since you have 10 filters, you multiply the total parameters per filter by the number of filters to get 130 parameters.\n\n\n**Calculation Example 2**\n\nNumber¬†of¬†Parameters = (ùëÅ√óùëÄ√óùê∑+1)√óùêæ\n\n- N: Kernel Height\n- M: Kernel Width\n- D: Number of Input Channels (Depth of the input)\n- K: Number of Filters (Output channels)\n- 1: Bias term for each filter\n  \n**Given your parameters:**\n\n- N = 2 (Kernel Height)\n- M = 2 (Kernel Width)\n- D = 3 (Number of Input Channels, as the input image has 3 channels: RGB)\n- K = 10 (Number of Filters)\n\n\n1. Calculate Kernel Parameters Per Filter:\n\n     ùëÅ√óùëÄ√óùê∑=2√ó2√ó3=12\n\n2. Add the Bias Term:\n\n    Kernel¬†Parameters +1=12+1=13\n\n\n3. Calculate Total Parameters:\n\n    Number¬†of¬†Parameters =13√óùêæ=13√ó10=130\n\nSo, by using the formula:Number¬†of¬†Parameters=(2√ó2√ó3+1)√ó10=(12+1)√ó10=13√ó10=130\n\n\n---\n**Parameter Calcution Formula**\n\n- N: Kernel Height\n- M: Kernel Width\n- D: Number of Input Channels (Depth of the input)\n- K: Number of Filters (Output channels)\n- 1: Bias term for each filter\n- `N x M`: This represents the size of the kernel. e.g 3 x 3\n- `ùê∑` : This represents the number of input channels. In this case, D=3, `RGB`\n- `+`1: This accounts for the bias term.\n","metadata":{}},{"cell_type":"markdown","source":"### Excercise - 3","metadata":{}},{"cell_type":"code","source":"# Define your model\nclass ConvModel(nn.Module):\n    def __init__(self):\n        super(ConvModel, self).__init__()\n        # Define a convolutional layer with 10 filters, 2x2 kernel size, and 'same' padding\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(2, 2), padding='same')\n\n    def forward(self, x):\n        # Apply the convolutional layer\n        x = self.conv1(x)\n        return x\n\n# Initialize the model \nmodel = ConvModel()\n\n# Print model summary using torchsummary\nsummary(model, input_size=(3, 32, 32))  # (channels, height, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.659136Z","iopub.execute_input":"2025-01-31T02:38:16.659484Z","iopub.status.idle":"2025-01-31T02:38:16.669836Z","shell.execute_reply.started":"2025-01-31T02:38:16.659424Z","shell.execute_reply":"2025-01-31T02:38:16.668535Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nConvModel                                [10, 32, 32]              --\n‚îú‚îÄConv2d: 1-1                            [10, 32, 32]              130\n==========================================================================================\nTotal params: 130\nTrainable params: 130\nNon-trainable params: 0\nTotal mult-adds (M): 0.04\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.08\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.09\n=========================================================================================="},"metadata":{}}],"execution_count":17},{"cell_type":"markdown","source":"## Text 3: PyTorch Application","metadata":{}},{"cell_type":"code","source":"# Test 1\n# Define your model\nclass ConvModel(nn.Module):\n    def __init__(self):\n        super(ConvModel, self).__init__()\n        # Define a convolutional layer with 10 filters, 2x2 kernel size, and 'same' padding           # 10 Filters/ 10 Different Features\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=10, kernel_size=(2, 2), padding='same')\n\n    def forward(self, x):\n        # Apply the convolutional layer\n        x = self.conv1(x)\n        return x\n\n# Initialize the model\nmodel = ConvModel()\n\n# Print model summary using torchsummary\nsummary(model, input_size=(3, 32, 32))  # (channels, height, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.671032Z","iopub.execute_input":"2025-01-31T02:38:16.671388Z","iopub.status.idle":"2025-01-31T02:38:16.691001Z","shell.execute_reply.started":"2025-01-31T02:38:16.671361Z","shell.execute_reply":"2025-01-31T02:38:16.689837Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nConvModel                                [10, 32, 32]              --\n‚îú‚îÄConv2d: 1-1                            [10, 32, 32]              130\n==========================================================================================\nTotal params: 130\nTrainable params: 130\nNon-trainable params: 0\nTotal mult-adds (M): 0.04\n==========================================================================================\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.08\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.09\n=========================================================================================="},"metadata":{}}],"execution_count":18},{"cell_type":"markdown","source":"#### Weights","metadata":{}},{"cell_type":"code","source":"# Instructor will discuss later on this(weights)\nwt = class_model.get_weights()  # retrieving the weights of all the layers in the model.get_weights() will return a list of NumPy arrays\nlen(wt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.694870Z","iopub.execute_input":"2025-01-31T02:38:16.695187Z","iopub.status.idle":"2025-01-31T02:38:16.711379Z","shell.execute_reply.started":"2025-01-31T02:38:16.695158Z","shell.execute_reply":"2025-01-31T02:38:16.710296Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Model A (using TensorFlow/Keras)\n\ninputs = layers.Input(shape=(image_size,image_size,3))     # Define input of the model with 3 channel\nd1 =  (inputs)\n\nd1 = Conv2D(5 ,kernel_size=(3,3), padding='same', activation='gelu')(d1)  # Added a 2D Conv layers with 5  filters each of size is (3,3)\nd1 = Activation('gelu')(d1)         # Defining this optiona here when pass above after padding\n\nclass_model = Model(inputs = inputs, outputs = d1)\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.712960Z","iopub.execute_input":"2025-01-31T02:38:16.713229Z","iopub.status.idle":"2025-01-31T02:38:16.754310Z","shell.execute_reply.started":"2025-01-31T02:38:16.713204Z","shell.execute_reply":"2025-01-31T02:38:16.753304Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_5 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m140\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m140\u001b[0m (560.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> (560.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m140\u001b[0m (560.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> (560.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":20},{"cell_type":"markdown","source":"#### Notes","metadata":{}},{"cell_type":"markdown","source":"- `The padding='same'` ensures that the output size is the same as the input size. The activation function used here is gelu (Gaussian Error Linear Unit)\n- `class_model = Model(inputs = inputs, outputs = d1)` : This creates the model by specifying the input and output layers. This prints a summary of the model, showing the layers and the number of parameters.\n- No Parameter in Activations Layer\n\n**Entire Network Consist of:**\n- An input layer for the images.\n- A convolutional layer to extract features from the images using a `gelu` activation function.\n- The model is built and summarized.\n\n**Parameters Calcuation**\n\n`Number¬†of¬†parameters=(Kernel¬†width√óKernel¬†height√óNumber¬†of¬†input¬†channels+Bias¬†term)√óNumber¬†of¬†filter`\n\n- Kernel size = 3x3\n- Channels = 3\n- Number of Filter = 5\n\n**Working**\n\n- So, Kernel Width: 3 and Height 3\n- Number of input Channels : 3\n- Bias Term 1 (Each Filter has one bias Term)\n- Number of Filter : 5\n\nSo, As per Formula, total parameter will be:\n\n`(3 x 3 x 3 + 1)\n= 27 + 1\n= 28`\n  \nSo, the filter has `28 parameters`.\nSince there are 5 filters so, the total number of parameters is:\n\n`28 (Parameters Per Filter) x 5 (Number of Filter)`\n`= 140`\n\nTherefore, the Conv2D layer has 140 parameters in total.\n\n","metadata":{}},{"cell_type":"code","source":"# Model B (using PyTorch)\nclass ConvGELUModel(nn.Module): \n    def __init__(self):\n        super(ConvGELUModel, self).__init__()\n        # Define a convolutional layer with 5 filters, 3x3 kernel size, and 'same' padding\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels=5, kernel_size=(3, 3), padding='same')\n        # Define the GELU activation function\n        self.gelu = nn.GELU()\n\n    def forward(self,x):\n        # Apply the convolutional layer followed by GELU activation\n        x = self.conv1(x)\n        x = self.gelu(x)\n        return x\n\n# Initialize the model\nmodel = ConvGELUModel()\n\n# Print model summary using torchsummary\nsummary(model, input_shape=(3, 32, 32))  # (channels, height, width)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.755408Z","iopub.execute_input":"2025-01-31T02:38:16.755828Z","iopub.status.idle":"2025-01-31T02:38:16.767746Z","shell.execute_reply.started":"2025-01-31T02:38:16.755776Z","shell.execute_reply":"2025-01-31T02:38:16.766577Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nConvGELUModel                            --\n‚îú‚îÄConv2d: 1-1                            140\n‚îú‚îÄGELU: 1-2                              --\n=================================================================\nTotal params: 140\nTrainable params: 140\nNon-trainable params: 0\n================================================================="},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"### Explanation","metadata":{}},{"cell_type":"markdown","source":"**Initialization (__init__ method):**\n\n`super(ConvGELUModel, self).__init__():` Calls the initializer of the parent class `nn.Module`. This is necessary to properly initialize the model.\n\n`self.conv1 = nn.Conv2d(...):` Defines a 2D convolutional layer. It takes in 3 input channels (e.g., RGB color channels), and outputs 5 feature maps (filters). The kernel size is (3, 3), meaning the convolutional filter has dimensions of 3x3. The padding is set to 'same', which means the output size will be the same as the input size.\n\n**Forward Pass (forward method):**\n\n`x = self.conv1(x):` Applies the convolutional layer to the input tensor x.\n\n`x = self.gelu(x):` Applies the GELU (Gaussian Error Linear Unit) activation function to the output of the convolutional layer.\n\nThe GELU activation function is a smoother alternative to ReLU (Rectified Linear Unit) and can be beneficial for certain types of data and tasks.\n\n**Model Summary:**\n\n`model = ConvGELUModel():` Initializes an instance of the ConvGELUModel.\n\n`summary(model, input_shape=(3, 32, 32)):` Prints a summary of the model's architecture, using the torchsummary package. The input shape is specified as (3, 32, 32), which means the model expects an input with 3 channels and spatial dimensions 32x32 (like a 32x32 RGB image).","metadata":{}},{"cell_type":"markdown","source":"#### Models Comperasion (Model A Vs Model B) Tensorflow & PyTorch","metadata":{}},{"cell_type":"markdown","source":"**Model A: TensorFlow**\n\n**Framework**\nTensorFlow/Keras: This model uses the Keras API, which is a high-level neural networks API running on top of TensorFlow.\n\n**Layer Definitions:**\n\n- `inputs = layers.Input(shape=(image_size, image_size, 3)):` Defines the input layer with a shape of (image_size, image_size, 3) (3 channels for RGB images).\n\n- `d1 = Conv2D(5, kernel_size=(3, 3), padding='same', activation='gelu')(d1):` Adds a 2D convolutional layer with 5 filters, a kernel size of (3, 3), 'same' padding, and the GELU activation function directly.\n\n- `d1 = Activation('gelu')(d1):` Applies the GELU activation function. This is optional here as the activation has already been applied in the previous layer.\n\n**Model Definition:**\n\nclass_model = Model(inputs=inputs, outputs=d1): Defines the model by specifying the input and output layers.\n\n\n**Model B (using PyTorch):**\n\n**Framework:**\n\n- PyTorch: This model uses PyTorch, a flexible and efficient deep learning library.\n\n**Layer Definitions:**\n\n- self.conv1 = nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(3, 3), padding='same'): Defines a 2D convolutional layer with 3 input channels, 5 filters, a kernel size of (3, 3), and 'same' padding.\n\n- self.gelu = nn.GELU(): Defines the GELU activation function.\n\n**Forward Pass:**\n\n- x = self.conv1(x): Applies the convolutional layer to the input tensor x.\n- x = self.gelu(x): Applies the GELU activation function to the output of the convolutional layer.\n\n**Model Summary:**\n\n`model = ConvGELUModel()`: Initializes the model.\n\n`summary(model, input_shape=(3, 32, 32))`: Prints the model summary using the torchsummary package.\n\n\n**Key Differences:**\n\n**Framework:**\n\n- Model A uses TensorFlow/Keras, which is often praised for its high-level API and ease of use.\n\n- Model B uses PyTorch, which is known for its dynamic computation graph and flexibility.\n\n**Model Definition:**\n\n- Model A uses the Model class to define the model by specifying the inputs and outputs.\n\n- Model B defines the model by creating a class that inherits from nn.Module and implements the forward method.\n\n**Syntax and API:**\n\nTensorFlow/Keras and PyTorch have different syntax and API conventions. Model A's code is more declarative, while Model B's code is more imperative.","metadata":{}},{"cell_type":"markdown","source":"## Batch Normalization","metadata":{}},{"cell_type":"code","source":"wt = class_model.get_weights()\nlen(wt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.768778Z","iopub.execute_input":"2025-01-31T02:38:16.769063Z","iopub.status.idle":"2025-01-31T02:38:16.789316Z","shell.execute_reply.started":"2025-01-31T02:38:16.769039Z","shell.execute_reply":"2025-01-31T02:38:16.788332Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"# simple Keras model with an input layer, a convolutional layer, and batch normalization\nimage_shape = 32\ninputs = layers.Input(shape=(image_size, image_size,3))\nd1 = (inputs)\n\nd1 = Conv2D(1, kernel_size=(3,3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)  \n\nclass_model = Model(inputs=inputs, outputs=d1)\nclass_model.summary()\n\n\n'''\nTask # 2: \nWhen Apply Batch Normalization, then Total Param 32, Trainable Param 32, Non-Trainable -2. \nFind who are these 2 Non-Trainable Params ?\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.790377Z","iopub.execute_input":"2025-01-31T02:38:16.790683Z","iopub.status.idle":"2025-01-31T02:38:16.849649Z","shell.execute_reply.started":"2025-01-31T02:38:16.790658Z","shell.execute_reply":"2025-01-31T02:38:16.848543Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_6\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           ‚îÇ              \u001b[38;5;34m28\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization                  ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           ‚îÇ               \u001b[38;5;34m4\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization                  ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n</pre>\n"},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"'\\nTask # 2: \\nWhen Apply Batch Normalization, then Total Param 32, Trainable Param 32, Non-Trainable -2. \\nFind who are these 2 Non-Trainable Params ?\\n\\n'"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"#### Explanation","metadata":{}},{"cell_type":"markdown","source":"- `d1 = BatchNormalization()(d1):`This layer normalizes the output of the convolutional layer to improve the training process by stabilizing the learning process and speeding up convergence.\n- `class_model = Model(inputs=inputs, outputs=d1)`: Creates the Keras model by specifying the input and output layers.\n- Here for this model, the total Params are 32 (Conv + Batch) 28 + 4 =32\n- Since BatchNormaization Param are 4, so its has 2 trainable & 2 Non-trainable params inside this normalization layers","metadata":{}},{"cell_type":"code","source":"# Same model, its for testing (Better Readibilty)\n# Batch Normalization with Tensorflow \nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization\n\nimage_size = 32\ninputs = layers.Input(shape=(image_size, image_size, 3))\nd1 = (inputs)\n\nd1 = Conv2D(1, kernel_size=(3, 3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)\n\nclass_model = Model(inputs=inputs, outputs=d1)\nclass_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.850818Z","iopub.execute_input":"2025-01-31T02:38:16.851176Z","iopub.status.idle":"2025-01-31T02:38:16.890385Z","shell.execute_reply.started":"2025-01-31T02:38:16.851134Z","shell.execute_reply":"2025-01-31T02:38:16.889340Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_7\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           ‚îÇ              \u001b[38;5;34m28\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_1                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)           ‚îÇ               \u001b[38;5;34m4\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_1                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":24},{"cell_type":"markdown","source":"### Layers Explanation","metadata":{}},{"cell_type":"markdown","source":"**Input Layer:**\n\n- Type: `InputLayer`\n\n- Output Shape: `(None, 32, 32, 3)`\n\n- `Param #: 0` (No parameters because it's just the input definition)\n\n**Conv2D Layer:**\n\n- Type: `Conv2D`\n\n- Output Shape: `(None, 32, 32, 1)`\n\n- `Param #: 28` (Trainable parameters)\n\n**Parameter Calculation:**\n\n- Filters: 1\n\n- Kernel Size: (3, 3)\n\n- Input Channels: 3\n\n- Bias Term: 1\n\n- Total Params = (3 * 3 * 3 + 1) * 1 = 28\n\n**Batch Normalization Layer:**\n\n- Type: `BatchNormalization`\n\n- Output Shape: `(None, 32, 32, 1)`\n\n- `Param #: 4` (Total parameters, including both trainable and non-trainable)\n\n**Parameter Calculation:**\n\n**Trainable Parameters:**\n\n- Gamma (scaling factor): 1\n\n- Beta (shifting factor): 1\n\n- Total Trainable Params = 1 + 1 = 2\n\n**Non-Trainable Parameters:**\n\n- Mean: 1\n\n- Moving Variance: 1\n\n- Total Non-Trainable Params = 1 + 1 = 2\n\n**Identifying Non-Trainable Parameters:**\n\nIn the Batch Normalization layer, there are 2 non-trainable parameters: the moving mean and moving variance. These parameters are calculated during the training process and used during inference to normalize the data.\n\n**Summary:**\n\n- Input Layer: No parameters\n\n- Conv2D Layer: 28 trainable parameters\n\n- Batch Normalization Layer: 4 parameters (2 trainable, 2 non-trainable)\n\nSo, the non-trainable parameters in this model are the moving mean and moving variance of the Batch Normalization layer.","metadata":{}},{"cell_type":"markdown","source":"**Moving Mean and Moving Variance:**\n\n**Batch Normalization:**\n\nBatch Normalization is a technique used to improve the training of deep neural networks. It normalizes the inputs of a layer for each mini-batch, thereby reducing internal covariate shift.\n\n**How It Works:**\n\nDuring training, for each mini-batch, Batch Normalization calculates the mean and variance of the inputs.\n\nIt then normalizes the inputs by subtracting the batch mean and dividing by the batch standard deviation.\n\n**Moving Mean and Moving Variance:**\n\nMoving Mean: It's an exponential moving average of the batch means calculated during training.\n\nMoving Variance: It's an exponential moving average of the batch variances calculated during training.\n\nThese moving statistics are updated during each training step to capture the running statistics of the entire training data.\n\n**Why They Are Non-Trainable:**\n\nNon-Trainable Parameters: These parameters are not updated through backpropagation and gradient descent. Instead, they are updated using a moving average formula.\n\nPurpose: The moving mean and variance are used during inference (testing or deployment) to normalize the inputs based on the statistics learned during training. This ensures that the model's behavior is consistent between training and inference.\n\nConsistency: By using moving averages, the normalization can be applied even when a single data point (or a batch of size one) is fed into the network during inference, providing consistent performance.\n\nIn summary, the moving mean and moving variance are essential for maintaining the learned normalization during inference, ensuring the model's performance remains stable and accurate. These parameters are updated during training but are not trainable in the conventional sense‚Äîthey're not adjusted through gradients but through running averages.","metadata":{}},{"cell_type":"markdown","source":"**Task**\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test : PyTorch\n# Batch Normalization with PyTorch\n\nfrom torchsummary import summary # Torch Summary used to print details Summary\nclass ConvGELUModel(nn.Module): \n    def __init__(self):\n        super(ConvGELUModel, self). __init__()\n        # Define a convolutional layer with 1 filter, 3x3 kernel size, and 'same' padding\n        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 1, kernel_size=(3,3), padding=1 )  # padding=1 for 'same'\n        # Define the GELU activation function\n        self.gelu = nn.GELU()\n\n        # Define Batch Normalization \n        self.batch_norm = nn.BatchNorm2d(1)  # Here inside 1 mean Channels (Applying on One channel and on EKJON both are correct, Out_channels 1 (ekjon)\n\n\n    def forward(self, x):\n        # Apply the convolutional layer, GELU activation, and Batch Normalization\n        x = self.conv1(x)\n        x = self.gelu(x)\n        x = self.batch_norm(x)\n        return x\n\n# Initialize the model\nmodel = ConvGELUModel()  \n\n# Print model summary using torchsummary\nsummary(model, input_size=(3, 32, 32))  # (channels, height, width)  Shows 1,32,32 instead of 32,32,3 due to out_channels=1 defined","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:16.891490Z","iopub.execute_input":"2025-01-31T02:38:16.891872Z","iopub.status.idle":"2025-01-31T02:38:17.099829Z","shell.execute_reply.started":"2025-01-31T02:38:16.891831Z","shell.execute_reply":"2025-01-31T02:38:17.098749Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 1, 32, 32]              28\n              GELU-2            [-1, 1, 32, 32]               0\n       BatchNorm2d-3            [-1, 1, 32, 32]               2\n================================================================\nTotal params: 30\nTrainable params: 30\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.02\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.04\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"## Explanation","metadata":{}},{"cell_type":"markdown","source":"\n`[-1, 1, 32, 32]`\n- `-1`: The -1 is used as a placeholder indicating that this dimension will be dynamically determined based on the number of samples in your input data batch during runtime. Batch size (number of samples in the batch).\n- `1`: Number of channels (e.g., grayscale images have 1 channel, RGB images have 3 channels).\n- `32, 32`: Height and width of the feature map (spatial dimensions).\n- `Using -1` allows the network to process variable-sized batches of input data efficiently.\n\n**Code Part- Class**\n\n`class ConvGELUModel(nn.Module):\n\n    def __init__(self):\n    \n        super(ConvGELUModel, self). __init__()`\n\n**Explanation:**\n\nfrom torchsummary import summary: This line imports the summary function from the torchsummary library, which is often used to print a detailed summary of a PyTorch model, including the output shapes and the number of parameters for each layer.\n\nclass `ConvGELUModel(nn.Module)`:: This line defines a new class `ConvGELUModel` that inherits from nn.Module. In PyTorch, nn.Module is the base class for all neural network modules, and your custom model class should inherit from it.\n\n`def __init__(self)`:: This is the constructor method for the `ConvGELUModel` class. It's called when an object of the class is created. In this method, you typically define the layers and parameters of your model.\n\n`super(ConvGELUModel, self).__init__()`: This line calls the constructor of the parent class (nn.Module). The super() function is used to give your class access to methods and properties of the parent class. In this case, it initializes the nn.Module class, which is essential for PyTorch models to work correctly.\n","metadata":{}},{"cell_type":"markdown","source":"** self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 1, kernel_size=(3,3), padding=1 )  # padding=1 for 'same'\n\n\nThe line self.conv1 = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=(3,3), padding=1) defines a 2D convolutional layer in your neural network. Let's break down what each part of this line does:\n\nExplanation:\nself.conv1:\n\nThis creates an instance variable conv1 for your class. The self keyword is used to refer to the instance of the class itself.\n\nnn.Conv2d:\n\nThis is a built-in PyTorch class for creating a 2D convolutional layer. Convolutional layers are used in neural networks to process image data by applying convolution operations to the input.\n\nin_channels=3:\n\nSpecifies the number of input channels to the convolutional layer. If you are working with RGB images, the number of input channels is 3 (since an RGB image has three color channels: red, green, and blue).\n\nout_channels=1:\n\nSpecifies the number of output channels produced by the convolutional layer. In this case, it will produce a single output channel. This is useful if you want to reduce the number of channels, for example, to convert an RGB image to a grayscale image.\n\nkernel_size=(3,3):\n\nSpecifies the size of the convolutional kernel (also called a filter). A (3,3) kernel means that the filter is 3x3 pixels. This kernel will slide over the input image to compute the convolution.\n\npadding=1:\n\nSpecifies the amount of zero-padding added to the edges of the input image. Padding helps maintain the spatial dimensions (height and width) of the input image after convolution. In this case, a padding of 1 will keep the output image size the same as the input image size.\n\nWhy Use self.conv1:\nUsing self.conv1 (or any instance variable) to define layers in the __init__ method allows these layers to be part of the class instance. This ensures that the layers are properly managed by PyTorch‚Äôs framework, including weight initialization, gradient computation, and updating during the training process.\n\n**Batch Normalization2D**\n\n- `Input: (N,C,H,W)`                \n- `Outpur: (N,C,H,W) same as Input`\n-  `self.batch_norm = nn.BatchNorm2d(1):` 1 Means Applying on Channel (C)\n\n**Q.Why & How Channel Reduce from 32,32,3 to 32,32,1?**\n\n- Becasue Output channels is 1, so output shows as `32,32,1` instead of `32,32,3`\n- Whatever the operation it will apply on One","metadata":{}},{"cell_type":"markdown","source":"\n\n\n","metadata":{}},{"cell_type":"markdown","source":"### Batch Normalization (Test 2)","metadata":{}},{"cell_type":"code","source":"'''\nwt1 = list()\n\nfor i in range(len(wt)):\n   wt1.append(K.sigmoid(wt[i]))\n\nf1 = 0\nprint(wt[f1][0][0], wt1[f1][0][0])\nclass_model.set_weights(wt1)\n\nwt2 = class_model.get_weights()\n\nprint(wt2[f1][0][0], wt1[f1][0][0])\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:17.100795Z","iopub.execute_input":"2025-01-31T02:38:17.101076Z","iopub.status.idle":"2025-01-31T02:38:17.107630Z","shell.execute_reply.started":"2025-01-31T02:38:17.101051Z","shell.execute_reply":"2025-01-31T02:38:17.106475Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"'\\nwt1 = list()\\n\\nfor i in range(len(wt)):\\n   wt1.append(K.sigmoid(wt[i]))\\n\\nf1 = 0\\nprint(wt[f1][0][0], wt1[f1][0][0])\\nclass_model.set_weights(wt1)\\n\\nwt2 = class_model.get_weights()\\n\\nprint(wt2[f1][0][0], wt1[f1][0][0])\\n\\n'"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"# Test 2.1 (TF Application)\n\nimage_size = 32\ninputs = layers.Input(shape=(image_size, image_size, 3))\nd1 = (inputs)\n\nd1 = Conv2D(5, kernel_size=(3,3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)      # Here Channel not mentioned, becuase TF/Keras by default make sure operation on LAST ON (Channel); whereas PyTorch alwasy keep channel at first (Allow Customization)\nd1 = MaxPool2D()(d1)             # Pooling reduce the dimenstion from 32 to 16\n\nclass_model = Model(inputs= inputs, outputs = d1)\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:17.108627Z","iopub.execute_input":"2025-01-31T02:38:17.108954Z","iopub.status.idle":"2025-01-31T02:38:17.164301Z","shell.execute_reply.started":"2025-01-31T02:38:17.108924Z","shell.execute_reply":"2025-01-31T02:38:17.163338Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_8\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_8 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m140\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_2                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_2                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m160\u001b[0m (640.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> (640.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m150\u001b[0m (600.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> (600.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m10\u001b[0m (40.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10</span> (40.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":27},{"cell_type":"markdown","source":"### Explanation","metadata":{}},{"cell_type":"markdown","source":"**Pooling**\n\n- Reduce the Dimenstion, in this layer there is no Trainable Parameters\n- See the Output Shape, its always recommended to take `Even` Numbers like 32,32, 16,16 (Half of 32,32)\n- In Batch Normalization, we would get 17,17 (This would Odd) if preceeding layer would have 34,34, So, its recommended take 2^ / 2 the power values","metadata":{}},{"cell_type":"code","source":"# Test 2.1 (PyTorch Application) Same This with PyTorch Application\n\nclass ConvGELUBNMaxPoolModel(nn.Module):\n    def __init__(self):\n        super(ConvGELUBNMaxPoolModel, self).__init__()\n        # Define the convolutional layer\n        self.conv1 = nn.Conv2d(in_channels =3, out_channels=5, kernel_size=(3,3), padding=1) # 'same' padding\n        # Define the GELU activation function\n        self.gelu = nn.GELU()\n        # Define Batch Normalization\n        self.batch_norm = nn.BatchNorm2d(5)\n        # Define Max Pooling\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n\n\n    def forward(self, x):\n        # Apply the convolutional layer, GELU activation, Batch Normalization, and Max Pooling\n        x = self.conv1(x)\n        x = self.gelu(x)\n        x = self.batch_norm(x)\n        x = self.max_pool(x)\n        return x\n\n# Initialization Model\nmodel = ConvGELUBNMaxPoolModel()\n\n# Print model summary using torchsummary\nsummary(model, input_size=(3, 32,32))  # (channels, height, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:17.165274Z","iopub.execute_input":"2025-01-31T02:38:17.165659Z","iopub.status.idle":"2025-01-31T02:38:17.189855Z","shell.execute_reply.started":"2025-01-31T02:38:17.165619Z","shell.execute_reply":"2025-01-31T02:38:17.188763Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 5, 32, 32]             140\n              GELU-2            [-1, 5, 32, 32]               0\n       BatchNorm2d-3            [-1, 5, 32, 32]              10\n         MaxPool2d-4            [-1, 5, 16, 16]               0\n================================================================\nTotal params: 150\nTrainable params: 150\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.13\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.14\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":28},{"cell_type":"markdown","source":"### Explanation","metadata":{}},{"cell_type":"markdown","source":"-- 2.1 Both are same Code, but for one it has 160 and for another it has 150, why ?","metadata":{}},{"cell_type":"markdown","source":"**Mathmatical Equation Or Model**\n\nI = input, O = output,\nC = Conv,\nA = Activation,\nN = Normalization,\nP = Pooling \\/\n\n1. I -  O\n\n2. I - C -  O\n\n3. I - C - A -  O\n\n4. I - C - A - N -  O\n\n5. I - C - A - N - P -  O\n\n6. I - C - A - N - P - C - A - N - P - C - A - N - P -  O           # 3 CANP BETWEEN I & O\n\nInside Input & Output it has number of CANP","metadata":{}},{"cell_type":"markdown","source":"## <font color=RoyalBlue> CANP Operation by TensorFlow<font>","metadata":{}},{"cell_type":"code","source":"# Test 3.1\n# TensorFlow Operaitons\n# Equation Number 6: I - C - A - N - P - C - A - N - P - C - A - N - P - O\n\n# Input\nimage_size = 32\ninputs = layers.Input(shape=(image_size,image_size,3))\nd1 =  (inputs)\n\n# CANP1\nd1 = Conv2D(5 ,kernel_size=(3,3), padding='same', activation='gelu')(d1) # last (d1) means applied on this d1\nd1 = BatchNormalization()(d1)\nd1 = MaxPool2D()(d1)\n\n\n# CANP2\nd1 = Conv2D(5 ,kernel_size=(3,3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)\nd1 = MaxPool2D()(d1)\n\n\n# CANP3\nd1 = Conv2D(5 ,kernel_size=(3,3), padding='same', activation='gelu')(d1)\nd1 = BatchNormalization()(d1)\nd1 = MaxPool2D()(d1)\n\n\n# Output-d1\nclass_model = Model(inputs = inputs, outputs = d1)\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:17.190940Z","iopub.execute_input":"2025-01-31T02:38:17.191297Z","iopub.status.idle":"2025-01-31T02:38:17.268867Z","shell.execute_reply.started":"2025-01-31T02:38:17.191267Z","shell.execute_reply":"2025-01-31T02:38:17.268153Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_9\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_9\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_9 (\u001b[38;5;33mInputLayer\u001b[0m)           ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m140\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_3                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m230\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_4                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             ‚îÇ             \u001b[38;5;34m230\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_5                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m5\u001b[0m)             ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_3                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_4                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_5                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m660\u001b[0m (2.58 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> (2.58 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m630\u001b[0m (2.46 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">630</span> (2.46 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"## Explation","metadata":{}},{"cell_type":"markdown","source":"**Layers**\n\n- Layers 32 > 8 > 4 ( Continous DownSampling )\n","metadata":{}},{"cell_type":"markdown","source":"## <font color=RoyalBlue> CANP Operations by PyTorch <font>","metadata":{}},{"cell_type":"code","source":"# Test 3.1\n# PyTorch Operaitons \n# Equation Number 6: I - C - A - N - P - C - A - N - P - C - A - N - P - O\n# CANP (Convolution, Activation, Normalization, Pooling)\n\n# Define your model\nclass ConvGELUBNMaxPoolModel(nn.Module): \n    def __init__(self):\n        super(ConvGELUBNMaxPoolModel, self).__init__()  # Confirmation all facilites of the class from nn.Module all for this ops\n        \n        # Define the First Convolution block\n        self.conv_block1 = nn.Sequential(\n            nn.Conv2d(in_channels=3, out_channels=5, kernel_size=(3, 3), padding=1), # 'same' padding\n            nn.GELU(),\n            nn.BatchNorm2d(5),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        # Sequence + Cov + Activation + Normalization + Pooling\n\n        # Define the Second convolutional block\n        self.conv_block2 = nn.Sequential(\n            nn.Conv2d(in_channels=5, out_channels=5, kernel_size=(3,3), padding=1),   # Kernel  or Filter\n            nn.GELU(),\n            nn.BatchNorm2d(5),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n        # Define the Third Convoluation Block\n        self.conv_block3 = nn.Sequential(\n            nn.Conv2d(in_channels=5, out_channels=5, kernel_size=(3,3), padding=1),\n            nn.GELU(),\n            nn.BatchNorm2d(5),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n\n    # Forward\n    def forward(self, x):\n        # Pass the input through the three convolutional blocks\n        x = self.conv_block1(x)\n        x = self.conv_block2(x)\n        x = self.conv_block3(x)\n        return x\n\n# Initialize the model\nmodel = ConvGELUBNMaxPoolModel()      # This model took all input by the above forward pass\n\n# Print model summary using torchsummary        \nsummary(model, input_size=(3, 32, 32))   # (channels, height, width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:17.269811Z","iopub.execute_input":"2025-01-31T02:38:17.270204Z","iopub.status.idle":"2025-01-31T02:38:17.294924Z","shell.execute_reply.started":"2025-01-31T02:38:17.270162Z","shell.execute_reply":"2025-01-31T02:38:17.293616Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1            [-1, 5, 32, 32]             140\n              GELU-2            [-1, 5, 32, 32]               0\n       BatchNorm2d-3            [-1, 5, 32, 32]              10\n         MaxPool2d-4            [-1, 5, 16, 16]               0\n            Conv2d-5            [-1, 5, 16, 16]             230\n              GELU-6            [-1, 5, 16, 16]               0\n       BatchNorm2d-7            [-1, 5, 16, 16]              10\n         MaxPool2d-8              [-1, 5, 8, 8]               0\n            Conv2d-9              [-1, 5, 8, 8]             230\n             GELU-10              [-1, 5, 8, 8]               0\n      BatchNorm2d-11              [-1, 5, 8, 8]              10\n        MaxPool2d-12              [-1, 5, 4, 4]               0\n================================================================\nTotal params: 630\nTrainable params: 630\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.01\nForward/backward pass size (MB): 0.17\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.18\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"**Question**\n\n- Q1.What are the params inside block? A. Input,output, kernel, padding\n- Q2. What are params in Pooling ? A: Kernel & Stride\n- Q3. Component of Block(s) Define : `Sequence + Cov + Activation + Normalization + Pooling`\n- Q4. Is Kernel and Filter is same ? Ans: Yes\n- Q5. What refer  by Padding 1 ? A: Its ensure that `output` will be same as `Input` size\n- Q6. What the Function of `GELU` ? Ans: It introduces non-linearity to the network, which helps in learning complex pattern\n- Q7. What is the contribution of BatchNorm ? Ans. Normalizes the output of the previous layer (5 feature maps) to improve the training stability and performance\n- Use of `Kernel_size` in maxpooling ? Its the size of `Pooling Window` is `2X2`\n- `Stide=2`: The window moves 2 steps at a time. This effectively downsamples the feature maps by a factor of 2, reducing their spatial dimensions\n\n**BatchNormalization**\n\n- Q8. Why `BatchNorm2d(5)`: Ans: BatchNorm2d must the `same number of output Channels` Since you defined the number of output channels as 5 in the convolutional layer, you also need the batch normalization to handle the same number of channels.\n- The purpose of this batch normalization is to standardize the outputs of the convolutional layer by adjusting and scaling the activations\n- This can help:\n  - Accelerate training by allowing the network to converge faster\n  - Improve generalization by reducing the risk of overfitting\n  - Ensure stable distributions of layer inputs, which can make the training process more robust\n  - The BatchNorm2d(5) line in your code indicates that batch normalization is being applied to five feature maps. This value of 5 matches the number of output channels defined in the convolutional layer `(nn.Conv2d(in_channels=5, out_channels=5, ...))`. Essentially, each output channel from the convolutional layer is normalized independently by the batch normalization layer\n  - Q9. What is the funnction of MaxPooling ? `Ans`: is helps for `Downsampling`\n\n\n**Model Architecture-Pytorch**\n\n- Class Define with nn Module\n- Constructor & Super Confirmation\n- Convolution Block(s) Design (Here we used 3 Block)\n- Forward Pass\n  - Pass Input(x) through all created block\n  - Return input(x)\n- Initializet the Model\n  - All forwarding will be initialized here\n- Print Summary of the Model","metadata":{}},{"cell_type":"markdown","source":"**Output Explanation**\n\n- `Conv2d-1:` The input shape is transformed to `[batch_size, 5, 32, 32].` This means the output of this layer will have 5 channels and the spatial dimensions (height and width) are both 32.\n- `GELU-2:` This is an activation layer, which does not change the shape of the input. So, the output shape remains `[batch_size, 5, 32, 32].`\n- `BatchNorm2d-3:` This layer also does not change the shape of the input. Thus, the output remains `[batch_size, 5, 32, 32].`\n- `MaxPool2d-4:` This layer performs downsampling, reducing the spatial dimensions by a factor of 2. The output shape is `[batch_size, 5, 16, 16]`\n- `Conv2d-5:` The output shape is `[batch_size, 5, 16, 16]`. The number of channels remains 5, and the spatial dimensions do not change.\n- `GELU-6:` This activation layer doesn't change the shape, so it remains `[batch_size, 5, 16, 16]`\n- `BatchNorm2d-7:` This also doesn't change the shape, so the output shape is `[batch_size, 5, 16, 16]`\n- `MaxPool2d-8:` Again, this layer downsamples by a factor of 2, resulting in an output shape of `[batch_size, 5, 8, 8]`\n- `Conv2d-9:` The output shape remains `[batch_size, 5, 8, 8]` as the number of channels remains 5 and the spatial dimensions do not change\n- `GELU-10:` This activation layer does not change the shape, so it remains `[batch_size, 5, 8, 8]`\n- `BatchNorm2d-11:` This layer does not change the shape, so the output remains `[batch_size, 5, 8, 8]`\n- `MaxPool2d-12:` Finally, this layer performs downsampling by a factor of 2, resulting in an output shape of `[batch_size, 5, 4, 4]`\n\n**Summary**\n\nSo, in summary, the shape transformation through the layers are as follows\n\n- Start with `[batch_size, 5, 32, 32]`\n- Downsampled to `[batch_size, 5, 16, 16]`\n- Downsampled again to `[batch_size, 5, 8, 8]`\n- Finally, downsampled to `[batch_size, 5, 4, 4]`\n\n**Question**\n\n- Q1. How you get total 230 param ? `A`: if you summ total params then you will get `230 Params`\n- Q2. As per output total oversavtion is 12,you see at every 4th rows, Pooling / downsampling Applied\n\n\n**How Batch Normalization got 10 parameters here ?**\n\n- Batch normalization layers have two types of parameters for each feature channel:\n\n  - `Scale (gamma):` One parameter per feature channel to scale the normalized value.\n  - `Shift (beta):` One parameter per feature channel to shift the normalized value.\n\nGiven that we have `5 feature channels in BatchNorm2d-3`, the calculation for the parameters goes as follows:\n\n- `Scale (gamma) parameters:` 5\n\n- `Shift (beta) parameters:` 5\n\nSo, the total number of parameters in BatchNorm2d-3 is:\n\n`5(scale)+5‚Äâ(shift)=10`\n`One for scaling and one for shifting, for each channel.`\n\nThat's why the total is 10 parameters. These parameters help the model learn the `appropriate scale` and `shift for the normalized feature maps` during training.\n\n\n**Calculation of 630 parameters**\n\n- `Conv2d-1` : Output `Output Shape: [-1, 5, 32, 32]`\n   -  `Calculation: (3√ó3√ó1+1)√ó5=140`  : Kernel `(3x3)` ; input=1, output=5, Bias = 1\n- `BatchNorm2d-3` : 5 feature channels `(2 * 5)= 10` Each channel has a scale and shift parameter\n- `Conv2d-5` : `Calculation: (3√ó3√ó5+1)√ó5=230` kernel= `(3x3)`, output=5, input=1, Bias=1\n- `BatchNorm2d-7` : 2x5 = 10\n- `Conv2d-9` : `Calculation: (3√ó3√ó5+1)√ó5=230` kernel= `(3x3)`, output=5, input=1, Bias=1\n- `BatchNorm2d-11` : 5 feature channels `(2 * 5)= 10` Each channel has a scale and shift parameter\n- `Total Params`: `140+10+230+10+230+10=630`\n\n\n\n**Why Non-Trainable Parameters are ZERO ?**\n\nIn this particular model, all the parameters are **trainable** because they all **contribute to the learning process**. Here's why:\n\n1. **Convolutional Layers:** The weights and biases of convolutional layers (Conv2d) are all trainable. These parameters are crucial for learning the features from the input data.\n\n2. **Batch Normalization Layers:** The scale (gamma) and shift (beta) parameters in BatchNorm2d layers are also trainable. These parameters help the network normalize its inputs more effectively and adaptively during training.\n\n3. **Activation Functions and Pooling Layers:** The GELU activation function and MaxPool2d layers do not have any parameters to train. They simply apply a fixed operation to the input data.\n\n`In summary:`\n\n**Convolutional layers:** Weights and biases are trainable.\n\n**Batch normalization layers:** Scale and shift parameters are trainable.\n\n**Activation functions (GELU) and pooling layers (MaxPool2d):** No parameters to train.\n\nSince all the parameters in your model are either weights, biases, scale, or shift factors, they are all trainable. That‚Äôs why there are no non-trainable parameters in this model.\n\n\n**Parameter Comperision Between TF & PyTorch 660 &  630, Explain Why ?**\n\n`Ans`: TensorFlow Always Take Higher Params over PyTorch due to :\n - TensorFlow `includes the bias in Conv2D by default`, even when `BatchNormalization` is used.\n - `PyTorch removes` the bias in Conv2D when BatchNorm2d follows, because BatchNorm itself already has a learnable `offset (Œ≤)`, making the bias in `Conv2D` redundant.\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## Exclusive Notes","metadata":{}},{"cell_type":"markdown","source":"## Test 4.0 Functional/modular way for model design","metadata":{}},{"cell_type":"code","source":"# Test 4.1\n# Step 1\ndef CANP(ind1, fltr, krnl):     # input dimension, Filter, Kernel\n    d1 = Conv2D(fltr, kernel_size=(krnl, krnl), padding='same', activation='gelu')(ind1)\n    d1 = BatchNormalization()(d1)\n    d1 = MaxPool2D()(d1)\n    return d1\n\n\n# Step 2: Define Size\nimage_size = 32\ninputs = layers.Input(shape=(image_size, image_size,3))\nd1 = (inputs)\n\n# Step 3: \nd1 = CANP(d1, 5,3)\nd1 = CANP(d1, 5,3)\nd1 = CANP(d1, 5,3)\n\n# Step 4:\nclass_model = Model(inputs=inputs, outputs=d1)\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:17.296132Z","iopub.execute_input":"2025-01-31T02:38:17.296550Z","iopub.status.idle":"2025-01-31T02:38:17.376891Z","shell.execute_reply.started":"2025-01-31T02:38:17.296504Z","shell.execute_reply":"2025-01-31T02:38:17.375733Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_10\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_10 (\u001b[38;5;33mInputLayer\u001b[0m)          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m140\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_6                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m230\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_7                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             ‚îÇ             \u001b[38;5;34m230\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_8                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m5\u001b[0m)             ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_6                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_7                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_8                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m660\u001b[0m (2.58 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> (2.58 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m630\u001b[0m (2.46 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">630</span> (2.46 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"**Steps Function**\n\n1. Step1: Define Function (CANP)\n2. Step2: Define Size (Input)\n3. Step3: Apply CANP Function\n4. Step4: Create and Summarize the Model\n\n---\n\n**Steps Summary**\n\n1. `Step1: Define Function (CANP) :` This function defines a sequence of three layers\n   - Conv2D Layer: Applies convolutional operations to the input data.\n   - BatchNormalization Layer: Normalizes the inputs to stabilize and speed up training\n   - MaxPooling2D Layer: Downsamples the input data by taking the maximum value in each pool.\n     \n3. `Step2: Define Size (Input)`:\n   - image_size: Sets the size of the input images (32x32 pixels).\n   - inputs: Defines the input layer with a shape of (32, 32, 3) indicating 32x32 pixel images with 3 color channels (RGB).\n     \n5. `Step3: Apply CANP Function`: \n   - The CANP function is applied three times sequentially to the data. Each time, it performs convolution, normalization, and pooling operations.\n     \n7. `Step4: Create and Summarize the Model`\n   - Create Model: Defines the model by specifying the inputs and the final output after applying the layers.\n   - Summary: Prints a summary of the model architecture, including the layers and the number of parameters.\n\nThis process builds a simple Convolutional Neural Network (CNN) with three blocks of Convolution, Batch Normalization, and Max Pooling layers.","metadata":{}},{"cell_type":"markdown","source":"**What is refer by `Model: \"functional_10\"` ?\n\n- This label is auto-generated by TensorFlow/Keras to refer to your specific model instance.\n- \"Functional\" refers to the type of model (using the Functional API), and \"10\" likely refers to it being the 10th model created in your current session or script.\n\n`batch_normalization_6 (BatchNormalization)`: This layer normalizes the input data to improve training stability. The \"6\" indicates it's the 6th BatchNormalization layer instance.\n\n`max_pooling2d_4 (MaxPooling2D)`: This layer performs max pooling operations to downsample the input data. The \"4\" indicates it's the 4th MaxPooling2D layer instance\n","metadata":{}},{"cell_type":"code","source":"# Test 4.1 (Check with a little Change)\n# Step 1\ndef CANP(ind1, fltr, krnl):\n    d1 = Conv2D(fltr, kernel_size=(krnl, krnl), padding='same', activation='gelu')(ind1)\n    d1 = BatchNormalization()(d1)\n    d1 = MaxPool2D()(d1)\n    return d1\n\n\n# Step 2: Define Size\nimage_size = 32\ninputs = layers.Input(shape=(image_size, image_size,3))\nd1 = (inputs)\n\n# Step 3: \nd1 = CANP(d1, 5,3)\nd1 = CANP(d1, 5,3)\nd1 = CANP(d1, 15,3)  # Chage 15 instead 5, to check and confirm the output, its Experimental\n\n# Step 4:\nclass_model = Model(inputs=inputs, outputs=d1)\nclass_model.summary()\n\n# Experiments output in orignal params was 660, now its 1160 due to change in params","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:17.377897Z","iopub.execute_input":"2025-01-31T02:38:17.378289Z","iopub.status.idle":"2025-01-31T02:38:17.460766Z","shell.execute_reply.started":"2025-01-31T02:38:17.378260Z","shell.execute_reply":"2025-01-31T02:38:17.459566Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_11\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m140\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_9                ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m230\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_10               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m5\u001b[0m)             ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m)            ‚îÇ             \u001b[38;5;34m690\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_11               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m15\u001b[0m)            ‚îÇ              \u001b[38;5;34m60\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m15\u001b[0m)            ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_9                ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_10               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)             ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)            ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">690</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_11               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)            ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)            ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,160\u001b[0m (4.53 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,160</span> (4.53 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,110\u001b[0m (4.34 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,110</span> (4.34 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m50\u001b[0m (200.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50</span> (200.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"### Explantion Function or Moduler Approach","metadata":{}},{"cell_type":"markdown","source":"**Desing CNN model by Functional Approach**\n\n**Step 1: Define CANP Function**\n\nThis function defines a series of operations using TensorFlow/Keras layers:\n\n- `Conv2D:` Applies a 2D convolution over the input image. It has several parameters:\n  - `fltr:` Number of output filters in the convolution.\n  - `kernel_size:` The height and width of the 2D convolution window.\n  - `padding='same':` Ensures the output has the same height and width as the input by padding the input.\n  - `activation='gelu':` Applies the Gaussian Error Linear Units (GELU) activation function.\n    \n- `BatchNormalization:` Normalizes the activations of the previous layer at each batch, improving training speed and stability.\n- `MaxPool2D:` Applies a 2D max pooling operation, reducing the spatial dimensions (height and width) of the input.\n\n**Step 2: Define Input Size**\n\n- `image_size = 32`: Sets the size of the input image to 32x32 pixels.\n- `inputs = layers.Input(shape=(image_size, image_size, 3)):` Defines the input layer with the specified size and 3 color channels (RGB).\n\n**Step 3: Apply CANP Function**\n\n- This part of the code calls the `CANP` function three times with d1 (initially the input) and specific `filter` and `kernel` sizes.\n- Each call to `CANP` performs `convolution, batch normalization, and max pooling on d1`, progressively `transforming` the input image.\n\nIn summary, this script defines a function `(CANP)` for processing images with `convolution, normalization, and pooling layers,` then applies this function multiple times to an input image of size 32x32 pixels.\n\n\n**`d1 = CANP(d1, 5,3)` explain 5 & 3 ?**\n\nThe values `5 and 3` used in the `CANP` function calls refer to:\n\n`5:` This is the number of filters in the Conv2D layer. Filters are used to extract different features from the input image. Having 5 filters means the convolution operation will produce 5 different feature maps.\n\n`3:` This is the size of the kernel (or filter window) used in the convolution operation. The kernel size is specified as (3, 3), which means the convolution will use a 3x3 window to scan through the input image, applying the convolution operation to extract features.\n\nIn each CANP function call, the image is convolved with 5 filters of size 3x3.\n\n\n\n\n\n\n\n\n\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"#### Parameter Counts","metadata":{}},{"cell_type":"markdown","source":"**1. First Conv2D Layer:**\n\n- Filter (Output Channel) = 5\n- Kernel Size  = `(3 x 3)`\n- Input Channel (RGB) = 3\n- as per Formula : `(Kernel_size *Input Channel * Filters ) + Bias Term for Each Filter`\n- `(3 x 3 x 3)+ (5*1) = 140`\n\n**2. First BatchNormalization Layer:**\n- `4` 2 Param for Gamma & 2 for Bita for each filter\n- `5` Number of filter\n- `4 x 5 = 20`\n\n**3. Second Conv2D Layer:**\n- `Input Shape : 16, 16, 5`\n- `(Kernel * Input Channel from Previos Layer * Filter ) + Bias Term`\n- `(3x3 x5 x5) + 5 = 225+5 = 230`\n\n**4. Second BatchNormalization Layer:**\n- `4` 2 Param for Gamma & 2 for Bita for each filter\n- `5` Number of filter\n- `4 x 5 = 20`\n\n**5. Third Conv2D Layer:**\n- `Input Shape : 8, 8, 5`\n- `(Kernel * Input Channel from Previos Layer * Filter ) + Bias Term`\n- `(3x3 x5 x5) + 5 = 225+5 = 230`\n\n**5. Third BatchNormalization Layer:**\n- `4` 2 Param for Gamma & 2 for Bita for each filter\n- `5` Number of filter\n- `4 x 5 = 20`\n\n\n**Total Params for model will be :**\n- `140 + 20 + 230 + 20 + 230 + 20 = 660` \n\n**Parmater Summary :**\n- **Conv2D Layers**: 600 Parameters\n- **BatchNorm Layers**: 60 Parameters\n- **Total** 660 Parameters","metadata":{}},{"cell_type":"markdown","source":"### Application - Connection Method","metadata":{}},{"cell_type":"code","source":"# Step 1\ndef R_CAN(ind1, fltr, krnl):\n    d1 = Conv2D(fltr, kernel_size=(krnl, krnl), padding='same', activation='gelu')(ind1)  # Conv-kernal, padding, activation\n    d1 = BatchNormalization()(d1)\n    return d1\n\n# Step 2 : Define Size\nimage_size = 32\ninputs = layers.Input(shape=(image_size, image_size,3))\nd1 = (inputs)\n\n# Step 3: Connections\nd2 = R_CAN(d1, 5, 3)  # Connection1\nd3 = R_CAN(d2, 5, 3)  # Connection2\nd4 = R_CAN(d3, 5, 3)  # Connection3\n\n# Step 4: Create and Summarize the Model\nclass_model = Model(inputs= inputs, outputs=d4)\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T05:06:03.586587Z","iopub.execute_input":"2025-01-31T05:06:03.587065Z","iopub.status.idle":"2025-01-31T05:06:03.673921Z","shell.execute_reply.started":"2025-01-31T05:06:03.587033Z","shell.execute_reply":"2025-01-31T05:06:03.672943Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_12\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_12\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)          ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)           ‚îÇ               \u001b[38;5;34m0\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m140\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_12               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m230\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_13               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)                   ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ             \u001b[38;5;34m230\u001b[0m ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_14               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)           ‚îÇ              \u001b[38;5;34m20\u001b[0m ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)                         </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape                </span>‚îÉ<span style=\"font-weight: bold\">         Param # </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)           ‚îÇ               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_12               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_13               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_14               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)           ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 ‚îÇ                             ‚îÇ                 ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m660\u001b[0m (2.58 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> (2.58 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m630\u001b[0m (2.46 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">630</span> (2.46 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m30\u001b[0m (120.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">30</span> (120.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"#### Connection Application 5.0","metadata":{}},{"cell_type":"code","source":"\n# Step 1\nimage_size = 32\ninputs = layers.Input(shape=(image_size,image_size,3))\nd1 =  (inputs) # This variable holds the input data and will be passed through subsequent layers\n\n# Step 2\nd2 = R_CAN(d1,5,3)  # This function applies a sequence of layers to d1 (the input). The output of R_CAN applied to d1\nd3 = R_CAN(d2,5,3)  # The output of R_CAN applied to d2 (with 5 filters and a 3x3 kernel).\nd31 = R_CAN(d2,25,3) # The output of R_CAN applied to d2 (with 25 filters and a 3x3 kernel).\n\n# Step 3\nd3 =  add([d3,d2]) # This operation adds the outputs of d3 and d2 element-wise. This is a common practice in residual networks (ResNets).\nd4 = R_CAN(d3,3,3) # This is the result of applying the R_CAN function to the combined output d3\n\n# Step 4\nclass_model = Model(inputs = inputs, outputs = d4)  # summary will be 0 if here metioned as `outputs = d1`, alwasy confirm last one\nclass_model.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T05:09:45.415527Z","iopub.execute_input":"2025-01-31T05:09:45.415979Z","iopub.status.idle":"2025-01-31T05:09:45.507797Z","shell.execute_reply.started":"2025-01-31T05:09:45.415942Z","shell.execute_reply":"2025-01-31T05:09:45.506778Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_13\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_13            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      ‚îÇ              \u001b[38;5;34m0\u001b[0m ‚îÇ -                      ‚îÇ\n‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)              ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ            \u001b[38;5;34m140\u001b[0m ‚îÇ input_layer_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_15    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ             \u001b[38;5;34m20\u001b[0m ‚îÇ conv2d_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ            \u001b[38;5;34m230\u001b[0m ‚îÇ batch_normalization_1‚Ä¶ ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_16    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ             \u001b[38;5;34m20\u001b[0m ‚îÇ conv2d_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ add (\u001b[38;5;33mAdd\u001b[0m)                 ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ              \u001b[38;5;34m0\u001b[0m ‚îÇ batch_normalization_1‚Ä¶ ‚îÇ\n‚îÇ                           ‚îÇ                        ‚îÇ                ‚îÇ batch_normalization_1‚Ä¶ ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      ‚îÇ            \u001b[38;5;34m138\u001b[0m ‚îÇ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_18    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      ‚îÇ             \u001b[38;5;34m12\u001b[0m ‚îÇ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)              </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">        Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to           </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_13            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                      ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> ‚îÇ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_15    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ conv2d_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> ‚îÇ batch_normalization_1‚Ä¶ ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_16    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ conv2d_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)                 ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ batch_normalization_1‚Ä¶ ‚îÇ\n‚îÇ                           ‚îÇ                        ‚îÇ                ‚îÇ batch_normalization_1‚Ä¶ ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span> ‚îÇ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_18    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> ‚îÇ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m560\u001b[0m (2.19 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">560</span> (2.19 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m534\u001b[0m (2.09 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">534</span> (2.09 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m26\u001b[0m (104.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26</span> (104.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"`add([d3, d2]):` : This operation adds the outputs of d3 and d2 element-wise. This is a common practice in residual networks (ResNets) to combine features learned from different layers.\n\n**Explanation:**\n\n`Input Layer`: Takes a 32x32 RGB image.\n\n`R_CAN(d1, 5, 3)`: First convolution block applied to the input.\n\n`R_CAN(d2, 5, 3)`: Second convolution block applied to the output of the first block.\n\n`R_CAN(d2, 25, 3)`: Another convolution block with more filters applied to the output of the first block.\n\n`add([d3, d2])`: Combines the second and first block outputs.\n\n`R_CAN(d3, 3, 3)`: Final convolution block applied to the combined output.\n\nThis structure likely aims to enhance feature extraction by combining different layers' outputs, leveraging the residual connections (add) to maintain feature integrity across layers.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Application 5.1","metadata":{}},{"cell_type":"code","source":"\n\nimage_size = 32\ninputs = layers.Input(shape=(image_size,image_size,3))\nin2 = layers.Input(shape=(image_size,image_size,3))\nd1 =  (inputs)\n\n\nd2 = R_CAN(d1,5,3)\nd21 = R_CAN(in2,5,3)\nd2 = add([d2,d21])\n\n\nd3 = R_CAN(d2,5,3)\nd3 = add([d3,d2])\nd4 = R_CAN(d3,3,3)\n\n\nclass_model = Model(inputs = [inputs, in2], outputs = [d2,d4])\nclass_model.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T05:17:17.641369Z","iopub.execute_input":"2025-01-31T05:17:17.641892Z","iopub.status.idle":"2025-01-31T05:17:17.734710Z","shell.execute_reply.started":"2025-01-31T05:17:17.641854Z","shell.execute_reply":"2025-01-31T05:17:17.733888Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_14\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_14            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      ‚îÇ              \u001b[38;5;34m0\u001b[0m ‚îÇ -                      ‚îÇ\n‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)              ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ input_layer_15            ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      ‚îÇ              \u001b[38;5;34m0\u001b[0m ‚îÇ -                      ‚îÇ\n‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)              ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ            \u001b[38;5;34m140\u001b[0m ‚îÇ input_layer_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ            \u001b[38;5;34m140\u001b[0m ‚îÇ input_layer_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_19    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ             \u001b[38;5;34m20\u001b[0m ‚îÇ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_20    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ             \u001b[38;5;34m20\u001b[0m ‚îÇ conv2d_24[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ add_1 (\u001b[38;5;33mAdd\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ              \u001b[38;5;34m0\u001b[0m ‚îÇ batch_normalization_1‚Ä¶ ‚îÇ\n‚îÇ                           ‚îÇ                        ‚îÇ                ‚îÇ batch_normalization_2‚Ä¶ ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ            \u001b[38;5;34m230\u001b[0m ‚îÇ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_21    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ             \u001b[38;5;34m20\u001b[0m ‚îÇ conv2d_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ add_2 (\u001b[38;5;33mAdd\u001b[0m)               ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m)      ‚îÇ              \u001b[38;5;34m0\u001b[0m ‚îÇ batch_normalization_2‚Ä¶ ‚îÇ\n‚îÇ                           ‚îÇ                        ‚îÇ                ‚îÇ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)        ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      ‚îÇ            \u001b[38;5;34m138\u001b[0m ‚îÇ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_22    ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      ‚îÇ             \u001b[38;5;34m12\u001b[0m ‚îÇ conv2d_26[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        ‚îÇ\n‚îÇ (\u001b[38;5;33mBatchNormalization\u001b[0m)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n‚îÉ<span style=\"font-weight: bold\"> Layer (type)              </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape           </span>‚îÉ<span style=\"font-weight: bold\">        Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to           </span>‚îÉ\n‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n‚îÇ input_layer_14            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                      ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ input_layer_15            ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                      ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> ‚îÇ input_layer_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">140</span> ‚îÇ input_layer_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_19    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_20    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ conv2d_24[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ batch_normalization_1‚Ä¶ ‚îÇ\n‚îÇ                           ‚îÇ                        ‚îÇ                ‚îÇ batch_normalization_2‚Ä¶ ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">230</span> ‚îÇ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_21    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> ‚îÇ conv2d_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      ‚îÇ              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ batch_normalization_2‚Ä¶ ‚îÇ\n‚îÇ                           ‚îÇ                        ‚îÇ                ‚îÇ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      ‚îÇ            <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span> ‚îÇ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ batch_normalization_22    ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      ‚îÇ             <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> ‚îÇ conv2d_26[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        ‚îÇ\n‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      ‚îÇ                        ‚îÇ                ‚îÇ                        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m720\u001b[0m (2.81 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">720</span> (2.81 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m684\u001b[0m (2.67 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">684</span> (2.67 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m36\u001b[0m (144.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36</span> (144.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":37},{"cell_type":"markdown","source":"### Tasks","metadata":{}},{"cell_type":"markdown","source":"- `Task1`: Explain the Parameter Calcuation Formula\n- `Task2`: Find Who are those Two Non-trainable Param ?\n  - Difference between Batch Norm by pytorch & tf (PyTorch 30 whereas TF-32) ?\n","metadata":{}},{"cell_type":"markdown","source":"### Ref","metadata":{}},{"cell_type":"markdown","source":"1. https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html","metadata":{}},{"cell_type":"markdown","source":"## Additional Test","metadata":{}},{"cell_type":"code","source":"# Excercise 1\n\nimport torch\nimport torch.nn as nn\nfrom torchsummary import summary\n\nclass ConvGELUModel(nn.Module):\n    def __init__(self):\n        super(ConvGELUModel, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)\n        self.gelu = nn.GELU()\n        self.bn1 = nn.BatchNorm2d(32)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n    def forward(self, x):\n        x = self.pool(self.bn1(self.gelu(self.conv1(x))))\n        return x\n\n# Creating an instance of the model\nmodel = ConvGELUModel()\n# Printing the model summary\nsummary(model, input_size=(1, 32, 32))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T02:38:17.461912Z","iopub.execute_input":"2025-01-31T02:38:17.462302Z","iopub.status.idle":"2025-01-31T02:38:17.478247Z","shell.execute_reply.started":"2025-01-31T02:38:17.462259Z","shell.execute_reply":"2025-01-31T02:38:17.477057Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1           [-1, 32, 32, 32]             320\n              GELU-2           [-1, 32, 32, 32]               0\n       BatchNorm2d-3           [-1, 32, 32, 32]              64\n         MaxPool2d-4           [-1, 32, 16, 16]               0\n================================================================\nTotal params: 384\nTrainable params: 384\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.81\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.82\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":33}]}