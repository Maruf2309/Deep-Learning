{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTgiVg0Aq-YD"
   },
   "source": [
    "# Crop Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3BMC1PSikJ_"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "02pI_cxYdCoh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pls\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Akn2MNqRi8_p",
    "outputId": "dbc96ca2-45b1-4994-eb8d-47fd4128fe34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUhm1p-2kHmK"
   },
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svty0lr219u9"
   },
   "source": [
    "## Data for Traing / Prepocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dD_Ds-x7kJkx",
    "outputId": "0cef814b-cae7-47f5-8e2c-c2db39671a97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1082 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = tf.keras.preprocessing.image.ImageDataGenerator (\n",
    "    rescale = 1/255.0\n",
    ")   # Creating an object, that just hold the data, 1 image. \n",
    "\n",
    "train_images = train_data_gen.flow_from_directory(             # flow_from_directory/ is a method : will help to execute / instruct to go following folder \n",
    "    'drive/MyDrive/DL-Econic/Crop Disease/AugmentedData',   # why augmented, because dl wants more data   \n",
    "    batch_size = 32,\n",
    "    target_size = (228, 228)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uM5VqjyCSFaw"
   },
   "source": [
    "### Code Narration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csgbtIH1NxWp"
   },
   "source": [
    "- code 5: each folder will be each category & each category will holds its own image\n",
    "- target_size: I dont know the actual size of image, that why i declared to read the image with 228 by 228 in pixel size / height & width\n",
    "- color not defined, because whatever the color machine will understand\n",
    "- code 5-8/ method: Return a things that is generator\n",
    "- Now the data is fridge, when executes it will call one by one, do not load whole data at a time, applied batch, not keeping all together, that helps for processing\n",
    "- train_test_gen is object & flow_from_directory is method, method applied on object\n",
    "- 3 classess means 3 folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3MaSgYyD2Bac"
   },
   "source": [
    "## Data for testing / validation || Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-4oYaBF2FFo",
    "outputId": "b86e9749-e89f-4e66-fe30-4950df76e157"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_data_gen = tf.keras.preprocessing.image.ImageDataGenerator (\n",
    "    rescale = 1 / 255.0     # 1/255 works little better, any value can be applied, depending dataset can be differet, 1 mean 1 imamge\n",
    ") \n",
    "\n",
    "valid_images = valid_data_gen.flow_from_directory (\n",
    "    'drive/MyDrive/DL-Econic/Crop Disease/data',\n",
    "    batch_size = 24,                             # total 120 image, which I want to keep in 5 batch so divided by 24\n",
    "    target_size = (228, 228)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlPvrKUlSkYg"
   },
   "source": [
    "## Generting Batch by Next Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3-8jhcyAVKAX"
   },
   "source": [
    "- Its return two: 1 is image: 0 & label of that batch or batch_size when index 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rokH0uaC63aB",
    "outputId": "57a89aff-7bde-4300-cacb-aca7c17534bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(valid_images)[1]  # Labels/ class Stored when index 1, see everything is ready, all data are in properly one hot encoded vector shape, its save more time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oKo9xE-tTKp4"
   },
   "source": [
    "### Code Narration - Next Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2PG9VMRTPns"
   },
   "source": [
    "- 1 means when its read image, then not store image only, rather store \"Label\" as well\n",
    "- See the array, 3 values means 3 category, where there is 1, its represent the class e.g kon ta kon class belong kore\n",
    "- Like saved/ stored the labels by \"One Hot Encoder\" whose index is 1 & Images stored in index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SrTkbcpStU5",
    "outputId": "fadb8a38-208d-47d5-b924-c29bc93fcbaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.58431375, 0.54509807, 0.2627451 ],\n",
       "         [0.5882353 , 0.5647059 , 0.26666668],\n",
       "         [0.5686275 , 0.5568628 , 0.25490198]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.58431375, 0.54509807, 0.2627451 ],\n",
       "         [0.5882353 , 0.5647059 , 0.26666668],\n",
       "         [0.5686275 , 0.5568628 , 0.25490198]],\n",
       "\n",
       "        [[1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         [1.        , 1.        , 1.        ],\n",
       "         ...,\n",
       "         [0.58431375, 0.54509807, 0.2627451 ],\n",
       "         [0.5882353 , 0.5647059 , 0.26666668],\n",
       "         [0.5686275 , 0.5568628 , 0.25490198]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.5686275 , 0.64705884, 0.25882354],\n",
       "         [0.5803922 , 0.65882355, 0.27058825],\n",
       "         [0.58431375, 0.6627451 , 0.27450982],\n",
       "         ...,\n",
       "         [0.3137255 , 0.22352943, 0.09803922],\n",
       "         [0.33333334, 0.2392157 , 0.10588236],\n",
       "         [0.34901962, 0.25490198, 0.12156864]],\n",
       "\n",
       "        [[0.5686275 , 0.64705884, 0.25882354],\n",
       "         [0.5803922 , 0.65882355, 0.27058825],\n",
       "         [0.58431375, 0.6627451 , 0.27450982],\n",
       "         ...,\n",
       "         [0.3137255 , 0.22352943, 0.09803922],\n",
       "         [0.33333334, 0.2392157 , 0.10588236],\n",
       "         [0.34901962, 0.25490198, 0.12156864]],\n",
       "\n",
       "        [[0.5686275 , 0.64705884, 0.25882354],\n",
       "         [0.5803922 , 0.65882355, 0.27058825],\n",
       "         [0.58431375, 0.6627451 , 0.27450982],\n",
       "         ...,\n",
       "         [0.3137255 , 0.22352943, 0.09803922],\n",
       "         [0.33333334, 0.2392157 , 0.10588236],\n",
       "         [0.34901962, 0.25490198, 0.12156864]]],\n",
       "\n",
       "\n",
       "       [[[0.93725497, 0.90196085, 0.882353  ],\n",
       "         [0.9333334 , 0.8941177 , 0.8588236 ],\n",
       "         [0.93725497, 0.8980393 , 0.86274517],\n",
       "         ...,\n",
       "         [0.9294118 , 0.8862746 , 0.86274517],\n",
       "         [0.93725497, 0.8862746 , 0.86274517],\n",
       "         [0.9294118 , 0.8862746 , 0.86274517]],\n",
       "\n",
       "        [[0.9333334 , 0.8980393 , 0.8705883 ],\n",
       "         [0.93725497, 0.8980393 , 0.86274517],\n",
       "         [0.9333334 , 0.8941177 , 0.8588236 ],\n",
       "         ...,\n",
       "         [0.9294118 , 0.8862746 , 0.86274517],\n",
       "         [0.9333334 , 0.882353  , 0.85098046],\n",
       "         [0.9333334 , 0.8941177 , 0.8588236 ]],\n",
       "\n",
       "        [[0.93725497, 0.90196085, 0.8745099 ],\n",
       "         [0.9333334 , 0.89019614, 0.86666673],\n",
       "         [0.9294118 , 0.8862746 , 0.86274517],\n",
       "         ...,\n",
       "         [0.92549026, 0.8862746 , 0.85098046],\n",
       "         [0.93725497, 0.8862746 , 0.854902  ],\n",
       "         [0.93725497, 0.8862746 , 0.854902  ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.93725497, 0.8862746 , 0.854902  ],\n",
       "         [0.9333334 , 0.8980393 , 0.8705883 ],\n",
       "         [0.94117653, 0.909804  , 0.8980393 ],\n",
       "         ...,\n",
       "         [0.94117653, 0.89019614, 0.8588236 ],\n",
       "         [0.93725497, 0.8862746 , 0.854902  ],\n",
       "         [0.94117653, 0.89019614, 0.8588236 ]],\n",
       "\n",
       "        [[0.9333334 , 0.8941177 , 0.8588236 ],\n",
       "         [0.93725497, 0.90196085, 0.882353  ],\n",
       "         [0.9294118 , 0.909804  , 0.8862746 ],\n",
       "         ...,\n",
       "         [0.93725497, 0.87843144, 0.85098046],\n",
       "         [0.94117653, 0.89019614, 0.8588236 ],\n",
       "         [0.93725497, 0.87843144, 0.85098046]],\n",
       "\n",
       "        [[0.9333334 , 0.8941177 , 0.8588236 ],\n",
       "         [0.94117653, 0.9058824 , 0.8862746 ],\n",
       "         [0.93725497, 0.909804  , 0.87843144],\n",
       "         ...,\n",
       "         [0.94117653, 0.89019614, 0.8588236 ],\n",
       "         [0.93725497, 0.8862746 , 0.854902  ],\n",
       "         [0.9490197 , 0.882353  , 0.854902  ]]],\n",
       "\n",
       "\n",
       "       [[[0.8941177 , 0.8431373 , 0.8196079 ],\n",
       "         [0.909804  , 0.83921576, 0.8235295 ],\n",
       "         [0.8941177 , 0.8431373 , 0.8196079 ],\n",
       "         ...,\n",
       "         [0.9176471 , 0.8745099 , 0.8588236 ],\n",
       "         [0.92549026, 0.8705883 , 0.8588236 ],\n",
       "         [0.9215687 , 0.86666673, 0.854902  ]],\n",
       "\n",
       "        [[0.8941177 , 0.8431373 , 0.8196079 ],\n",
       "         [0.8941177 , 0.8352942 , 0.81568635],\n",
       "         [0.90196085, 0.85098046, 0.82745105],\n",
       "         ...,\n",
       "         [0.92549026, 0.882353  , 0.86666673],\n",
       "         [0.9294118 , 0.8862746 , 0.8705883 ],\n",
       "         [0.9176471 , 0.8745099 , 0.8588236 ]],\n",
       "\n",
       "        [[0.89019614, 0.83921576, 0.81568635],\n",
       "         [0.8980393 , 0.83921576, 0.8196079 ],\n",
       "         [0.8980393 , 0.8470589 , 0.8235295 ],\n",
       "         ...,\n",
       "         [0.9176471 , 0.8745099 , 0.8588236 ],\n",
       "         [0.92549026, 0.882353  , 0.8588236 ],\n",
       "         [0.9333334 , 0.89019614, 0.86666673]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9294118 , 0.8588236 , 0.8431373 ],\n",
       "         [0.9215687 , 0.86274517, 0.8352942 ],\n",
       "         [0.91372555, 0.8588236 , 0.8470589 ],\n",
       "         ...,\n",
       "         [0.9294118 , 0.8705883 , 0.85098046],\n",
       "         [0.92549026, 0.86666673, 0.8470589 ],\n",
       "         [0.9058824 , 0.854902  , 0.8313726 ]],\n",
       "\n",
       "        [[0.9294118 , 0.86274517, 0.8352942 ],\n",
       "         [0.9215687 , 0.86274517, 0.8352942 ],\n",
       "         [0.9176471 , 0.8588236 , 0.8313726 ],\n",
       "         ...,\n",
       "         [0.9176471 , 0.86666673, 0.8431373 ],\n",
       "         [0.9215687 , 0.8705883 , 0.8470589 ],\n",
       "         [0.9215687 , 0.86666673, 0.854902  ]],\n",
       "\n",
       "        [[0.93725497, 0.8705883 , 0.83921576],\n",
       "         [0.9294118 , 0.86274517, 0.8352942 ],\n",
       "         [0.92549026, 0.8588236 , 0.82745105],\n",
       "         ...,\n",
       "         [0.90196085, 0.85098046, 0.82745105],\n",
       "         [0.94117653, 0.89019614, 0.86666673],\n",
       "         [0.9176471 , 0.86274517, 0.8588236 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.90196085, 0.83921576, 0.83921576],\n",
       "         [0.9058824 , 0.85098046, 0.8470589 ],\n",
       "         [0.9215687 , 0.8705883 , 0.8470589 ],\n",
       "         ...,\n",
       "         [0.9215687 , 0.8705883 , 0.8470589 ],\n",
       "         [0.93725497, 0.86666673, 0.85098046],\n",
       "         [0.9333334 , 0.8745099 , 0.8470589 ]],\n",
       "\n",
       "        [[0.90196085, 0.83921576, 0.83921576],\n",
       "         [0.8941177 , 0.85098046, 0.8352942 ],\n",
       "         [0.91372555, 0.86274517, 0.83921576],\n",
       "         ...,\n",
       "         [0.9215687 , 0.8705883 , 0.8470589 ],\n",
       "         [0.9215687 , 0.854902  , 0.82745105],\n",
       "         [0.9333334 , 0.8745099 , 0.8470589 ]],\n",
       "\n",
       "        [[0.90196085, 0.83921576, 0.83921576],\n",
       "         [0.90196085, 0.8470589 , 0.8352942 ],\n",
       "         [0.909804  , 0.854902  , 0.8431373 ],\n",
       "         ...,\n",
       "         [0.9333334 , 0.8745099 , 0.86274517],\n",
       "         [0.9215687 , 0.85098046, 0.8352942 ],\n",
       "         [0.92549026, 0.86666673, 0.83921576]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.909804  , 0.85098046, 0.83921576],\n",
       "         [0.9215687 , 0.86274517, 0.85098046],\n",
       "         [0.9058824 , 0.854902  , 0.8313726 ],\n",
       "         ...,\n",
       "         [0.9215687 , 0.86274517, 0.85098046],\n",
       "         [0.9294118 , 0.8705883 , 0.85098046],\n",
       "         [0.9294118 , 0.87843144, 0.854902  ]],\n",
       "\n",
       "        [[0.91372555, 0.854902  , 0.8352942 ],\n",
       "         [0.909804  , 0.854902  , 0.8431373 ],\n",
       "         [0.9176471 , 0.8588236 , 0.83921576],\n",
       "         ...,\n",
       "         [0.9176471 , 0.8588236 , 0.8470589 ],\n",
       "         [0.9294118 , 0.8705883 , 0.85098046],\n",
       "         [0.92549026, 0.86666673, 0.8470589 ]],\n",
       "\n",
       "        [[0.9176471 , 0.8588236 , 0.83921576],\n",
       "         [0.90196085, 0.8588236 , 0.8431373 ],\n",
       "         [0.9176471 , 0.8588236 , 0.8313726 ],\n",
       "         ...,\n",
       "         [0.92549026, 0.86666673, 0.8470589 ],\n",
       "         [0.9333334 , 0.86274517, 0.8470589 ],\n",
       "         [0.9294118 , 0.8705883 , 0.85098046]]],\n",
       "\n",
       "\n",
       "       [[[0.9450981 , 0.91372555, 0.90196085],\n",
       "         [0.94117653, 0.909804  , 0.8980393 ],\n",
       "         [0.9450981 , 0.9058824 , 0.90196085],\n",
       "         ...,\n",
       "         [0.9294118 , 0.8862746 , 0.86274517],\n",
       "         [0.9333334 , 0.8980393 , 0.8705883 ],\n",
       "         [0.9294118 , 0.8862746 , 0.86274517]],\n",
       "\n",
       "        [[0.9450981 , 0.91372555, 0.90196085],\n",
       "         [0.94117653, 0.909804  , 0.8980393 ],\n",
       "         [0.9450981 , 0.91372555, 0.9058824 ],\n",
       "         ...,\n",
       "         [0.9294118 , 0.8862746 , 0.86274517],\n",
       "         [0.92549026, 0.89019614, 0.86274517],\n",
       "         [0.92549026, 0.882353  , 0.8588236 ]],\n",
       "\n",
       "        [[0.94117653, 0.909804  , 0.8980393 ],\n",
       "         [0.93725497, 0.9058824 , 0.8941177 ],\n",
       "         [0.9490197 , 0.9176471 , 0.9058824 ],\n",
       "         ...,\n",
       "         [0.9294118 , 0.8941177 , 0.86666673],\n",
       "         [0.9294118 , 0.8862746 , 0.86274517],\n",
       "         [0.92549026, 0.882353  , 0.8588236 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9450981 , 0.91372555, 0.90196085],\n",
       "         [0.95294124, 0.92549026, 0.90196085],\n",
       "         [0.9450981 , 0.90196085, 0.8862746 ],\n",
       "         ...,\n",
       "         [0.92549026, 0.882353  , 0.8588236 ],\n",
       "         [0.94117653, 0.90196085, 0.86666673],\n",
       "         [0.92549026, 0.882353  , 0.8588236 ]],\n",
       "\n",
       "        [[0.94117653, 0.909804  , 0.8980393 ],\n",
       "         [0.95294124, 0.92549026, 0.90196085],\n",
       "         [0.95294124, 0.909804  , 0.8941177 ],\n",
       "         ...,\n",
       "         [0.9333334 , 0.89019614, 0.8745099 ],\n",
       "         [0.94117653, 0.90196085, 0.86666673],\n",
       "         [0.9294118 , 0.8862746 , 0.86274517]],\n",
       "\n",
       "        [[0.94117653, 0.909804  , 0.8980393 ],\n",
       "         [0.9450981 , 0.9176471 , 0.8941177 ],\n",
       "         [0.95294124, 0.909804  , 0.8941177 ],\n",
       "         ...,\n",
       "         [0.9294118 , 0.8862746 , 0.8705883 ],\n",
       "         [0.93725497, 0.8980393 , 0.86274517],\n",
       "         [0.9176471 , 0.8745099 , 0.85098046]]],\n",
       "\n",
       "\n",
       "       [[[0.9450981 , 0.909804  , 0.89019614],\n",
       "         [0.9490197 , 0.909804  , 0.90196085],\n",
       "         [0.9450981 , 0.91372555, 0.90196085],\n",
       "         ...,\n",
       "         [0.9294118 , 0.8941177 , 0.8745099 ],\n",
       "         [0.93725497, 0.8862746 , 0.854902  ],\n",
       "         [0.9333334 , 0.89019614, 0.86666673]],\n",
       "\n",
       "        [[0.9450981 , 0.909804  , 0.89019614],\n",
       "         [0.9490197 , 0.909804  , 0.90196085],\n",
       "         [0.9450981 , 0.91372555, 0.90196085],\n",
       "         ...,\n",
       "         [0.9333334 , 0.8980393 , 0.87843144],\n",
       "         [0.93725497, 0.8862746 , 0.86274517],\n",
       "         [0.94117653, 0.89019614, 0.86666673]],\n",
       "\n",
       "        [[0.94117653, 0.9058824 , 0.8862746 ],\n",
       "         [0.94117653, 0.9058824 , 0.8862746 ],\n",
       "         [0.9490197 , 0.9176471 , 0.9058824 ],\n",
       "         ...,\n",
       "         [0.9333334 , 0.8980393 , 0.87843144],\n",
       "         [0.9333334 , 0.89019614, 0.8745099 ],\n",
       "         [0.94117653, 0.89019614, 0.86666673]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.9450981 , 0.909804  , 0.89019614],\n",
       "         [0.94117653, 0.9215687 , 0.909804  ],\n",
       "         [0.94117653, 0.9215687 , 0.909804  ],\n",
       "         ...,\n",
       "         [0.9333334 , 0.8941177 , 0.8588236 ],\n",
       "         [0.9294118 , 0.8862746 , 0.86274517],\n",
       "         [0.93725497, 0.8941177 , 0.8705883 ]],\n",
       "\n",
       "        [[0.9450981 , 0.909804  , 0.89019614],\n",
       "         [0.9450981 , 0.91372555, 0.90196085],\n",
       "         [0.94117653, 0.9215687 , 0.909804  ],\n",
       "         ...,\n",
       "         [0.9333334 , 0.8941177 , 0.8588236 ],\n",
       "         [0.94117653, 0.8980393 , 0.8745099 ],\n",
       "         [0.93725497, 0.8941177 , 0.8705883 ]],\n",
       "\n",
       "        [[0.94117653, 0.9058824 , 0.8862746 ],\n",
       "         [0.9490197 , 0.909804  , 0.90196085],\n",
       "         [0.93725497, 0.9176471 , 0.90196085],\n",
       "         ...,\n",
       "         [0.93725497, 0.8980393 , 0.86274517],\n",
       "         [0.93725497, 0.8941177 , 0.8705883 ],\n",
       "         [0.93725497, 0.8941177 , 0.8705883 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(valid_images)[0]  # Image Stored when index 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkNWrt3TVt7B"
   },
   "source": [
    "# Creating Method / Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmgGkJZfXD7Q"
   },
   "source": [
    "- Creating Method for ploting \"Loss\" & \"Accuracy\"\n",
    "- It will take from history & training\n",
    "- plot for trainin loss or validation loss / error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nki2QwAiUrQR"
   },
   "outputs": [],
   "source": [
    "def plotLoss(history:pd.DataFrame):  # Providing history dataframe, which will keep training history in neuron network & see that over the time how model learned graphically\n",
    "  plt.figure(figsize=(18,20))\n",
    "  plt.plot(history.index.values,\n",
    "           history['loss'], label='Training Error', color = 'darkorange', linewidth=3)\n",
    "  plt.plot(history.index.values,\n",
    "           history['val_loss'], label = 'Validation Error', color = 'lightgreen', linewidth=3)\n",
    "  \n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "def plotAccuracy(history:pd.DataFrame):\n",
    "  plt.figure(figsize=(18,20))\n",
    "  plt.plot(history.index.values, history['accuracy'],\n",
    "           label='Training Accuracy', color = 'darkorange', linewidth=3)\n",
    "  plt.plot(history.index.values, history['val_accuracy'],\n",
    "           label='Validation Accuracy', color='lightgreen', linewidth=3)\n",
    "  \n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJs4frZBaJCO"
   },
   "source": [
    "# Convolution Neuron Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MI8ONlLlkr-4"
   },
   "source": [
    "## Initialize - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rREBqz8taNRJ"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.Sequential([\n",
    "        # Convolution Feature Extraction                 # First layer is convolutional layer, normalization can also be applied, its optional\n",
    "        tf.keras.layers.Conv2D(                          # There are also 1D, 2D & 3D available\n",
    "           filters=32, kernel_size=(3,3),\n",
    "           strides=(1,1), activation='relu',\n",
    "           input_shape=(228, 228, 3), padding='same'     # Since its first layer, its dont know enough, so input spape must be defined, so that it can understand\n",
    "        ), \n",
    "\n",
    "\n",
    "        # Dimesionality Reduction                     # After 1st conv, there are so many dimenstion, that must be reduced\n",
    "        tf.keras.layers.MaxPool2D(                    # Maxpool 2D, becuause our filter/ Cov2D, so its must be 2D\n",
    "           pool_size=(2,2), strides=(1,1), padding='same'\n",
    "        ),\n",
    "\n",
    "        \n",
    "        # Batch Normalization                        # Batch Normalization works better for image processing\n",
    "        tf.keras.layers.BatchNormalization(),         # after normalization, still its in image for, so need to covert into 1D array\n",
    "        tf.keras.layers.Flatten(),                  # Flatting for converting 1D array\n",
    "\n",
    "\n",
    "        # fulluy Connected Network                            # Connecting Artifician Neuron Network\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(rate=0.5, seed=42),              # regularization: dropout, earlystopping, cotroll randomness, seed 42\n",
    "        tf.keras.layers.Dense(units=3, activation='softmax')   # 3 for 3 class classfication / for multiclass softmax\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i9eL7JZDTxQ3"
   },
   "source": [
    "### Code Narration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfXmr2D6T0HS"
   },
   "source": [
    "- First layer is convolutional layer, normalization can also be applied, its optional\n",
    "- Normalization, not needed actually, becase at the first when retrieve image, we are defining data generated to rescale the image (1/255), so its alreay normalized\n",
    "- 3x3, total 32 filter like eye, e.g some filter recognize eye, some for nose, some for ear, some for lip etc\n",
    "- So, multiple filter used for different purpose\n",
    "- Why multiple feature ? Ans. Each will understand different features\n",
    "- Kernel Size: that mean 3x3 matrix, stride 1,1 , move space. First move right with 1 space, end then move down with 1 space, first col wise then row wise on the image\n",
    "- For each pixel, 1 value will be generated, oi filter ta oi image er porsion er sathe multiply hobe component wise then we do sum of this -\n",
    "- After summation the value we got, that will be passed through the activation wether the pixel will be activated or not or pass or not as a feature that is activation\n",
    "- Relu: inially in deep layers, relu works better\n",
    "- Layers needed to add continuouly when 'Sequencial'\n",
    "- MaxPool: The output we get from first layer, setar upore dimenstion reduce korar jonno, will do MaxPool\n",
    "- PoolSize : 2D (2,2) : That is matrix size will move over the \"Output Matrix\" or output image, Stride, move space by col & row wise\n",
    "- Stride (1,1) : it could be 2,2 ; 3,3 the more the value, the more the dimentionality reduction with the chance of loosing data also, but it will depend  the image size/ image position\n",
    "- Sequencial in a sence of layers not data, layers are sequencially connected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KQKB4yMngDGX"
   },
   "source": [
    "#### Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvvjlBsbgHts"
   },
   "source": [
    "- Batch normalization is a method used to make training of artificial neural networks faster and more stable through normalization of the layers' inputs by re-centering and re-scaling.\n",
    "- Like there are 32 image, like ekta certain corner er pixel value for each 32 image (with same positional pixel value), it will sum & do average (so that all collection of pixel values stays at a similar range/ come under normal form) & by that value it will apply the normalization\n",
    "- Pixel pixel/ same positional pixel value/ same korner er for 32 imange e.g 0,1\n",
    "- Batch Normalization for model optimization\n",
    "- Like standard/ min, max sclar: Standard scaler, protita dataset k average kore okhan theke min k minus korto & std diye divide korto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oPszbz2vk4gh"
   },
   "source": [
    "## Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rZE4qilCk60S"
   },
   "outputs": [],
   "source": [
    "cnn.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'categorical_crossentropy',  # Categorical crosentropy for calculating loss for multiclass\n",
    "    metrics = ['accuracy']             # Matrics for evaluate that is accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQ5qxrTal1Ku"
   },
   "source": [
    "## GPU Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzwR3dtSl_Wh"
   },
   "source": [
    "- Go Runtime > Change runtime type > hardware > GPU >> run all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j7LfjNaglei7",
    "outputId": "2a1b0b8b-676c-483f-e9d1-7278deb17d04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices()  # Check the CPU & GPU Status, here I have 1 CPU & 1 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMx39P_bm7_f"
   },
   "source": [
    "## Fit the Model - with GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Os_bzOIymqqL",
    "outputId": "bd06767a-a6fe-4791-8337-958388b27ed7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "34/34 [==============================] - 599s 17s/step - loss: 85.9909 - accuracy: 0.5961 - val_loss: 16.7322 - val_accuracy: 0.3750\n",
      "Epoch 2/25\n",
      "34/34 [==============================] - 7s 205ms/step - loss: 3.8972 - accuracy: 0.5850 - val_loss: 1.2057 - val_accuracy: 0.4500\n",
      "Epoch 3/25\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.8080 - accuracy: 0.5397 - val_loss: 1.3926 - val_accuracy: 0.3750\n",
      "Epoch 4/25\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 1.1202 - accuracy: 0.5841 - val_loss: 1.1591 - val_accuracy: 0.4833\n",
      "Epoch 5/25\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 0.8589 - accuracy: 0.6155 - val_loss: 1.1248 - val_accuracy: 0.4333\n",
      "Epoch 6/25\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 0.8225 - accuracy: 0.6128 - val_loss: 1.5181 - val_accuracy: 0.4417\n",
      "Epoch 7/25\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 0.6611 - accuracy: 0.6590 - val_loss: 0.7231 - val_accuracy: 0.6833\n",
      "Epoch 8/25\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 0.6227 - accuracy: 0.6756 - val_loss: 0.5801 - val_accuracy: 0.7500\n",
      "Epoch 9/25\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.5901 - accuracy: 0.6728 - val_loss: 0.5319 - val_accuracy: 0.7667\n",
      "Epoch 10/25\n",
      "34/34 [==============================] - 7s 199ms/step - loss: 0.6230 - accuracy: 0.6738 - val_loss: 0.8086 - val_accuracy: 0.5083\n",
      "Epoch 11/25\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 0.5940 - accuracy: 0.7043 - val_loss: 0.4605 - val_accuracy: 0.8583\n",
      "Epoch 12/25\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.5377 - accuracy: 0.7107 - val_loss: 0.6274 - val_accuracy: 0.7000\n",
      "Epoch 13/25\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 0.5597 - accuracy: 0.7089 - val_loss: 0.4107 - val_accuracy: 0.7500\n",
      "Epoch 14/25\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 0.5073 - accuracy: 0.7495 - val_loss: 0.2970 - val_accuracy: 0.9250\n",
      "Epoch 15/25\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 0.5050 - accuracy: 0.7384 - val_loss: 0.3996 - val_accuracy: 0.9417\n",
      "Epoch 16/25\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 0.5838 - accuracy: 0.7255 - val_loss: 2.3027 - val_accuracy: 0.6333\n",
      "Epoch 17/25\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 0.4817 - accuracy: 0.7625 - val_loss: 1.2919 - val_accuracy: 0.7083\n",
      "Epoch 18/25\n",
      "34/34 [==============================] - 7s 204ms/step - loss: 0.5497 - accuracy: 0.7431 - val_loss: 1.2772 - val_accuracy: 0.6417\n",
      "Epoch 19/25\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 0.4996 - accuracy: 0.7662 - val_loss: 0.5983 - val_accuracy: 0.8333\n",
      "Epoch 20/25\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 0.5218 - accuracy: 0.7662 - val_loss: 1.6462 - val_accuracy: 0.7167\n",
      "Epoch 21/25\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 0.4806 - accuracy: 0.7930 - val_loss: 0.3211 - val_accuracy: 0.9333\n",
      "Epoch 22/25\n",
      "34/34 [==============================] - 7s 202ms/step - loss: 0.4619 - accuracy: 0.7939 - val_loss: 0.1442 - val_accuracy: 0.9417\n",
      "Epoch 23/25\n",
      "34/34 [==============================] - 7s 200ms/step - loss: 0.5026 - accuracy: 0.7579 - val_loss: 2.1029 - val_accuracy: 0.6667\n",
      "Epoch 24/25\n",
      "34/34 [==============================] - 7s 201ms/step - loss: 0.5942 - accuracy: 0.7153 - val_loss: 57.7139 - val_accuracy: 0.4500\n",
      "Epoch 25/25\n",
      "34/34 [==============================] - 7s 203ms/step - loss: 0.5688 - accuracy: 0.7163 - val_loss: 0.8532 - val_accuracy: 0.8083\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):  # Creating Session: ask to use GPU devise to perform all the follwing opertion\n",
    "  cnn.fit(\n",
    "      train_images,  # Generator\n",
    "      epochs= 25,\n",
    "      validation_data = valid_images  # Generator\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NKhiy04rEt0"
   },
   "source": [
    "- Accuracy fluctuate becasue each iteration train on different batched, that is the chararistic of Stochastic Approach\n",
    "- Fluctuation will increase more if take one after one image, that why we dont take one & one, rather applied batch\n",
    "- Application on all at a time also problem, so batch is better option"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhoDfSiSr--H"
   },
   "source": [
    "# Model Summary - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W06zIeXsnj2z",
    "outputId": "f230a87b-e79f-419c-87f5-d014d25bd798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 228, 228, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 228, 228, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 228, 228, 32)     128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1663488)           0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               212926592 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 212,928,003\n",
      "Trainable params: 212,927,939\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 833
    },
    "id": "FGXYBfkisDYa",
    "outputId": "a63b52b6-a323-426b-8f36-00ba9abc3592"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b6c68aac-c754-4bb0-8422-db388c62f841\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.990913</td>\n",
       "      <td>0.596118</td>\n",
       "      <td>16.732220</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.897228</td>\n",
       "      <td>0.585028</td>\n",
       "      <td>1.205655</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.807974</td>\n",
       "      <td>0.539741</td>\n",
       "      <td>1.392599</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.120162</td>\n",
       "      <td>0.584104</td>\n",
       "      <td>1.159144</td>\n",
       "      <td>0.483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.858871</td>\n",
       "      <td>0.615527</td>\n",
       "      <td>1.124847</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.822478</td>\n",
       "      <td>0.612754</td>\n",
       "      <td>1.518076</td>\n",
       "      <td>0.441667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.661092</td>\n",
       "      <td>0.658965</td>\n",
       "      <td>0.723090</td>\n",
       "      <td>0.683333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.622743</td>\n",
       "      <td>0.675601</td>\n",
       "      <td>0.580110</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.590127</td>\n",
       "      <td>0.672828</td>\n",
       "      <td>0.531947</td>\n",
       "      <td>0.766667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.623026</td>\n",
       "      <td>0.673752</td>\n",
       "      <td>0.808594</td>\n",
       "      <td>0.508333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.594002</td>\n",
       "      <td>0.704251</td>\n",
       "      <td>0.460463</td>\n",
       "      <td>0.858333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.537657</td>\n",
       "      <td>0.710721</td>\n",
       "      <td>0.627416</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.559658</td>\n",
       "      <td>0.708872</td>\n",
       "      <td>0.410730</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.507276</td>\n",
       "      <td>0.749538</td>\n",
       "      <td>0.297010</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.505011</td>\n",
       "      <td>0.738447</td>\n",
       "      <td>0.399577</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.583811</td>\n",
       "      <td>0.725508</td>\n",
       "      <td>2.302717</td>\n",
       "      <td>0.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.481653</td>\n",
       "      <td>0.762477</td>\n",
       "      <td>1.291908</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.549660</td>\n",
       "      <td>0.743068</td>\n",
       "      <td>1.277228</td>\n",
       "      <td>0.641667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.499632</td>\n",
       "      <td>0.766174</td>\n",
       "      <td>0.598341</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.521794</td>\n",
       "      <td>0.766174</td>\n",
       "      <td>1.646158</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.480585</td>\n",
       "      <td>0.792976</td>\n",
       "      <td>0.321066</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.461914</td>\n",
       "      <td>0.793900</td>\n",
       "      <td>0.144248</td>\n",
       "      <td>0.941667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.502627</td>\n",
       "      <td>0.757856</td>\n",
       "      <td>2.102896</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.594228</td>\n",
       "      <td>0.715342</td>\n",
       "      <td>57.713852</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.568772</td>\n",
       "      <td>0.716266</td>\n",
       "      <td>0.853196</td>\n",
       "      <td>0.808333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6c68aac-c754-4bb0-8422-db388c62f841')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-b6c68aac-c754-4bb0-8422-db388c62f841 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-b6c68aac-c754-4bb0-8422-db388c62f841');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "         loss  accuracy   val_loss  val_accuracy\n",
       "0   85.990913  0.596118  16.732220      0.375000\n",
       "1    3.897228  0.585028   1.205655      0.450000\n",
       "2    1.807974  0.539741   1.392599      0.375000\n",
       "3    1.120162  0.584104   1.159144      0.483333\n",
       "4    0.858871  0.615527   1.124847      0.433333\n",
       "5    0.822478  0.612754   1.518076      0.441667\n",
       "6    0.661092  0.658965   0.723090      0.683333\n",
       "7    0.622743  0.675601   0.580110      0.750000\n",
       "8    0.590127  0.672828   0.531947      0.766667\n",
       "9    0.623026  0.673752   0.808594      0.508333\n",
       "10   0.594002  0.704251   0.460463      0.858333\n",
       "11   0.537657  0.710721   0.627416      0.700000\n",
       "12   0.559658  0.708872   0.410730      0.750000\n",
       "13   0.507276  0.749538   0.297010      0.925000\n",
       "14   0.505011  0.738447   0.399577      0.941667\n",
       "15   0.583811  0.725508   2.302717      0.633333\n",
       "16   0.481653  0.762477   1.291908      0.708333\n",
       "17   0.549660  0.743068   1.277228      0.641667\n",
       "18   0.499632  0.766174   0.598341      0.833333\n",
       "19   0.521794  0.766174   1.646158      0.716667\n",
       "20   0.480585  0.792976   0.321066      0.933333\n",
       "21   0.461914  0.793900   0.144248      0.941667\n",
       "22   0.502627  0.757856   2.102896      0.666667\n",
       "23   0.594228  0.715342  57.713852      0.450000\n",
       "24   0.568772  0.716266   0.853196      0.808333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = pd.DataFrame(cnn.history.history)\n",
    "hist"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
